{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서플로우\n",
    "* 수치 계산을 위한 강력한 오픈소스 SW 라이브러리\n",
    "* 계산 그래프를 여러 부분으로 나누어 여러 CPU나 GPU에서 병렬로 실행할 수 있다.\n",
    "* 분산 컴퓨팅도 지원하므로 수백 대의 서버에 계산을 나누어 납득할만한 시간 안에 대규모 데이터셋으로 거대한 신경을 훈련시킬 수 있다.\n",
    "* 수백만 개의 특성을 가진 수십억 개의 샘플로 구성된 데이터셋에서 수백만 개의 파라미터를 가진 네트워크를 훈련시킬 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 계산 그래프 만들어 세션에서 실행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_1:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "x = tf.Variable(3, name='x')\n",
    "y = tf.Variable(4, name='y')\n",
    "f = x*x*y + y + 2\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 코드가(특히 마지막 줄) 계산을 하는 것처럼 보이지만 실제로 어떤 계산도 수행하지 않는다. 단지 계산 그래프만 만든다. 사실 변수조차도 초기화되지 않는다.\n",
    "* 이 계산 그래프를 평가하려면 텐서플로 세션을 시작하고 변수를 초기화한 다음 `f`를 평가해야 한다.\n",
    "> **평가**  \n",
    "계산 그래프나 노드를 실행(run, execute)하여 연산의 값을 계산한다는 의미\n",
    "* 세션은 연산을 CPU나 GPU같은 장치에 올리고 실행하는 것을 도와주며 모든 변숫값을 가지고 있다. (텐서플로 분산 환경에서는 변숫값이 세션이 아니라 서버에 저장된다)\n",
    "\n",
    "#### 세션을 만들고 변수 초기화한 다음 `f`를 평가하고 세션 닫기(즉, 자원 해제)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 매번 실행하는 `sess.run()` 반복을 해소하는 방법(단순화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * `with` 블록 안에서는 `with`문에서 선언한 세션이 기본 세션으로 지정된다.\n",
    "* `x.initializer.run()` : `tf.get_default_session().run(x.initializer)` 호출하는 것과 동일\n",
    "* `f.eval()` : `tf.get_default_session().run(f)` 호출하는 것과 동일\n",
    "    * `tf.Operation` 객체 (`x.initializer`와 같은) : `run()` 메서드 사용\n",
    "    * `tf.Tensor` 객체 : `eval()` 메서드 사용\n",
    "        * 실제 `eval()` 메서드에서 하는 작업 : 디폴트 세션의 `run()` 메서드 호출\n",
    "* 세션은 `with` 블록이 끝나면 자동으로 종료된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 각 변수의 초기화를 일일히 실행하는 대신 `global_variables_initializer()` 함수를 사용할 수 있다.\n",
    "* 이 함수는 초기화를 바로 수행하지 않고 계산 그래프가 실행될 때 모든 변수를 초기화할 노드를 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer() # init 노드 준비\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run() # 실제 모든 변수 초기화\n",
    "    result = f.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 주피터나 파이썬 셸에서는 `InteractiveSession`을 만드는 편이 편리할 수 있다.\n",
    "* 일반적인 `Session`과 다른 점 : `InteractiveSession`이 만들어질 때 자동으로 자신을 기본 세션으로 지정한다.\n",
    "    * 그러므로 `with` 블록을 사용할 필요가 없다.\n",
    "    * 대신 사용이 끝났을 때는 수동으로 세션을 종료해주어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "init.run()\n",
    "result = f.eval()\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. 텐서플로 프로그램 구성\n",
    "텐서플로 프로그램은 두 부분으로 나뉜다.\n",
    "* **구성 단계** : 계산 그래프를 만든다.\n",
    "    * 훈련에 필요한 계산과 머신러닝 모델을 표현한 계산 그래프를 만든다.\n",
    "* **실행 단계** : 이 그래프를 실행한다.\n",
    "    * 훈련 스텝을 반복해서 평가하고(예를 들면 미니배치마다 한 스텝씩), 모델 파라미터를 점진적으로 개선하기 위해 반복 루프를 수행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 계산 그래프 관리\n",
    "노드를 만들면 자동으로 기본 계산 그래프에 추가된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대부분의 경우 이것으로 충분하지만 독립적인 그래프를 여러 개 만들 경우가 생긴다.  \n",
    "이 때는 새로운 Graph 객체를 만들어 `with` 블록 안에서 임시로 이를 기본 계산 그래프로 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "    \n",
    "x2.graph is graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **TIP**  \n",
    "주피터 (또는 파이썬 셸)에서 실험적인 작업을 하는 동안에는 같은 명령을 여러 번 실행하는 경우가 많다.  \n",
    "이렇게 하면 기본 그래프에 중복된 노드가 많이 포함된다.  \n",
    "주피터 커널 (또는 파이썬 셸)을 다시 시작하는 것이 한 가지 해법이지만, 더 편리한 방법은 `tf.reset_default_graph()`로 기본 그래프를 초기화해주는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 노드 값의 생애주기\n",
    "한 노드를 평가할 때 텐서플로는 이 노드가 의존하고 있는 다른 노드들을 자동으로 찾아 먼저 평가한다.\n",
    "> * 텐서플로 변수는 초기화를 위한 노드가 따로 있다.\n",
    "* `tf.constant`로 만들어진 상수는 노드 자체에 값을 지니고 있으며 변경 불가능하다.\n",
    "\n",
    "1. 매우 간단한 그래프를 정의한 다음 세션을 시작하고 `y`를 평가하기 위해 계산 그래프를 실행한다.\n",
    "    * 텐서플로는 자동으로 `y`가 `x`에 의존한다는 것과 `x`가 `w`에 의존한다는 것을 감지한다.  \n",
    "2. 먼저 `w`를 평가하고 그 다음에 `x`를, 그 다음에 `y`를 평가해서 `y`값을 반환한다.\n",
    "3. 마지막으로 `z`를 평가하기 위해 그래프를 실행한다.\n",
    "4. 다시 한번 텐서플로는 먼저 `w`와 `x`를 평가해야 한다는 것을 감지한다.\n",
    "    * 이 때 이전에 평가된 `w`와 `x`를 재사용하지 않는다.\n",
    "    * 즉 위 코드는 `w`와 `x`를 두 번 평가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval())\n",
    "    print(z.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모든 노드의 값은 계산 그래프 실행 간에 유지되지 않는다.\n",
    "* 변숫값은 예외로, 그래프 실행 간에도 세션에 의해 유지된다(큐(queue)와 리더(reader)도 일부 상태를 유지한다(12장 참고)).\n",
    "* 변수는 초기화될 때 일생이 시작되고 세션이 종료될 때까지 남아있다.\n",
    "\n",
    "#### 효율적으로 평가하기\n",
    "* 이전 코드처럼 `w`와 `x`를 두 번 평가하지 않고 `y`와 `z`를 효율적으로 평가하려면 한 번의 그래프 실행에서 `y`와 `z`를 모두 평가하도록 만들어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    y_val, z_val = sess.run([y, z])\n",
    "    print(y_val)\n",
    "    print(z_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **CAUTION**  \n",
    "* 단일 프로세스 텐서플로 : 같은 그래프를 재사용하더라도 여러 세션에서 어떤 상태도 공유하지 않는다.\n",
    "    * 각 세션은 모든 변수에 대해 고유한 복사본을 가진다.\n",
    "* 분산 텐서플로 : 변수 상태가 세션이 아니라 서버에 저장되므로 여러 세션이 같은 변수를 공유할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 텐서플로를 이용한 선형 회귀\n",
    "* 텐서플로 연산(operation, 줄여서 ops) : 여러 개의 입력을 받아 출력을 만들 수 있다.\n",
    "* 소스 연산(source ops) : 상수와 변수 연산은 입력이 없다. 이러한 것\n",
    "* 입력과 출력은 **텐서**(tensor)라는 다차원 배열이다.\n",
    "* 텐서는 데이터타입과 크기를 가지며 파이썬 API에서 텐서는 Numpy `ndarray`로 나타난다.\n",
    "> 텐서를 평가한 결과가 Numpy 배열로 반환된다.\n",
    "* 보통은 실수로 채워지지만 문자열(임의의 바이트 배열)을 저장할 수도 있다.\n",
    "\n",
    "#### 스칼라가 아닌 배열을 가지는 텐서의 연산\n",
    "캘리포니아 주택 가격 데이터셋에 선형회귀를 수행하기 위해 2D 배열을 다루기\n",
    "1. 먼저 데이터셋을 추출하고 모든 훈련 샘플에 편향에 대한 입력 특성($x_0 = 1$)을 추가한다(이 부분은 numpy를 사용하므로 즉시 실행된다).\n",
    "2. 두 개의 텐서플로 상수 노드 `X`, `y`를 만들고 데이터와 타깃을 담는다.\n",
    "> `theta`를 계산하기 위해 `housing.target`을 열 벡터로 변경  \n",
    "`reshape`의 차원 하나를 `-1`(\"정의되지 않았음\")로 지정할 수 있고, 다른 차원과 배열의 길이에 따라 결정된다.\n",
    "3. 텐서플로에서 행렬 연산을 사용해 `theta`를 정의한다.\n",
    "    * `transpose()`, `matmul()`, `matrix_inverse()` 이 함수들은 계산을 즉각 수행하지 않는다. 대신 그래프가 실행될 때 계산을 수행할 노드를 생성한다.\n",
    "    * 정규방정식 $\\hat \\theta = (X^T \\cdot X)^{-1} \\cdot X^T \\cdot y)$\n",
    "> 파이썬 3.5이상에서는 점곱 `matmul()`을 `@`연산자로 대신 사용할 수 있다.\n",
    "4. 세션을 만들고 `theta`를 평가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.7185181e+01],\n",
       "       [ 4.3633747e-01],\n",
       "       [ 9.3952334e-03],\n",
       "       [-1.0711310e-01],\n",
       "       [ 6.4479220e-01],\n",
       "       [-4.0338000e-06],\n",
       "       [-3.7813708e-03],\n",
       "       [-4.2348403e-01],\n",
       "       [-4.3721911e-01]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing['data'].shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing['data']]\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name='X')\n",
    "y = tf.constant(housing['target'].reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "    \n",
    "theta_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정규방정식을 Numpy로 직접 계산하지 않고 위 코드를 사용하는 장점\n",
    "* GPU가 있는 경우 텐서플로가 자동으로 이 코드를 GPU에서 실행한다(GPU버전의 텐서플로 설치 필요, 12장 참조)\n",
    "    > `np.c_`는 Numpy의 `CClass` 객체로서 `hstack()` 함수와 비슷하지만 나열된 배열을 열 방향으로 합칠 때 배열의 차원을 2차원으로 늘려준다.  \n",
    "    따라서 `np.c_[np.ones((m, )), housing.data]`같이 쓸 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numpy와 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.69419202e+01],\n",
       "       [ 4.36693293e-01],\n",
       "       [ 9.43577803e-03],\n",
       "       [-1.07322041e-01],\n",
       "       [ 6.45065694e-01],\n",
       "       [-3.97638942e-06],\n",
       "       [-3.78654265e-03],\n",
       "       [-4.21314378e-01],\n",
       "       [-4.34513755e-01]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = housing_data_plus_bias\n",
    "y = housing['target'].reshape(-1, 1)\n",
    "theta_numpy = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "theta_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scikit-learn과 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.69419202e+01],\n",
       "       [ 4.36693293e-01],\n",
       "       [ 9.43577803e-03],\n",
       "       [-1.07322041e-01],\n",
       "       [ 6.45065694e-01],\n",
       "       [-3.97638942e-06],\n",
       "       [-3.78654265e-03],\n",
       "       [-4.21314378e-01],\n",
       "       [-4.34513755e-01]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing['data'], housing['target'].reshape(-1, 1))\n",
    "np.r_[lin_reg.intercept_.reshape(-1, 1), lin_reg.coef_.T]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 경사 하강법 구현\n",
    "1. 먼저 gradient를 수동으로 계산해보고 그 다음에 텐서플로의 자동 미분 기능을 사용해 gradient를 자동으로 계산해보기  \n",
    "2. 마지막으로 텐서플로에 내장된 옵티마이저(optimizer) 사용해보기\n",
    "> 여기서 옵티마이저는 `tf.train.Optimizer` 클래스를 상속하여 구현된 것들을 총칭한다.\n",
    "\n",
    "> **CAUTION**  \n",
    "경사 하강법 사용 시 입력 특성 벡터 정규화가 중요하다. 그렇지 않으면 훈련속도가 매우 느려진다.  \n",
    "정규화는 텐서플로, 넘파이, 사이킷런 `StandardScaler`, 선호하는 다른 도구를 사용해도 가능하다.  \n",
    "\n",
    "> 정규화는 입력 특성의 스케일을 비슷하게 맞추어주므로, 경사 하강법에서 전역 최솟값으로 빠르게 수렴할 수 있도록 도와준다.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scikit-learn을 이용한 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.00000000e+00  6.60969987e-17  5.50808322e-18  6.60969987e-17\n",
      " -1.06030602e-16 -1.10161664e-17  3.44255201e-18 -1.07958431e-15\n",
      " -8.52651283e-15]\n",
      "[ 0.38915536  0.36424355  0.5116157  ... -0.06612179 -0.06360587\n",
      "  0.01359031]\n",
      "0.11111111111111005\n",
      "(20640, 9)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]\n",
    "\n",
    "print(scaled_housing_data_plus_bias.mean(axis=0))\n",
    "print(scaled_housing_data_plus_bias.mean(axis=1))\n",
    "print(scaled_housing_data_plus_bias.mean())\n",
    "print(scaled_housing_data_plus_bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. 직접 그래디언트 계산\n",
    "* `random_uniform()` : 난수를 담은 텐서를 생성하는 노드를 그래프에 생성한다.\n",
    "    * Numpy의 `rand()`처럼 크기와 난수의 범위를 입력받는다.\n",
    "* `reduce_mean()` : 텐서의 평균을 계산하는 노드를 그래프에 추가한다.\n",
    "* `assign()` : 변수에 새로운 값을 할당하는 노드를 생성한다.  \n",
    "여기서는 배치 경사 하강법의 스텝 $\\theta^{next \\mbox{ } step} = \\theta - \\eta\\nabla_\\theta MSE(\\theta)$\n",
    "* 반복 루프는 훈련 단계를 계속 반복해서 실행하고(`n_epoch`만큼), 100번 반복마다 현재의 평균 제곱 에러(`mse` 변수)를 출력한다.\n",
    "    * MSE는 매 반복에서 값이 줄어들어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 0 MSE = 14.772638\n",
      "에포크 100 MSE = 0.96464515\n",
      "에포크 200 MSE = 0.68937033\n",
      "에포크 300 MSE = 0.64019346\n",
      "에포크 400 MSE = 0.60823655\n",
      "에포크 500 MSE = 0.5852422\n",
      "에포크 600 MSE = 0.56859726\n",
      "에포크 700 MSE = 0.556536\n",
      "에포크 800 MSE = 0.54778975\n",
      "에포크 900 MSE = 0.5414423\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name='X')\n",
    "y = tf.constant(housing['target'].reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name='theta')\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"에포크\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "        \n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0685523 ],\n",
       "       [ 0.80584   ],\n",
       "       [ 0.15618882],\n",
       "       [-0.14223817],\n",
       "       [ 0.16928521],\n",
       "       [ 0.00942415],\n",
       "       [-0.041986  ],\n",
       "       [-0.6493025 ],\n",
       "       [-0.6133993 ]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. 자동 미분 사용\n",
    "### 5.2.1. 앞의 코드처럼 직접 코드로 미분하는 경우\n",
    "* 비용 함수(MSE)의 그래디언트를 수학적으로 유도해야 한다.\n",
    "* 심층 신경망에서는 이 과정이 쉽지 않을 수 있다.  \n",
    "\n",
    "### 5.2.2.  **기호 미분**(symbolic differentiation)을 사용한 경우\n",
    "* 자동으로 편미분 방정식을 구할 수 있다.\n",
    "* 하지만 결과 코드의 효율이 몹시 나쁠 수 있다.\n",
    "    \n",
    "#### $f(x) = exp(exp(exp(x)))$로 효율이 나쁜 이유 알아보기\n",
    "* 편미분 $f'(x) = exp(x) \\times exp(exp(x)) \\times exp(exp(exp(x)))$\n",
    "* $f(x)$와 $f'(x)$를 각각 있는 그대로 사용하면 코드가 효율적이지 않다.\n",
    "* 더 효율적인 방법은 먼저 $exp(x)$를 계산하고, 그 다음에 $exp(exp(x)$를 계산하고, 그 다음에 $exp(exp(exp(x)))$를 계산해서 이 3가지를 모두 반환하는 함수를 만드는 것이다.\n",
    "* 이 함수를 사용하면 $f(x)$를 바로 (세 번째 항으로) 계산할 수 있고 편미분이 필요하면 이 세 항을 모두 곱해서 구할 수 있다.\n",
    "* 무식한 방법으로 $f(x)$와 $f'(x)$를 계산하면 $exp$ 함수를 9번 호출해야 하지만, 이 방법을 사용하면 3번만 호출하면 된다.\n",
    "\n",
    "#### 더 심각한 경우\n",
    "* 함수가 임의의 코드로 작성되어 있다면 상황은 더 심각해진다.\n",
    "* 아래 함수의 편미분을 계산하기 위한 식(또는 코드)를 찾을 수 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func(a, b):\n",
    "    z = 0\n",
    "    for i in range(100):\n",
    "        z = a * np.cos(z + i) + z * np.sin(b - i)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.21253923284754914"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_func(0.2, 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.3. 텐서플로 자동 미분 기능을 이용한 경우\n",
    "위와 같은 문제를 해결해준다. 이 기능은 자동으로 그리고 효율적으로 그래디언트를 계산한다.\n",
    "* 그래디언트를 구하는 부분만 바꿔주면 된다.\n",
    "* `gradients()` : 하나의 연산(여기서는 `mse`)과 변수 리스트(여기서는 `theta` 하나)를 받아 각 변수에 대한 연산의 그래디언트를 계산하는 새로운 연산을 만든다.(변수당 하나씩)\n",
    "* 그러므로 `gradients` 노드는 `theta`에 대한 MSE의 그래디언트 벡터를 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 0 MSE = 10.592645\n",
      "에포크 100 MSE = 0.6994553\n",
      "에포크 200 MSE = 0.5719243\n",
      "에포크 300 MSE = 0.5573525\n",
      "에포크 400 MSE = 0.54831356\n",
      "에포크 500 MSE = 0.54179937\n",
      "에포크 600 MSE = 0.5370738\n",
      "에포크 700 MSE = 0.5336407\n",
      "에포크 800 MSE = 0.5311441\n",
      "에포크 900 MSE = 0.5293267\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name='X')\n",
    "y = tf.constant(housing['target'].reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name='theta')\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "\n",
    "# gradients = 2/m * tf.matmul(tf.transpose(X), error) \n",
    "# 바뀌는 부분\n",
    "gradients = tf.gradients(mse, [theta])[0] \n",
    "\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"에포크\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "        \n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 자동 미분으로 `a`와 `b`에 대한 `my_func()` 함수의 편도함수 구하기\n",
    "$a=0.2$와 $b=0.3$일 때 함수 값을 계산하고 그 다음 $a$와 $b$에 대한 편미분을 구한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.21253741\n",
      "[-1.1388494, 0.19671395]\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(0.2, name='a')\n",
    "b = tf.Variable(0.3, name='b')\n",
    "z = tf.constant(0.0, name='z0')\n",
    "\n",
    "for i in range(100):\n",
    "    z = a * tf.cos(z + i) + z * tf.sin(b - i)\n",
    "    \n",
    "grads = tf.gradients(z, [a, b])\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    print(z.eval())\n",
    "    print(sess.run(grads))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.4. 자동으로 그래디언트를 계산하는 방법 정리\n",
    "* 자동으로 그래디언트를 계산하는 방법은 4가지이다.\n",
    "\n",
    "| 기법 | 모든 그래디언트를 계산하기 위한 그래프 순회 수 | 정확도 | 임의의 코드 지원 | 비고 |\n",
    "|------|------------------------------------------------|--------|------------------|------|\n",
    "| 수치미분 | $n_{inputs} + 1$ | 낮음 | 지원 | 구현하기 쉬움 |\n",
    "| 기호미분 | 해당 없음 | 높음 | 미지원 | 상이한 그래프 생성 |\n",
    "| 전진 모드 자동 미분 | $n_{inputs}$ | 높음 | 지원 | 이원수(dual number) 사용 |\n",
    "| 후진 모드 자동 미분 | $n_{outputs} + 1$ | 높음 | 지원 | 텐서플로가 사용하는 방식 |\n",
    "\n",
    "* 텐서플로는 **후진 모드 자동 미분**(reverse-mode autodiff)를 사용하며 신경망에서처럼 입력이 많고 출력이 적을 때 완벽한(효율적이고 정확한) 방법이다.\n",
    "* 모든 입력에 대한 출력의 편미분을 $n_{outputs} + 1$ 그래프 순회 안에 모두 계산한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. 옵티마이저 사용\n",
    "* 텐서플로는 경사 하강법 옵티마이저를 포함하여 여러 가지 내장 옵티마이저를 제공한다. \n",
    "    * 텐서플로의 자동 그래디언트 계산보다 더 쉬운 방법이다.\n",
    "* `gradients = ...`와 `training_op = ...` 코드만 바꾸면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 0 MSE = 3.4576716\n",
      "에포크 100 MSE = 0.6180698\n",
      "에포크 200 MSE = 0.54878557\n",
      "에포크 300 MSE = 0.5419552\n",
      "에포크 400 MSE = 0.538383\n",
      "에포크 500 MSE = 0.5356584\n",
      "에포크 600 MSE = 0.53349864\n",
      "에포크 700 MSE = 0.5317748\n",
      "에포크 800 MSE = 0.5303924\n",
      "에포크 900 MSE = 0.5292792\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name='X')\n",
    "y = tf.constant(housing['target'].reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name='theta')\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "\n",
    "# gradients = 2/m * tf.matmul(tf.transpose(X), error) \n",
    "# gradients = tf.gradients(mse, [theta])[0] \n",
    "# training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "# 바뀌는 부분\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"에포크\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "        \n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0685525 ],\n",
       "       [ 0.91043264],\n",
       "       [ 0.12519866],\n",
       "       [-0.43449146],\n",
       "       [ 0.4525745 ],\n",
       "       [-0.00320723],\n",
       "       [-0.04159459],\n",
       "       [-0.77699476],\n",
       "       [-0.75784343]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모멘텀 옵티마이저 사용하기\n",
    "* 모멘텀(momentum) 옵티마이저를 사용하려면 `optimizer = ...` 코드만 바꾸면 된다.\n",
    "* 종종 경사 하강법보다 빠르게 수렴한다. (11장 참조)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 0 MSE = 12.408011\n",
      "에포크 100 MSE = 0.5252007\n",
      "에포크 200 MSE = 0.5243332\n",
      "에포크 300 MSE = 0.5243213\n",
      "에포크 400 MSE = 0.52432084\n",
      "에포크 500 MSE = 0.524321\n",
      "에포크 600 MSE = 0.5243211\n",
      "에포크 700 MSE = 0.52432096\n",
      "에포크 800 MSE = 0.52432096\n",
      "에포크 900 MSE = 0.52432096\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name='X')\n",
    "y = tf.constant(housing['target'].reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name='theta')\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "\n",
    "# gradients = 2/m * tf.matmul(tf.transpose(X), error) \n",
    "# gradients = tf.gradients(mse, [theta])[0] \n",
    "# training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "# 바뀌는 부분\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)\n",
    "\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"에포크\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "        \n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.068558  ],\n",
       "       [ 0.8296182 ],\n",
       "       [ 0.11875144],\n",
       "       [-0.26552498],\n",
       "       [ 0.3056947 ],\n",
       "       [-0.00450307],\n",
       "       [-0.03932622],\n",
       "       [-0.89988816],\n",
       "       [-0.8705434 ]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 훈련 알고리즘에 데이터 주입\n",
    "* 미니배치 경사 하강법을 구현하려면 매 반복에서 `X`와 `y`를 다음번 미니배치로 바꿔야 한다.\n",
    "* 가장 간단한 방법은 **플레이스홀더**(placeholder) 노드를 사용하는 것이다.\n",
    "* 플레이스 홀더 노드: 실제로 아무 계산도 하지 않는 특수한 노드\n",
    "    * 실행 시에 주입한 데이터를 출력하기만 한다.\n",
    "    * 전형적으로 훈련동안 텐서플로에 훈련 데이터를 전달하기 위해 사용된다.\n",
    "    * 실행 시 플레이스홀더에 값을 지정하지 않으면 예외가 발생한다.\n",
    "    * `placeholder()` 함수로 플레이스홀더 노드를 만들고, 훌력 텐서의 데이터 타입을 지정해야 한다.\n",
    "        * 크기를 지정할 수도 있다.\n",
    "        * 차원을 `None`으로 설정하면 어떤 크기도 가능하다는 의미\n",
    "        \n",
    "#### placeholder 노드 사용하기\n",
    "1. 플레이스홀더 노드 `A`와 `B`를 만든다.\n",
    "2. `B`를 평가할 때 `eval()` 메서드에 `feed_dict` 매개변수로 `A`의 값을 전달한다.\n",
    "    * `A`는 랭크(rank)가 2(2차원)이고 열은 3개 이어야 한다 (그렇지 않으면 예외가 발생한다.)\n",
    "    > 텐서플로의 랭크는 배열의 차원을 말한다.  \n",
    "    스칼라의 랭크 : 0, 벡터 : 1, 행렬 : 2  \n",
    "    수학의 행렬에서 선형 독립인 행/열을 나타내는 계수(rank)와 무관하다.\n",
    "    * 행의 개수는 상관없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6., 7., 8.]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "A = tf.placeholder(tf.float32, shape=(None, 3))\n",
    "B = A + 5\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    B_val_1 = B.eval(feed_dict={A: [[1, 2, 3]]})\n",
    "    B_val_2 = B.eval(feed_dict={A: [[4, 5, 6], [7, 8, 9]]})\n",
    "    \n",
    "B_val_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9., 10., 11.],\n",
       "       [12., 13., 14.]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_val_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **NOTE**  \n",
    "실제로는 플레이스홀더뿐만 아니라 어떤 연산의 출력값도 주입할 수 있다.  \n",
    "이런 경우 텐서플로는 이 연산을 평가하지 않고 주입된 값을 사용한다.\n",
    "* 예를 들어 신경망의 은닉층에 캐싱된 결과를 주입하기 위해 사용한다 (11장 참조)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 미니배치 경사 하강법 구현\n",
    "1. 기존 코드의 구성 단계에서 `X`, `y` 정의를 플레이스홀더 노드로 변경한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name='X')\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name='y')\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1], -1.0, 1.0, seed=42), name='theta')\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 그런 다음 배치 크기와 전체 배치 횟수를 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size)) # m, n = housing.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 실행 단계에서 `X`, `y`에 의존하는 노드를 평가할 때 미니배치를 하나씩 추출하여 `feed_dict` 매개변수로 전달한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch * n_batches + batch_index)\n",
    "    indices = np.random.randint(m, size=batch_size)\n",
    "    X_batch = scaled_housing_data_plus_bias[indices]\n",
    "    y_batch = housing.target.reshape(-1, 1)[indices]\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0703337 ],\n",
       "       [ 0.8637145 ],\n",
       "       [ 0.12255151],\n",
       "       [-0.31211874],\n",
       "       [ 0.38510373],\n",
       "       [ 0.00434168],\n",
       "       [-0.01232954],\n",
       "       [-0.83376896],\n",
       "       [-0.8030471 ]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            \n",
    "    best_theta = theta.eval()\n",
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **NOTE**  \n",
    "`theta`는 `X`, `y`에 의존하지 않으므로 `theta`를 평가할 때는 `X`, `y`값을 전달할 필요가 없다.\n",
    "* `theta`는 변수로 정의되었으므로 의존하고 있는 노드가 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 모델 저장과 복원\n",
    "\n",
    "## 7.1. 모델 저장\n",
    "* 모델 파라미터를 디스크에 저장하거나 훈련하는 동안 일정한 간격으로 체크포인트(checkpoint)를 저장하여 훈련 중간에 문제를 일으켰을 때 체크포인트부터 이어나갈 수 있다.\n",
    "* 구성 단계의 끝에서 (모든 변수 노드를 생성한 후) `Saver` 노드를 추가하고, 실행 단계에서 모델을 저장하고 싶을 때 `save()` 메서드에 세션과 체크포인트 파일의 경로를 전달하여 호출하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 :  0 MSE =  9.161543\n",
      "에포크 :  100 MSE =  0.7145006\n",
      "에포크 :  200 MSE =  0.566705\n",
      "에포크 :  300 MSE =  0.5555719\n",
      "에포크 :  400 MSE =  0.5488112\n",
      "에포크 :  500 MSE =  0.5436362\n",
      "에포크 :  600 MSE =  0.5396294\n",
      "에포크 :  700 MSE =  0.5365092\n",
      "에포크 :  800 MSE =  0.5340678\n",
      "에포크 :  900 MSE =  0.5321474\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name='X')\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1], -1.0, 1.0, seed=42), name='theta')\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print('에포크 : ', epoch, 'MSE = ', mse.eval())\n",
    "            save_path = saver.save(sess, './tmp/my_model.ckpt')\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(sess, './tmp/my_model_final.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0685525 ],\n",
       "       [ 0.8874027 ],\n",
       "       [ 0.14401658],\n",
       "       [-0.34770882],\n",
       "       [ 0.36178368],\n",
       "       [ 0.00393811],\n",
       "       [-0.04269556],\n",
       "       [-0.6614528 ],\n",
       "       [-0.6375277 ]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. 모델 복원\n",
    "* 이전과 마찬가지로 구성 단계 끝에서 `Saver` 노드를 생성하고 실행 단계를 시작할 때 `init` 노드를 사용하여 변수를 초기화하는 대신 `Saver` 객체의 `restore()` 메서드를 호출한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tmp/my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './tmp/my_model_final.ckpt')\n",
    "    best_theta_restored = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(best_theta, best_theta_restored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3. 별도의 이름을 사용한 저장/복원\n",
    "* `Saver`는 기본적으로 모든 변수를 각자의 이름으로 저장하고 복원한자.\n",
    "* 하지만 저장/복원할 변수를 지정하거나 별도의 이름을 사용할 수 있다.\n",
    "\n",
    "#### 별도 이름으로 저장\n",
    "아래 `Saver`는 `theta` 변수만 `weights`란 이름으로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver({'weights': theta})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `save()` 메서드는 기본적으로 .meta 확장자 파일에 그래프의 구조를 저장한다.\n",
    "* `tf.train.import_meta_graph()`를 사용해 이 그래프 구조를 읽어 들일 수 있다.\n",
    "* 이 그래프는 기본 그래프로 추가되며, 반환된 `Saver` 인스턴스로 그래프의 상태(즉, 변수값)를 복원하는 데 이용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tmp/my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "reset_graph() # 빈 그래프로 시작\n",
    "\n",
    "# 그래프 구조 로드\n",
    "saver = tf.train.import_meta_graph('./tmp/my_model_final.ckpt.meta')\n",
    "theta = tf.get_default_graph().get_tensor_by_name('theta:0')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './tmp/my_model_final.ckpt') # 그래프의 상태(변수값) 로드\n",
    "    best_theta_restored = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(best_theta, best_theta_restored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 하면 원래 만들었던 코드를 찾아보지 않고도 그래프 구조와 변숫값을 포함해 저장된 모델을 완벽하게 복원할 수 있다.\n",
    "> `sess.run()` 함수에 텐서나 연산 객체를 전달할 수도 있지만 텐서나 연산의 이름을 넣어 실행할 수도 있다.  \n",
    "예를 들어 이름이 'X'인 변수 `x`를 출력하려면 `sess.run(x ...)`도 가능하지만  `sess.run('X:0', ...)`도 같은 결과를 낸다.  \n",
    "그래프 구성을 독립된 파이썬 모듈에 정의하거나 저장된 그래프를 읽어 들인다면 그래프를 구성할 때 지정한 이름을 사용해 텐서를 얻어오거나 `sess.run('y_pred:0', ...)`과 같이 직접 연산을 실행시킬 수 있다.(11장 참조)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. 텐서보드로 그래프와 학습 곡선 시각화하기\n",
    "\n",
    "#### 텐서보드 사용하기\n",
    "1. 먼저 그래프 정의와 훈련 통계(예. 훈련 에러(MES))를 텐서보드가 읽을 수 있는 로그 디렉토리에 쓰도록 프로그램을 조금 수정해야 한다.\n",
    "    * 프로그램을 실행할 때마다 다른 로그 디렉토리를 사용해야 한다. \n",
    "        * 그렇지 않으면 프로그램을 실행할 때마다 만들어진 통계가 합쳐져서 텐서보드 그래프가 엉망이 될 것이다.\n",
    "        * 로그 디렉토리 이름에 타임스탬프를 포함하면 간단히 해결된다.\n",
    "    * 프로그램 서두에 아래 코드를 추가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime('%Y%m%d%H%M%S')\n",
    "root_logdir = 'tf_logs'\n",
    "logdir = '{}/run-{}'.format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 구성 단계의 가장 마지막에 다음 코드를 추가한다.\n",
    "    1. MSE 값을 평가하고 그것을 **서머리**(summary)를 쓰기 위한 노드를 그래프에 추가한다.\n",
    "        * 서머리 : 텐서보드가 인식하는 이진 로그 문자열\n",
    "    2. `FileWriter` 객체를 만들어 로그 디렉토리에 있는 로그 파일에 서머리를 기록한다.\n",
    "        * 첫 번째 매개변수 : 로그 디렉토리 경로\n",
    "        * 두 번째 매개변수(옵션) : 시각화하고자 하는 계산 그래프\n",
    "        > 두 번째 매개변수를 지정하지 않고 `file_writer.add_graph()` 메서드를 통해 그래프를 지정해도 된다.\n",
    "        * `FileWriter`가 생성될 때 로그 디렉토리가 존재하지 않으면 새로 만들고(필요하면 부모 디렉토리도), **이벤트 파일**(event file)이라 불리는 이진 로그 파일에 그래프의 정의를 기록한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 실행 단계에서 훈련하는 동안 `mse_summary` 노드를 정기적으로(예. 미니배치 10회마다) 평가하도록 수정해야 한다.\n",
    "    * 이렇게 만들어진 서머리는 `file_writer`를 사용해 이벤트 파일에 기록할 수 있다.\n",
    "    > * `add_summary()` 메서드의 첫 번째 매개변수 : 서머리 노드의 평가 결과를 입력한다.\n",
    "     * 두 번째 매개변수 : 훈련 스텝을 입력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **CAUTION**  \n",
    "훈련 스텝마다 통계를 기록하면 훈련 속도가 많이 느려지므로 피해야 한다.\n",
    "\n",
    "4. 마지막으로 프로그램 끝에서 `FileWriter` 객체를 닫는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0703337 ],\n",
       "       [ 0.8637145 ],\n",
       "       [ 0.12255151],\n",
       "       [-0.31211874],\n",
       "       [ 0.38510373],\n",
       "       [ 0.00434168],\n",
       "       [-0.01232954],\n",
       "       [-0.83376896],\n",
       "       [-0.8030471 ]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_writer.close()\n",
    "\n",
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 이 프로그램을 실행할 때마다 로그 디렉토리를 만들고 그 안에 이벤트 파일을 생성해 그래프의 정의와 MSE 값을 기록할 것이다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 텐서보드 서버 실행하기\n",
    "1. `vritualenv` 환경을 만들었다면 이를 활성화하고 최상위 로그 디렉토리를 옵션으로 주어 `tensorboard` 명령을 실행해 서버를 시작시킨다.\n",
    "    * 터미널에서 로그 디렉토리가 있는 경로로 이동해서 \n",
    "        * `source env/bin/activate`\n",
    "        * `tensorboard --logdir tf_logs/`\n",
    "    * 그러면 텐서보드 서버가 포트 6006에서 시작된다.\n",
    "2. 브라우저에서 http://0.0.0.0:6006/ (또는 http://localhost:6006/)에 접속한다.\n",
    "\n",
    "#### 텐서보드 그래프\n",
    "* 간단하게 표현하기 위해 **에지**(연결선)가 많은 노드는 오른쪽의 보조 영역에 나뉘어 있다.\n",
    " \n",
    "#### 주피터 노트북에서 그래프 나타내기\n",
    "* 주피터에 직접 그리려면 아래 `show_graph()` 함수를 사용하면 된다.\n",
    "\n",
    "> **TIP**\n",
    "* 주피터 노트북에서 그래프를 나타내기 위해 https://tensorboard.appspot.com/ 에 서비스 중인 텐서보드 서버를 사용한다(즉, 인터넷 연결이 안되면 작동되지 않습니다).   \n",
    "원래 알렉산더 모드빈치세프(Alexander Mordvintsev)가 딥드림(deepdream) 튜토리얼 노트북에 포함된 것이다(http://goo.gl/EtCWUc).  \n",
    "* 다른 방법으로 그래프 시각화를 위한 주피터 확장 기능을 포함한 에릭 장(Eric Jang)의 텐서플로 디버거 도구(https://github.com/ericjang/tdb)를 설치하는 것이다.\n",
    "    * tdb는 업데이트가 잘 안되고 있어 디버깅을 위해서는 텐서플로 공식 디버거 tfdbg(https://goo.gl/dFCzdy)를 사용하는 것이 좋다.\n",
    "* 또는 tfgraphviz(https://github.com/akimach/tfgraphviz)를 사용할 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_graph_in_jupyter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-95d096a8a0fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_graph_in_jupyter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshow_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mshow_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_defalut_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_graph_in_jupyter'"
     ]
    }
   ],
   "source": [
    "from tensorflow_graph_in_jupyter import show_graph\n",
    "\n",
    "show_graph(tf.get_defalut_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. 이름 범위\n",
    "* 신경망처럼 복잡한 모델을 다룰 때는 계산 그래프가 수천 개의 노드로 인해 어질러지기 쉽다. 이를 피하려면 **이름 범위**(name scope)를 만들어 관련 있는 노드들을 그룹으로 묶어야 한다.\n",
    "\n",
    "#### 이전 코드를 수정해 \"loss\" 이름 범위 안에 있는 `error`, `mse` 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss') as scope:\n",
    "    error = y_pred - y\n",
    "    mse = tf.reduce_mean(tf.square(error), name='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_theta:\n",
      "[[ 2.0703337 ]\n",
      " [ 0.8637145 ]\n",
      " [ 0.12255151]\n",
      " [-0.31211874]\n",
      " [ 0.38510373]\n",
      " [ 0.00434168]\n",
      " [-0.01232954]\n",
      " [-0.83376896]\n",
      " [-0.8030471 ]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "    best_theta = theta.eval()\n",
    "\n",
    "file_writer.flush()\n",
    "file_writer.close()\n",
    "print(\"best_theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 이 범위 안에 있는 모든 연산의 이름에는 `loss/` 접두사가 붙는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss/sub\n",
      "loss/mse\n"
     ]
    }
   ],
   "source": [
    "print(error.op.name)\n",
    "print(mse.op.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 텐서보드에서 기본으로 접혀있는 loss 이름 범위 안에 mse, sub 노드가 나타난다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. 모듈화\n",
    "#### 두 개의 ReLU 출력을 더하는 그래프를 만든다고 가정\n",
    "* **ReLU**(rectified linear unit) : 입력에 대한 선형 함수로서 양수는 그대로 출력하고, 음수일 때는 0을 출력한다.\n",
    "* ReLU 함수  \n",
    "$$ h_{w, b}(X) = max(X \\cdot w + b, 0) $$\n",
    "\n",
    "\n",
    "* 아래 코드는 ReLU 구현 방식을 설명하기 위해 직접 `maximum()` 함수를 사용했다.  \n",
    "실전에서는 텐서플로가 제공하는 `tf.nn.relu()` 함수를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name='X')\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal((n_features, 1)), name='weights1')\n",
    "w2 = tf.Variable(tf.random_normal((n_features, 1)), name='weights2')\n",
    "b1 = tf.Variable(0.0, name='bias1')\n",
    "b2 = tf.Variable(0.0, name='bias2')\n",
    "\n",
    "z1 = tf.add(tf.matmul(X, w1), b1, name='z1')\n",
    "z2 = tf.add(tf.matmul(X, w2), b2, name='z2')\n",
    "\n",
    "relu1 = tf.maximum(z1, 0., name='relu1')\n",
    "relu2 = tf.maximum(z2, 0., name='relu2')\n",
    "\n",
    "output = tf.add(relu1, relu2, name='output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 이런 반복적인 코드는 유지 보수하기 어렵고 에러가 발생하기 쉽다.  \n",
    "ReLU 함수를 더 추가해야 한다면 상황은 더 심각해진다.\n",
    "\n",
    "텐서플로에서 DRY(Don't Repeat Yourself) 원칙을 유지하게 도와준다. 간단하게 ReLU를 구현하는 함수를 만들면 된다.\n",
    "> 보통 ReLU 함수는 위 수학식의 구현을 의미하지만 이 `relu()` 함수는 예제를 위해서 선형방정식 $w \\times x + b$의 계산을 포함한 것이다.\n",
    "\n",
    "#### 다섯 개의 ReLU를 생성해서 합을 계산하기\n",
    "* `add_n()` : 텐서의 리스트를 받아 합을 계산하는 연산 노드를 만든다.\n",
    "> `add_n()`은 배열의 원소별로 더하므로 입력된 텐서들의 차원이 다르면 예외가 발생한다.  \n",
    "유사 함수로는 미분 가능하지 않지만 메모리 효율이 조금 더 나은 `accumulate_n()`이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X):\n",
    "    w_shape = (int(X.get_shape()[1]), 1)\n",
    "    w = tf.Variable(tf.random_normal(w_shape), name='weights')\n",
    "    b = tf.Variable(0.0, name='bias')\n",
    "    z = tf.add(tf.matmul(X, w), b, name='z')\n",
    "    return tf.maximum(z, 0., name='relu')\n",
    "\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name='X')\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer = tf.summary.FileWriter('logs/relu1', tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 노드가 생성될 때 텐서플로는 그 이름이 이미 존재하는지 확인한다. 만약 같은 이름이 존재하면 밑줄 다음에 숫자를 붙여 고유한 이름을 만든다.  \n",
    "그래서 첫 번째 ReLU는 \"weights\", \"bias\", \"z\", \"relu\"라는 이름의 노드를 포함한다.  \n",
    "두 번째 ReLU는 \"weights_1\", \"bias_1\", \"z_1\", \"relu_1\" 같은 이름의 노드를 포함한다.  \n",
    "텐서보드는 이런 노드 시리즈를 인식하고 하나로 합쳐 번잡함을 줄여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이름 범위 사용하여 그래프 훨씬 깔끔하게 표현하기\n",
    "`relu()` 함수 안의 내용을 모두 이름 범위 아래로 옮기면 된다.\n",
    "* 텐서플로는 이름 범위에 대해서도 고유한 이름을 위해 \"\\_1\", \"\\_2\" 등을 점미사로 붙인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X):\n",
    "    with tf.name_scope(\"relu\"):\n",
    "        w_shape = (int(X.get_shape()[1]), 1)                          \n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")    \n",
    "        b = tf.Variable(0.0, name=\"bias\")                             \n",
    "        z = tf.add(tf.matmul(X, w), b, name=\"z\")                      \n",
    "        return tf.maximum(z, 0., name=\"max\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")\n",
    "\n",
    "file_writer = tf.summary.FileWriter(\"logs/relu2\", tf.get_default_graph())\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. 변수 공유\n",
    "* 그래프의 여러 구성 요소 간에 변수를 공유하고 싶다면, 기본적으로 변수를 먼저 만들고 필요한 함수에 매개변수로 전달하는 것이다.\n",
    "\n",
    "#### ReLU의 임곗값 조정을 위한 `threshold` 변수를 모든 ReLU에서 공유"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X, threshold):\n",
    "    with tf.name_scope('relu'):\n",
    "        w_shape = (int(X.get_shape()[1]), 1)\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name='weights')\n",
    "        b = tf.Variable(0.0, name='bias')\n",
    "        z = tf.add(tf.matmul(X, w), b, name='z')\n",
    "        return tf.maximum(z, threshold, name='max')\n",
    "    \n",
    "threshold = tf.Variable(0.0, name='threshold')\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name='X')\n",
    "relus = [relu(X, threshold) for i in range(5)]\n",
    "output = tf.add_n(relus, name='output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 이렇게 해도 문제없이 작동한다. `threshold` 변수로 모든 ReLU 임곗값을 조정할 수 있다.  \n",
    "하지만 이런 공유 변수가 많으면 항상 매개변수로 전달해야 하므로 번거워진다.\n",
    "\n",
    "#### 변수 공유 또 다른 방식 1\n",
    "모델에 있는 모든 변수를 담을 파이썬 딕셔너리를 만들고 함수마다 이를 전달하는 방식을 사용한다.\n",
    "#### 변수 공유 또 다른 방식 2\n",
    "모듈화를 위해 파이썬 클래스를 만든다 (예. `ReLU` 클래스를 만들면 클래스 변수로 공유 매개변수를 대신할 수 있다.)\n",
    "#### 변수 공유 또 다른 방식 3\n",
    "`relu()`를 맨 처음 호출할 때 함수의 속성으로 다음과 같이 공유 변수를 지정하는 것\n",
    "> 파이썬은 모든 것이 객체라서 속성, 메서드를 가질 수 있다  \n",
    "* `hasattr()` : 어떤 객체의 속성이 정의되어 있는지 확인한다.\n",
    "* `setattr()` : 객체의 속성에 값을 지정한다.\n",
    "* 아래 코드처럼 속성에 값을 할당할 때 `setattr()` 대신 점 표기법(dot notation)을 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X):\n",
    "    with tf.name_scope(\"relu\"):\n",
    "        if not hasattr(relu, 'threshold'):\n",
    "            relu.threshold = tf.Variable(0.0, name='threshold')\n",
    "        w_shape = int(X.get_shape()[1]), 1                          \n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")  \n",
    "        b = tf.Variable(0.0, name=\"bias\")                           \n",
    "        z = tf.add(tf.matmul(X, w), b, name=\"z\")                    \n",
    "        return tf.maximum(z, relu.threshold, name=\"max\")\n",
    "    \n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1. 텐서플로에서 제공하는 더 깔끔하고 모듈화하기 좋은 방법\n",
    "* 이 방식은 처음엔 이해하기 조금 까다롭지만, 텐서플로에서 많이 사용된다.\n",
    "* 기본 아이디어\n",
    "    * `get_variable()` 함수를 사용해 공유 변수가 아직 존재하지 않을 때는 새로 만들고 이미 있을 때는 재사용하는 것이다.\n",
    "    * 상황에 맞는 동작(생성 또는 재사용)은 현재 `variable_scope()` 속성값으로 결정된다.\n",
    "    \n",
    "#### `relu/threshold` 변수 생성하기\n",
    "* `shape=()`이므로 스칼라 변수이고, 초깃값은 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "with tf.variable_scope('relu'):\n",
    "    threshold = tf.get_variable('threshold', shape=(), \n",
    "                                initializer=tf.constant_initializer(0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 만약 이 변수가 이전의 `get_variable()` 호출에서 이미 생성되었다면 예외를 발생한다.\n",
    "    * 이런 동작 방식은 실수로 변수가 사용되는 것을 막아준다.\n",
    "* 변수를 재사용하고 싶다면 명시적으로 변수 범위에 `reuse=True`로 지정해야 한다 (이 때는 크기나 초깃값을 지정할 필요가 없다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('relu', reuse=True):\n",
    "    threshold = tf.get_variable('threshold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 이미 존재하는 `relu/threshold` 변수를 가져오며, 존재하지 않거나 `get_variable()`로 만들지 않은 변수일 경우에는 예외가 발생한다.  \n",
    "\n",
    "변수 범위의 블록 안에서 `reuse_variables()` 메서드를 호출하여 `reuse=True`로 설정할 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('relu') as scope:\n",
    "    scope.reuse_variables()\n",
    "    threshold = tf.get_variable('threshold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **CAUTION**  \n",
    "`reuse`가 `True`로 설정되면 블록 안에서는 다시 `False`로 되돌릴 수 없다.  \n",
    "또한 이 블록 안에서 다른 변수 범위를 정의하면 자동으로 `reuse=True`를 상속하게 된다.  \n",
    "`get_variable()`로 만든 변수만 이 방식으로 재사용할 수 있다.\n",
    "\n",
    "#### 매개변수로 전달하지 않고 `threshold` 변수를 공유하도록 `relu()` 함수 만들기\n",
    "1. 먼저 `relu()` 함수를 정의하고 그 다음으로 `relu/threshold` 변수를 생성한다 (스칼라 변수이고, `0.0`으로 초기화될 것이다.)\n",
    "2. `relu()` 함수를 호출해 다섯 개의 ReLU를 만든다.\n",
    "3. `relu()` 함수는 `relu/threshold` 변수를 재사용하여 ReLU 노드를 만든다.\n",
    "\n",
    "> **NOTE**  \n",
    "`get_variable()`로 만든 변수는 항상 `variable_scope`의 이름을 접두사로 사용한다 (예. `relu/threshold`)  \n",
    "하지만 (`tf.Variable()`을 사용해 만든 변수를 포함해서) 다른 모든 노드에 대해서는 변수 범위가 새로운 이름 범위처럼 작동한다.  \n",
    "특히 같은 명칭으로 이름 범위가 이미 만들어져 있다면 유일한 이름을 만들기 위해 접미사가 붙는 식이다.  \n",
    "예를 들어 앞의 코드에서 만들어진 모든 노드는 (`threshold` 변수만 제외하고) 이름에 `relu_1/`에서 `relu_5/`까지 접두사를 포함한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X):\n",
    "    with tf.variable_scope('relu', reuse=True):\n",
    "        threshold = tf.get_variable('threshold') # 기존 변수를 재사용한다.\n",
    "        w_shape = int(X.get_shape()[1]), 1\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name='weights')\n",
    "        b = tf.Variable(0.0, name='bias')\n",
    "        z = tf.add(tf.matmul(X, w), b, name='z')\n",
    "        return tf.maximum(z, threshold, name='max')\n",
    "    \n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name='X')\n",
    "with tf.variable_scope('relu'): # 변수를 새로 만든다.\n",
    "    threshold = tf.get_variable('threshold', shape=(),\n",
    "                               initializer=tf.constant_initializer(0.0))\n",
    "relus = [relu(X) for relu_index in range(5)]\n",
    "output = tf.add_n(relus, name='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer = tf.summary.FileWriter('logs/relu6', tf.get_default_graph())\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `reuse_variables()` 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reset_graph()\n",
    "\n",
    "def relu(X):\n",
    "    with tf.variable_scope(\"relu\"):\n",
    "        threshold = tf.get_variable(\"threshold\", shape=(), initializer=tf.constant_initializer(0.0))\n",
    "        w_shape = (int(X.get_shape()[1]), 1)\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")\n",
    "        b = tf.Variable(0.0, name=\"bias\")\n",
    "        z = tf.add(tf.matmul(X, w), b, name=\"z\")\n",
    "        return tf.maximum(z, threshold, name=\"max\")\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "with tf.variable_scope(\"\", default_name=\"\") as scope:\n",
    "    first_relu = relu(X)     # 공유 변수를 만든 후\n",
    "    scope.reuse_variables()  # 재사용합니다.\n",
    "    relus = [first_relu] + [relu(X) for i in range(4)]\n",
    "output = tf.add_n(relus, name=\"output\")\n",
    "\n",
    "file_writer = tf.summary.FileWriter(\"logs/relu8\", tf.get_default_graph())\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 모든 ReLU 코드가 `relu()` 함수 안에 있지만 `threshold` 변수는 함수 밖에서 정의되어야 한다.  \n",
    "\n",
    "#### 처음 호출될 때 `relu()` 함수 안에서 `threshold` 변수를 생성하고 그 다음부터 호출될 때는 이 변수를 재사용하기\n",
    "* 이렇게 하면 `relu()` 함수는 이름 범위나 변수 공유를 신경 쓰지 않아도 된다.\n",
    "* `threshold` 변수를 생성하거나 재사용할 때 그냥 `get_variable()` 함수를 호출하면 된다(어떤 경우에 해당하는지 알 필요가 없다.)\n",
    "* 그 다음엔 `relu()`를 다섯 번 호출한다.\n",
    "* 처음 호출할 때는 `reuse=False`가 되고 그 다음부터는 `reuse=True`가 된다.\n",
    "> 이 코드는 `relu()` 함수 안에 있던 `variable_scope`를 함수 밖으로 옮겨서 `reuse` 속성을 함수 밖에서 조절하도록 변경했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X):\n",
    "    threshold = tf.get_variable(\"threshold\", shape=(),\n",
    "                                initializer=tf.constant_initializer(0.0))\n",
    "    w_shape = (int(X.get_shape()[1]), 1)                        # 책에는 없습니다.\n",
    "    w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")  # 책에는 없습니다.\n",
    "    b = tf.Variable(0.0, name=\"bias\")                           # 책에는 없습니다.\n",
    "    z = tf.add(tf.matmul(X, w), b, name=\"z\")                    # 책에는 없습니다.\n",
    "    return tf.maximum(z, threshold, name=\"max\")\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "relus = []\n",
    "for relu_index in range(5):\n",
    "    with tf.variable_scope(\"relu\", reuse=(relu_index >= 1)) as scope:\n",
    "        relus.append(relu(X))\n",
    "output = tf.add_n(relus, name=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer = tf.summary.FileWriter(\"logs/relu9\", tf.get_default_graph())\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 공유 변수가 첫 번째 ReLU 안에 들어있다.\n",
    "\n",
    "#### 이름 범주와 공유 변수, 변수의 관계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0: my_scope/x\n",
      "x1: my_scope/x_1\n",
      "x2: my_scope/x_2\n",
      "x3: my_scope/x\n",
      "x4: my_scope_1/x\n",
      "x5: my_scope/x\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "with tf.variable_scope(\"my_scope\"):\n",
    "    x0 = tf.get_variable(\"x\", shape=(), initializer=tf.constant_initializer(0.))\n",
    "    x1 = tf.Variable(0., name=\"x\")\n",
    "    x2 = tf.Variable(0., name=\"x\")\n",
    "\n",
    "with tf.variable_scope(\"my_scope\", reuse=True):\n",
    "    x3 = tf.get_variable(\"x\")\n",
    "    x4 = tf.Variable(0., name=\"x\")\n",
    "\n",
    "with tf.variable_scope(\"\", default_name=\"\", reuse=True):\n",
    "    x5 = tf.get_variable(\"my_scope/x\")\n",
    "\n",
    "print(\"x0:\", x0.op.name)\n",
    "print(\"x1:\", x1.op.name)\n",
    "print(\"x2:\", x2.op.name)\n",
    "print(\"x3:\", x3.op.name)\n",
    "print(\"x4:\", x4.op.name)\n",
    "print(\"x5:\", x5.op.name)\n",
    "print(x0 is x3 and x3 is x5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * **첫 번째 `variable_scope()` 블럭**\n",
    "    * 이름이 my_scope/x인 공유 변수 `x0`를 만든다.  \n",
    "    * 공유 변수 이외의 모든 연산에 대해서는 (공유되지 않는 변수를 포함하여) 변수 범위가 일반적인 이름 범위처럼 작동한다.   \n",
    "    그래서 두 변수 `x1`과 `x2`에 접두사 my_scope/가 붙는다. \n",
    "    * 하지만 텐서플로는 이름을 고유하게 만들기 위해 my_scope/x_1, my_scope/x_2처럼 인덱스를 추가시킨다.\n",
    "* **두 번째 variable_scope() 블럭**\n",
    "    * `my_scope` 범위에 있는 공유 변수를 재사용한다. 그래서 x0 is x3가 참이다. \n",
    "    * 여기에서도 공유 변수를 제외한 모든 연산은 이름 범주와 같이 작동한다.   \n",
    "    * 첫 번째 블럭과 다르기 때문에 텐서플로가 고유한 범주 이름을 만든다(my_scope_1). 변수 `x4`의 이름은 my_scope_1/x가 됩니다.\n",
    "* **세 번째 블럭**\n",
    "    * 공유 변수 my_scope/x를 다루는 다른 방식을 보여준다. 루트 범위(이름이 빈 문자열)에서 `variable_scope()`를 만들고 공유 변수의 전체 이름(즉, \"my_scope/x\")으로 `get_variable()`을 호출한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문자열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'Do' b'you' b'want' b'some' b'caf\\xc3\\xa9?']\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "text = np.array(\"Do you want some café?\".split())\n",
    "text_tensor = tf.constant(text)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(text_tensor.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 여러가지 자동 미분의 작동 원리\n",
    "https://github.com/rickiepark/handson-ml/blob/b5eaad8c9ffcfbe6df9ddc15107ff838ed960ad9/extra_autodiff.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연습문제\n",
    "## 1.\n",
    "계산을 직접 실행하지 않고 계산 그래프를 만드는 주요 장점과 단점은 무엇인가요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 주요 장점\n",
    "* 텐서플로가 자동으로 그래디언트를 계산할 수 있다(후진 모드 자동 미분을 사용하여).\n",
    "* 텐서플로가 여러 스레드에서 연산을 병렬로 실행할 수 있다.\n",
    "* 동일한 모델을 여러 장치에 걸쳐 실행시키기 편리하다.\n",
    "* 내부 구조를 살피기 쉽다. 예를 들어 텐서보드에서 모델을 시각화 할 수 있다.\n",
    "\n",
    "#### 주요 단점\n",
    "* 익숙하게 다루려면 시간이 필요하다.\n",
    "* 단계별 디버깅을 수행하기 어렵다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.\n",
    "`a_val = a.eval(session=sess)`와 `a_val = sess.run(a)`는 동일한 문장인가요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "완전 동일하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.\n",
    "`a_val, b_val = a.eval(session=sess), b.eval(session=sess)`와 `a_val, b_val = sess.run([a, b])`는 동일한 문장인가요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아니오.  \n",
    "첫 번째 문장은 그래프를 두 번(한 번은 `a`, 또 한 번은 `b`를 계산하기 위해) 실행하지만, 두 번째 문장은 그래프를 한 번만 실행한다.  \n",
    "이 연산(또는 의존하는 다른 연산)이 부수효과를 일으키면 (예. 변수가 수정되거나, 큐에 아이템이 추가되거나, 리더가 파일을 읽으면) 결과가 달라질 것이다.  \n",
    "만약 부수효과가 없다면 두 문장은 동일한 결과를 반환하지만 두 번째 문장이 첫 번째 문장보다 속도가 더 빠를 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.\n",
    "같은 세션에서 두 개의 그래프를 실행할 수 있나요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아니오.  \n",
    "먼저 두 개의 그래프를 하나의 그래프로 합쳐야 한다.\n",
    "> `tf.Session()`으로 세션을 만들 때 `graph` 매개변수로 사용할 그래프를 한 개 지정할 수 있다. 그렇지 않으면 기본 계산 그래프가 사용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.\n",
    "만약 변수 `w`를 가진 그래프 `g`를 만들고 스레드 두 개를 시작해 각 스레드에서 동일한 그래프 `g`를 사용하는 세션을 열면, 각 세션은 변수 `w`를 따로 가지게 될까요? 아니면 공유할까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로컬 텐서플로에서는 세션이 변숫값을 관리하므로 각 스레드에서 로컬 세션을 열면 각 세션은 변수 `w`의 복사본을 각자 가지게 될 것이다.  \n",
    "그러나 분산 텐서플로에서는 변숫값이 클러스터에 의해 관리되는 컨테이너에 저장된다.  \n",
    "그러므로 두 개의 세션이 같은 클러스터에 접속하여 가은 컨테이너를 사용하면 동일한 변수 `w`의 값을 공유할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.\n",
    "변수는 언제 초기화되고 언제 소멸되나요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "초기화 함수가 호출될 때 초기화되고, 세션이 종료될 때 소멸된다.  \n",
    "분산 텐서플로에서는 변수가 클러스터에 있는 컨테이너에 존재하기 때문에 세션을 종료해도 변수가 소멸되지 않으며 변수를 삭제하려면 컨테이너를 리셋해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.\n",
    "플레이스홀더와 변수의 차이점은 무엇인가요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 변수\n",
    "* 값은 가진 연산이다. 변수를 실행하면 값이 반환된다.  \n",
    "* 변수는 실행하기 전에 초기화해야 한다. \n",
    "* 변수의 값을 바꿀 수 있다(예. 할당 연산을 사용하여)\n",
    "* 변수는 상태를 가진다. 즉, 그래프를 연속해서 실행할 때 변수는 동일한 값을 유지한다.\n",
    "* 일반적으로 변수는 모델 파라미터를 저장하는 데 사용하지만 다른 목적으로도 쓰인다(예. 전체 훈련 스텝을 카운트하기 위해)\n",
    "\n",
    "#### 플레이스홀더\n",
    "* 기술적으로 봤을 때 많은 일을 하지 않는다. 표현하려는 텐서의 크기, 타입 정보를 가지고 있을 뿐 아무런 값도 가지고 있지 않다.\n",
    "* 실제로 플레이스홀더에 의존하는 연산을 평가하려면 플레이스홀더의 값을(`feed_dict` 매개변수를 통해) 텐서플로에 제공해야 한다. 그렇지 않으면 예외가 발생한다.\n",
    "* 일반적으로 플레이스홀더는 실행 단계에서 텐서플로에 훈련 데이터와 테스트 데이터를 주입하기 위해 사용된다.\n",
    "* 또한 변수의 값을 바꾸기 위해 할당 연산 노드에 값을 전달하는 용도로도 사용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.\n",
    "플레이스홀더에 의존하는 연산을 평가하기 위해 그래프를 실행할 때 플레이스홀더에 값을 주입하지 않으면 어떻게 될까요? 플레이스홀더에 의존하지 않는 연산이라면 어떻게 될까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 의존하는 연산을 평가할 때\n",
    "예외가 발생한다.\n",
    "\n",
    "#### 의존하지 않는 연산을 평가할 때\n",
    "예외가 발생하지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.\n",
    "그래프를 실행할 때 어떤 연산자의 출력값을 주입할 수 있나요? 아니면 플레이스홀더의 값만 가능한가요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "플레이스홀더뿐만 아니라 어떤 연산의 출력값도 주입할 수 있다.  \n",
    "그러나 실제로는 이는 매우 드문 경우이다(예. 동결된 층의 출력을 캐싱할 때 사용할 수 있다. 11장 참조)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.\n",
    "(실행 단계에서) 변수에 원하는 값을 어떻게 설정할 수 있나요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 그래프 구성 단계에서 변수의 초기화 값을 지정할 수 있고, 실행 단계에서 변수의 초기화 함수를 실행할 때 초기화될 것이다.\n",
    "* 실행 단계에서 변수의 값을 변경하는 간단한 방법\n",
    "    * (구성 단계에서) `tf.assign()`을 이용한 할당 노드를 만들고 매개변수로 변수와 플레이스홀더를 전달하는 것이다.\n",
    "    * 그리고 실행 단계에서 플레이스홀더를 사용해 변수의 새로운 값을 주입하여 할당 연산을 실행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78304076\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.Variable(tf.random_uniform(shape=(), minval=0.0, maxval=1.0))\n",
    "x_new_val = tf.placeholder(shape=(), dtype=tf.float32)\n",
    "x_assign = tf.assign(x, x_new_val)\n",
    "\n",
    "with tf.Session():\n",
    "    x.initializer.run() # 여기서 난수가 발생된다.\n",
    "    print(x.eval())\n",
    "    x_assign.eval(feed_dict={x_new_val: 5.0})\n",
    "    print(x.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.\n",
    "후진 모드 자동 미분으로 변수 10개에 대한 비용 함수의 그래디언트를 계산하려면 그래프를 몇 번 순회해야 하나요? 전진 모드 자동 미분이나 기호 미분의 경우는 어떨까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 후진 모드 자동 미분\n",
    "변수 개수에 상관없이 변수에 대한 비용 함수의 그래디언트를 계산하기 위해 그래프를 두 번 순회해야 한다.  \n",
    "\n",
    "##### 전진 모드 자동 미분\n",
    "각 변수마다 한 번씩 실행해야 한다(그러므로 10개의 다른 변수에 대한 그래디어트를 계산하려면 10번 실행해야 한다).  \n",
    "\n",
    "#### 기호 미분\n",
    "그래디언트 계산을 위해 다른 그래프를 만든다. 그래서 원본 그래프를 순회하지 않는다(그래디언트를 위한 새 그래프를 만들 때는 제외).  \n",
    "* 최적화가 매우 잘된 기호 미분 시스템은 모든 변수에 대한 그래디언트를 계산하기 위해 딱 한 번 새 그래디언트 그래프를 실행할 수 있다.  \n",
    "하지만 새 그래프가 매우 복잡하고 원본 그래프에 비해 비효율적일 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. \n",
    "텐서플로를 사용해 미니배치 경사 하강법을 로지스틱 회귀를 구현해보세요. (5장에서 소개한) moons 데이터셋에 훈련시키고 평가해보세요. 그리고 다음 부가 기능을 추가해보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 데이터 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "m = 1000\n",
    "X_moons, y_moons = make_moons(m, noise=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X_moons[y_moons == 1, 0], X_moons[y_moons == 1, 1], 'go', label='양성')\n",
    "plt.plot(X_moons[y_moons == 0, 0], X_moons[y_moons == 0, 1], 'r^', label='음성')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 편향 특성 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.05146968,  0.44419863],\n",
       "       [ 1.        ,  1.03201691, -0.41974116],\n",
       "       [ 1.        ,  0.86789186, -0.25482711],\n",
       "       [ 1.        ,  0.288851  , -0.44866862],\n",
       "       [ 1.        , -0.83343911,  0.53505665]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_moons_with_bias = np.c_[np.ones((m, 1)), X_moons]\n",
    "X_moons_with_bias[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### y_train 열 벡터로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_moons_column_vector = y_moons.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 훈련 세트/테스트 세트 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = 0.2\n",
    "test_size = int(m * test_ratio)\n",
    "\n",
    "X_train = X_moons_with_bias[:-test_size]\n",
    "X_test = X_moons_with_bias[-test_size:]\n",
    "y_train = y_moons_column_vector[:-test_size]\n",
    "y_test = y_moons_column_vector[-test_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 배치 만들기\n",
    "아래 배치를 생성하는 함수는 훈련 세트에서 랜덤하게 샘플링한다.  \n",
    "하나의 배치에 중복 샘플이 있을 수 있고 한 번의 에포크에 모든 훈련 샘플이 포함되지 않을 수 있다(사실 샘플의 $\\frac{2}{3}$ 정도가 포함된다).  \n",
    "하지만 실전에서 별 문제가 되지 않고 코드가 간단해진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(X_train, y_train, batch_size):\n",
    "    rnd_indices = np.random.randint(0, len(X_train), batch_size)\n",
    "    X_batch = X_train[rnd_indices]\n",
    "    y_batch = y_train[rnd_indices]\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "작은 배치 만들어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.01441495,  0.21721282],\n",
       "       [ 1.        ,  0.10021403,  1.05137369],\n",
       "       [ 1.        ,  1.12513092,  0.18174901],\n",
       "       [ 1.        , -1.02798645,  0.3103742 ],\n",
       "       [ 1.        ,  1.97903238,  0.52900065]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch, y_batch = random_batch(X_train, y_train, 5)\n",
    "X_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]], dtype=int64)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 모델 만들기\n",
    "\n",
    "#### 기본 그래프 리셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "moons 데이터셋은 두 개의 입력 특성을 가지므로 각 샘플은 평면 위의 한 점이다(즉, 2차원)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 로지스틱 회귀 모델 만들기\n",
    "먼저 (선형 회귀 모델과 동일하게) 입력의 가중치 합을 계산하고 그 결과를 시그모이드 함수에 적용하여 양성 클래스에 대한 추정 확률을 만든다.\n",
    "\n",
    "$ \\hat p = h_{\\theta}(ｘ) = \\sigma(\\theta^T \\cdot ｘ) $\n",
    "* $\\theta$ : 편향 $\\theta_0$와 가중치 $\\theta_1, \\theta_2, \\dots, \\theta_n$을 포함한 파라미터 벡터\n",
    "* $ｘ$ : 상수항 $x_0 = 1$과 입력 특성 $x_1, x_2, \\dots, x_n$을 포함한 입력 벡터\n",
    "\n",
    "한 번에 여러 샘플에 대한 예측을 만들 수 있어야 하므로 하나의 입력 벡터보다 입력 행렬 $\\mathbf X$를 사용 한다.  \n",
    "$i^{th}$번째 행이 $i^{th}$번째 입력 벡터의 전치$(ｘ^i)^T$이다.  \n",
    "아래 식을 사용하여 각 샘플의 양성 클래스에 속할 확률을 추정할 수 있다.  \n",
    "\n",
    "$ \\hat p = \\sigma(\\mathbf X \\cdot \\theta)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs + 1), name='X')\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name='y')\n",
    "theta = tf.Variable(tf.random_uniform([n_inputs + 1, 1], -1.0, 1.0, seed=42), \n",
    "                    name='theta')\n",
    "logits = tf.matmul(X, theta, name='logits')\n",
    "# y_proba = 1 / (1 + tf.exp(-logits))\n",
    "y_proba = tf.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 로그 손실\n",
    "로지스틱 회귀에 사용하기 좋은 비용함수이다.\n",
    "\n",
    "$J(\\mathbf{\\theta}) = -\\dfrac{1}{m} \\sum\\limits_{i=1}^{m}{\\left[ y^{(i)} log\\left(\\hat{p}^{(i)}\\right) + (1 - y^{(i)}) log\\left(1 - \\hat{p}^{(i)}\\right)\\right]}$\n",
    "\n",
    "\n",
    "1. 로그 손실 직접 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-7 # 로그 계산 시 오버플로우 피하기 위해\n",
    "loss = -tf.reduce_mean(y * tf.log(y_proba + epsilon) + \n",
    "                       (1 - y) * tf.log(1 - y_proba + epsilon))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. `tf.losses.log_loss()` 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.log_loss(y, y_proba)  # 기본적으로 epsilon = 1e-7 가 사용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 옵티마이저 만들고 비용 함수 최소화 시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 변수 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크: 0 \tLoss: 0.79260236\n",
      "에포크: 100 \tLoss: 0.3434635\n",
      "에포크: 200 \tLoss: 0.30754045\n",
      "에포크: 300 \tLoss: 0.29288894\n",
      "에포크: 400 \tLoss: 0.28533572\n",
      "에포크: 500 \tLoss: 0.28047806\n",
      "에포크: 600 \tLoss: 0.27808294\n",
      "에포크: 700 \tLoss: 0.2761544\n",
      "에포크: 800 \tLoss: 0.27551997\n",
      "에포크: 900 \tLoss: 0.27491233\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 50\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = random_batch(X_train, y_train, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val = loss.eval({X: X_test, y: y_test})\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"에포크:\", epoch, \"\\tLoss:\", loss_val)\n",
    "\n",
    "    y_proba_val = y_proba.eval(feed_dict={X: X_test, y: y_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **NOTE**  \n",
    "배치를 만들 때 에포크 수를 사용하지 않았으므로 두 개의 `for` 반복을 중첩하지 않고 하나의 `for` 반복을 사용할 수 있다.  \n",
    "하지만 훈련 시간을 에포크의 개수로 생각하는게 편리하다(즉, 알고리즘이 훈련 세트를 모두 훑고 지나가는 횟수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.54895616],\n",
       "       [0.70724374],\n",
       "       [0.51900256],\n",
       "       [0.9911136 ],\n",
       "       [0.5085905 ]], dtype=float32)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba_val[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `y_proba_val`은 해당 샘플이 양성 클래스에 속할 모델의 추정 확률을 담고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 최대 가능도 방법(Maximum Likelihood)을 사용하여 각 샘플 분류하기\n",
    "추정 확률이 0.5보다 크거나 같으면 양성으로 분류한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (y_proba_val >= 0.5)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 다른 임계값을 사용해야 할 경우가 있다.  \n",
    "높은 정밀도(대신 낮은 재현율)를 원한다면 임계값을 높이고, 재현율을 높이려면(대신 낮은 정밀도) 임계값을 낮춘다 (3장 참조)\n",
    "\n",
    "#### 모델의 정밀도, 재현율 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8627450980392157"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8888888888888888"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예측에 대한 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_idx = y_pred.reshape(-1) # 열 벡터를 1차원 배열로 변환\n",
    "plt.plot(X_test[y_pred_idx, 1], X_test[y_pred_idx, 2], 'go', label='양성')\n",
    "plt.plot(X_test[~y_pred_idx, 1], X_test[~y_pred_idx, 2], 'r^', label='음성')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 결과가 좋지 않다.  \n",
    "하지만 로지스틱 회귀 모델은 선형적인 결정 경계를 가지므로 최선에 가까운 것 같다 (특성을 더 추가하지 않는다면)\n",
    "\n",
    "### (3) 연습문제 부가기능을 추가해서 구현\n",
    "* (손쉽게 재사용할 수 있도록) `logistic_regression()` 안에 그래프를 정의하세요.\n",
    "* 훈련하는 동안 `Saver`로 체크포인트를 정기적으로 저장하세요. 그리고 훈련 마지막에 최종 모델을 저장하세요.\n",
    "* 훈련이 중지되고 다시 시작될 때 마지막 체크포인트를 복원하세요.\n",
    "* 텐서보드에서 그래프가 일목요연하게 보이도록 이름 범위를 사용해 그래프를 정의하세요.\n",
    "* 서머리를 추가해 텐서보드에서 학습 곡선을 시각화 해보세요.\n",
    "* 학습률이나 미니배치 크기같은 하이퍼파라미터를 바꿔보고 학습 곡선의 형태를 살펴보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 성능 향상을 위해 특성 추가\n",
    "연습문제에는 포함되어 있지 않지만 입력에 $x_1^2, x_2^2, x_1^3, x_2^3$ 4개 특성 추가한다.  \n",
    "여기서는 수동으로 특성을 추가하지만 `sklearn.preprocessing.PolynomialFeatures`를 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00, -5.14696757e-02,  4.44198631e-01,\n",
       "         2.64912752e-03,  1.97312424e-01, -1.36349734e-04,\n",
       "         8.76459084e-02],\n",
       "       [ 1.00000000e+00,  1.03201691e+00, -4.19741157e-01,\n",
       "         1.06505890e+00,  1.76182639e-01,  1.09915879e+00,\n",
       "        -7.39511049e-02],\n",
       "       [ 1.00000000e+00,  8.67891864e-01, -2.54827114e-01,\n",
       "         7.53236288e-01,  6.49368582e-02,  6.53727646e-01,\n",
       "        -1.65476722e-02],\n",
       "       [ 1.00000000e+00,  2.88850997e-01, -4.48668621e-01,\n",
       "         8.34348982e-02,  2.01303531e-01,  2.41002535e-02,\n",
       "        -9.03185778e-02],\n",
       "       [ 1.00000000e+00, -8.33439108e-01,  5.35056649e-01,\n",
       "         6.94620746e-01,  2.86285618e-01, -5.78924095e-01,\n",
       "         1.53179024e-01]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_enhanced = np.c_[X_train, \n",
    "                         np.square(X_train[:, 1]),\n",
    "                         np.square(X_train[:, 2]),\n",
    "                         X_train[:, 1] ** 3,\n",
    "                         X_train[:, 2] ** 3]\n",
    "X_test_enhanced = np.c_[X_test,\n",
    "                        np.square(X_test[:, 1]),\n",
    "                        np.square(X_test[:, 2]),\n",
    "                        X_test[:, 1] ** 3,\n",
    "                        X_test[:, 2] ** 3]\n",
    "X_train_enhanced[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 그래프 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 그래프를 만들기 위한 함수 정의\n",
    "입력 `X`와 타킷 `y`의 정의를 포함하지 않았다.\n",
    "* 이 함수에서 정의할 수 있지만 그렇게 하지 않아야 다양한 경우에 이 함수를 사용할 수 있다.\n",
    "    * 예. 로지스틱 회귀 모델에 주입하기 전에 입력에 대해 전처리 단계를 추가하 ㄹ수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X, y, initializer=None, seed=42, learning_rate=0.01):\n",
    "    n_inputs_including_bias = int(X.get_shape()[1])\n",
    "    with tf.name_scope('logistic_regression'):\n",
    "        with tf.name_scope('model'):\n",
    "            if initializer is None:\n",
    "                initializer = tf.random_uniform([n_inputs_including_bias, 1],\n",
    "                                               -1.0, 1.0, seed=seed)\n",
    "            theta = tf.Variable(initializer, name='theta')\n",
    "            logits = tf.matmul(X, theta, name='logits')\n",
    "            y_proba = tf.sigmoid(logits)\n",
    "        with tf.name_scope('train'):\n",
    "            loss = tf.losses.log_loss(y, y_proba, scope='loss')\n",
    "            optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "            training_op = optimizer.minimize(loss)\n",
    "            loss_summary = tf.summary.scalar('log_loss', loss)\n",
    "        with tf.name_scope('init'):\n",
    "            init = tf.global_variables_initializer()\n",
    "        with tf.name_scope('save'):\n",
    "            saver = tf.train.Saver()\n",
    "    return y_proba, loss, training_op, loss_summary, init, saver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### summary를 저장할 로그 디렉토리 이름을 생성하는 함수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def log_dir(prefix=''):\n",
    "    now = datetime.utcnow().strftime('%Y%m%d%H%M%S')\n",
    "    root_logdir = 'tf_logs'\n",
    "    if prefix:\n",
    "        prefix += '-'\n",
    "    name = prefix + 'run-' + now\n",
    "    return '{}/{}/'.format(root_logdir, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `logistic_regression()` 함수를 사용해 그래프 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 2 + 4\n",
    "logdir = log_dir('logreg')\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs + 1), name='X')\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name='y')\n",
    "\n",
    "y_proba, loss, training_op, loss_summary, init, saver = logistic_regression(X, y)\n",
    "\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "드디어 모델을 학습시킬 수 있다.\n",
    "\n",
    "#### 훈련\n",
    "이전에 훈련 세션이 중지되었는지부터 검사하고, 그렇다면 체크포인트를 로드하고 저장된 에포크 횟수부터 훈련을 이어간다.  \n",
    "* 이 예에서는 별도의 파일에 에포크 횟수를 저장했지만 11장에서 모델에 일부로 훈련 스텝을 저장하는 방법을 배운다(예. `global_step`이란 훈련되지 않는 변수를 옵티마이저의 `minimize()` 메서드에 전달한다).\n",
    "\n",
    "다시 시작할 때 마지막 체크포인트가 제대로 복원되는지 확인하기 위해 훈련을 중지시켜 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 :  0 \t손실 :  0.6294791\n",
      "에포크 :  500 \t손실 :  0.16108647\n",
      "에포크 :  1000 \t손실 :  0.11897118\n",
      "에포크 :  1500 \t손실 :  0.0972774\n",
      "에포크 :  2000 \t손실 :  0.083749466\n",
      "에포크 :  2500 \t손실 :  0.07437385\n",
      "에포크 :  3000 \t손실 :  0.06752581\n",
      "에포크 :  3500 \t손실 :  0.06225726\n",
      "에포크 :  4000 \t손실 :  0.058033537\n",
      "에포크 :  4500 \t손실 :  0.054592587\n",
      "에포크 :  5000 \t손실 :  0.05173551\n",
      "에포크 :  5500 \t손실 :  0.049303055\n",
      "에포크 :  6000 \t손실 :  0.047174234\n",
      "에포크 :  6500 \t손실 :  0.045370862\n",
      "에포크 :  7000 \t손실 :  0.043779805\n",
      "에포크 :  7500 \t손실 :  0.042379476\n",
      "에포크 :  8000 \t손실 :  0.04110836\n",
      "에포크 :  8500 \t손실 :  0.039951876\n",
      "에포크 :  9000 \t손실 :  0.0388961\n",
      "에포크 :  9500 \t손실 :  0.037979417\n",
      "에포크 :  10000 \t손실 :  0.037118115\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "n_epochs = 10001\n",
    "batch_size = 50\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "checkpoint_path = '/tmp/my_logreg_model.ckpt'\n",
    "checkpoint_epoch_path = checkpoint_path + '.epoch'\n",
    "final_model_path = './my_logreg_model'\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if os.path.isfile(checkpoint_epoch_path):\n",
    "        # 체크포인트 파일이 있으면 모델을 복원하고 에포크 횟수 로드\n",
    "        with open(checkpoint_epoch_path, 'rb') as f:\n",
    "            start_epoch = int(f.read())\n",
    "        print('중지되었던 훈련입이다. 에포크를 이어값니다.', start_epoch)\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        sess.run(init)\n",
    "        \n",
    "    for epoch in range(start_epoch, n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = random_batch(X_train_enhanced, y_train, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, summary_str = sess.run([loss, loss_summary], \n",
    "                                        feed_dict={X: X_test_enhanced, y: y_test})\n",
    "        file_writer.add_summary(summary_str, epoch)\n",
    "        if epoch % 500 == 0:\n",
    "            print('에포크 : ', epoch, '\\t손실 : ', loss_val)\n",
    "            saver.save(sess, checkpoint_path)\n",
    "            with open(checkpoint_epoch_path, 'wb') as f:\n",
    "                f.write(b'%d' % (epoch + 1))\n",
    "    \n",
    "    saver.save(sess, final_model_path)\n",
    "    y_proba_val = y_proba.eval(feed_dict={X: X_test_enhanced, y: y_test})\n",
    "    os.remove(checkpoint_epoch_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9797979797979798"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (y_proba_val >= 0.5)\n",
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9797979797979798"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_idx = y_pred.reshape(-1) # 열 벡터 대신 1차원 배열\n",
    "plt.plot(X_test[y_pred_idx, 1], X_test[y_pred_idx, 2], 'go', label=\"양성\")\n",
    "plt.plot(X_test[~y_pred_idx, 1], X_test[~y_pred_idx, 2], 'r^', label=\"음성\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 훨씬 좋아졌다. 새로 추가한 특석이 확실히 도움이 많이 되었다.\n",
    "\n",
    "#### 텐서보드 서버를 시작해서 학습 곡선 확인해보기\n",
    "즉, 에포크 횟수에 대해 테스트 세트로 평가한 손실이 얼마나 되는지  \n",
    "\\$ tensorboard --logdir=tf_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `batch_size`나 `learning_rate` 하이퍼파라미터 랜덤 서치로 조정 후 훈련하면서 학습 곡선 비교\n",
    "* 간단하게 하기 위해 체크포인트 관리 부분은 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복 0\n",
      "  logdir: tf_logs/logreg-run-20190114041419/\n",
      "  batch_size: 53\n",
      "  learning_rate: 0.004430375245218265\n",
      "  훈련: .....................\n",
      "  정밀도: 0.9797979797979798\n",
      "  재현율: 0.9797979797979798\n",
      "반복 1\n",
      "  logdir: tf_logs/logreg-run-20190114041545/\n",
      "  batch_size: 80\n",
      "  learning_rate: 0.0017826497151386947\n",
      "  훈련: .....................\n",
      "  정밀도: 0.9696969696969697\n",
      "  재현율: 0.9696969696969697\n",
      "반복 2\n",
      "  logdir: tf_logs/logreg-run-20190114041643/\n",
      "  batch_size: 73\n",
      "  learning_rate: 0.00203228544324115\n",
      "  훈련: .....................\n",
      "  정밀도: 0.9696969696969697\n",
      "  재현율: 0.9696969696969697\n",
      "반복 3\n",
      "  logdir: tf_logs/logreg-run-20190114041754/\n",
      "  batch_size: 6\n",
      "  learning_rate: 0.004491523825137997\n",
      "  훈련: .....................\n",
      "  정밀도: 0.9801980198019802\n",
      "  재현율: 1.0\n",
      "반복 4\n",
      "  logdir: tf_logs/logreg-run-20190114043002/\n",
      "  batch_size: 24\n",
      "  learning_rate: 0.07963234721775589\n",
      "  훈련: .....................\n",
      "  정밀도: 0.9801980198019802\n",
      "  재현율: 1.0\n",
      "반복 5\n",
      "  logdir: tf_logs/logreg-run-20190114043256/\n",
      "  batch_size: 75\n",
      "  learning_rate: 0.0004634250583294876\n",
      "  훈련: .....................\n",
      "  정밀도: 0.912621359223301\n",
      "  재현율: 0.9494949494949495\n",
      "반복 6\n",
      "  logdir: tf_logs/logreg-run-20190114043356/\n",
      "  batch_size: 86\n",
      "  learning_rate: 0.047706818419354494\n",
      "  훈련: .....................\n",
      "  정밀도: 0.98\n",
      "  재현율: 0.98989898989899\n",
      "반복 7\n",
      "  logdir: tf_logs/logreg-run-20190114043453/\n",
      "  batch_size: 87\n",
      "  learning_rate: 0.0001694044709524274\n",
      "  훈련: .....................\n",
      "  정밀도: 0.8888888888888888\n",
      "  재현율: 0.8080808080808081\n",
      "반복 8\n",
      "  logdir: tf_logs/logreg-run-20190114043551/\n",
      "  batch_size: 61\n",
      "  learning_rate: 0.04171461199412461\n",
      "  훈련: .....................\n",
      "  정밀도: 0.9801980198019802\n",
      "  재현율: 1.0\n",
      "반복 9\n",
      "  logdir: tf_logs/logreg-run-20190114043712/\n",
      "  batch_size: 92\n",
      "  learning_rate: 0.00010742922968438615\n",
      "  훈련: .....................\n",
      "  정밀도: 0.8823529411764706\n",
      "  재현율: 0.7575757575757576\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "\n",
    "n_search_iterations = 10\n",
    "\n",
    "for search_iteration in range(n_search_iterations):\n",
    "    batch_size = np.random.randint(1, 100)\n",
    "    learning_rate = reciprocal(0.0001, 0.1).rvs(random_state=search_iteration)\n",
    "    \n",
    "    n_inputs = 2 + 4\n",
    "    logdir = log_dir('logreg')\n",
    "    \n",
    "    print(\"반복\", search_iteration)\n",
    "    print(\"  logdir:\", logdir)\n",
    "    print(\"  batch_size:\", batch_size)\n",
    "    print(\"  learning_rate:\", learning_rate)\n",
    "    print(\"  훈련: \", end=\"\")\n",
    "\n",
    "    reset_graph()\n",
    "\n",
    "    X = tf.placeholder(tf.float32, shape=(None, n_inputs + 1), name=\"X\")\n",
    "    y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "    y_proba, loss, training_op, loss_summary, init, saver = logistic_regression(\n",
    "        X, y, learning_rate=learning_rate)\n",
    "\n",
    "    file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "    n_epochs = 10001\n",
    "    n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "    final_model_path = \"./my_logreg_model_%d\" % search_iteration\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            for batch_index in range(n_batches):\n",
    "                X_batch, y_batch = random_batch(X_train_enhanced, y_train, \n",
    "                                                batch_size)\n",
    "                sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            loss_val, summary_str = sess.run([loss, loss_summary], \n",
    "                                    feed_dict={X: X_test_enhanced, y: y_test})\n",
    "            file_writer.add_summary(summary_str, epoch)\n",
    "            if epoch % 500 == 0:\n",
    "                print(\".\", end=\"\")\n",
    "\n",
    "        saver.save(sess, final_model_path)\n",
    "\n",
    "        print()\n",
    "        y_proba_val = y_proba.eval(feed_dict={X: X_test_enhanced, y: y_test})\n",
    "        y_pred = (y_proba_val >= 0.5)\n",
    "        \n",
    "        print(\"  정밀도:\", precision_score(y_test, y_pred))\n",
    "        print(\"  재현율:\", recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하이퍼파라미터의 적절한 스케일을 감잡을 수 없을 때 `scipy.stats.reciprocal` 함수를 사용하여 난수 분포를 얻을 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 인공 신경망\n",
    "* **인공신경망**(ANN, artificial neural networks)은 다재다능하고 강력하고 확장성이 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 생물학적 뉴런에서 인공 뉴런까지\n",
    "\n",
    "## 1.1. 생물학적 뉴런\n",
    "\n",
    "## 1.2. 뉴런을 사용한 논리 연산\n",
    "\n",
    "## 1.3. 퍼셉트론\n",
    "* **퍼셉트론**(Perceptron)은 가장 간단한 인공 신경망 구조 중 하나이다.\n",
    "* **TLU**(threshold logic unit)라는 조금 다른 형태의 인공 뉴런을 기반으로 한다.\n",
    "\n",
    "#### TLU\n",
    "* 입력과 출력이 (이진 on/off 값이 아니라) 어떤 숫자고, 각각의 입력 연결은 가중치와 연관되어 있다.\n",
    "* TLU 과정\n",
    "    1. 입력의 가중치 합을 계산한다.  \n",
    "        $z = w_1x_1 + w_2x_2 + \\dots + w_nx_n = W^T \\cdot X$\n",
    "    2. 그런 다음 계산된 합에 **계단 함수**(step function)를 적용하여 그 결과를 출력한다.  \n",
    "        $ h_w(X) = step(z) = step(W^T \\cdot X)$\n",
    "\n",
    "#### 퍼셉트론에서 가장 널리 사용되는 계단함수\n",
    "* **헤비사이드 계단 함수**(Heaviside step function)\n",
    "    * 가장 널리 사용된다.\n",
    "    * 단위 계단 함수(unit step function)라고도 한다.\n",
    "$$ \\mbox{heaviside}(z) = \n",
    "\\begin{cases} \n",
    "0 & z < 0 \\mbox{일 때}\\\\\n",
    "1 & z ≥ 0 \\mbox{일 때}\n",
    "\\end{cases} $$\n",
    "* 부호 함수(sign function)\n",
    "$$ \\mbox{sgn}(z) = \n",
    "\\begin{cases}\n",
    "-1 & z < 0 \\mbox{일 때}\\\\\n",
    "0 & z = 0 \\mbox{일 때}\\\\\n",
    "1 & z > 0 \\mbox{일 때}\n",
    "\\end{cases} $$\n",
    "\n",
    "#### 하나의 TLU 사용 예; 간단한 선형 이진 분류 문제에 사용\n",
    "* (로지스틱 회귀 분류기나 선형 SVM처럼) 입력의 선형 조합을 계산해서 그 결과가 임곗값을 넘어서면 양성 클래스를 출력하고 그렇지 않으면 음성 클래스를 출력한다.\n",
    "* ex)  \n",
    "하나의 TLU를 이용해 (편향 특성 $x_0 = 1$을 추가해서) 꽃잎 길이와 너비를 기반으로 붓꽃의 품종을 분류할 수 있다.\n",
    "* TLU를 훈련시킨다는 것은 최적의 $w_0, w_1, w_2$를 찾는다는 뜻이다.\n",
    "\n",
    "#### 퍼셉트론\n",
    "* 층이 하나뿐인 TLU로 구성된다.\n",
    "* 각 뉴런은 모든 입력에 연결되어 있다. \n",
    "    * 이 연결은 **입력 뉴런**(input neuron)이라 부르는 특별한 통과 뉴런을 사용해 표현되곤 한다. \n",
    "    * 이 뉴런은 무엇이 주입되든 입력을 그냥 출력으로 통과시킨다.\n",
    "* 보통 거기에 편향 특성($x_0 = 1$)이 더해진다.\n",
    "    * 전형적으로 이 편향 특성은 항상 1을 출력하는 특별한 종류의 뉴런인 **편향 뉴런**(bias neuron)으로 표현된다.\n",
    "    > 입력 뉴런은 그냥 입력값 자체를 말하며, 편향 뉴런은 신경망 그림에서 편의상 표시하지 않는 경우도 많다.\n",
    "    \n",
    "### 1.3.1. 퍼셉트론의 훈련\n",
    "* 두 뉴런이 동일한 출력을 낼 때마다 그들 사이의 연결 가중치가 증가한다.\n",
    "    * '서로 활성화되는 세포가 서로 연결된다'는 헤브의 규칙(또는 **헤브 학습**(Hebbian learning)의 아이디어를 이용\n",
    "* 퍼셉트론은 네트워크가 만드는 에러를 반영하도록 조금 변형된 규칙을 사용하여 훈련된다.\n",
    "    * 잘못된 출력을 만드는 연결은 강화시키지 않는다.\n",
    "    * 구체적으로 퍼셉트론에 한 번에 한 개의 샘플이 주입되면 각 샘플에 대해 예측이 만들어진다. 잘못된 예측을 하는 모든 출력 뉴런에 대해 올바른 예측을 만들 수 있도록 입력에 학습 규칙에 따라 연결된 가중치를 강화시킨다.\n",
    "\n",
    "#### 퍼셉트론 학습 규칙(가중치 업데이트)\n",
    "$$ w_{i, j}^{\\mbox{next step}} = w_{i, j} + \\eta(y_i - \\hat y_j)x_i $$\n",
    "* $w_{i, j}$ : $i$번째 입력 뉴런과 $j$번째 추렭 뉴런 사이를 연결하는 가중치\n",
    "* $x_i$ : 현재 훈련 샘플의 $i$번째 뉴런의 입력값\n",
    "* $\\hat y_j$ : 현재 훈련 샘플의 $j$번째 출력 뉴런의 출력값\n",
    "* $y_j$ : 현재 훈련 샘플의 $j$번째 출력 뉴런의 타깃값\n",
    "* $\\eta$ : 학습률\n",
    "\n",
    "#### 퍼셉트론 수렴 이론\n",
    "* 각 출력 뉴련의 결정 경계는 선형이므로 퍼셉트론도 (로지스틱 회귀 분류기처럼) 복잡한 패턴을 학습하지 못한다.\n",
    "* 하지만 훈련 샘플이 선형적으로 구분될 수 있다면 이 알고리즘이 정답에 수렴한다는 것이 **퍼셉트론 수렴 이론**(Perceptron convergence theorem)이다.\n",
    "\n",
    "#### scikit-learn의 퍼셉트론\n",
    "* scikit-learn은 하나의 TLU 네트워크를 구현한 `Perceptron` 클래스를 제공한다\n",
    "> `sklearn.neural_network` 아래에 회귀와 분류의 다층 퍼셉트론 구현인 `MLPClassifier`와 `MLPRegressor`도 제공한다.\n",
    "* `Perceptron` 클래스는 매개변수가 `loss='perceptron', learning_rate='constant', eta0=1(학습률), pernalty=None(규제없음)`인 `SGDClassifier`와 같다.\n",
    "* 로지스틱 회귀 분류기와 달리 퍼셉트론은 클래스 확률을 제공하지 않으며 고정된 임곗값을 기준으로 예측을 만든다. 이런 이유로 퍼셉트론보다 로지스틱 회귀가 선호된다.\n",
    "\n",
    "#### 붓꽃 데이터셋에 퍼셉트론 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)] # 꽃잎 길이, 너비\n",
    "y = (iris.target == 0).astype(np.int)\n",
    "\n",
    "per_clf = Perceptron(max_iter=100, random_state=42)\n",
    "per_clf.fit(X, y)\n",
    "y_pred = per_clf.predict([[2, 0.5]])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = -per_clf.coef_[0][0] / per_clf.coef_[0][1]\n",
    "b = -per_clf.intercept_ / per_clf.coef_[0][1]\n",
    "\n",
    "axes = [0, 5, 0, 2]\n",
    "\n",
    "x0, x1 = np.meshgrid(\n",
    "        np.linspace(axes[0], axes[1], 500).reshape(-1, 1),\n",
    "        np.linspace(axes[2], axes[3], 200).reshape(-1, 1),\n",
    "    )\n",
    "X_new = np.c_[x0.ravel(), x1.ravel()]\n",
    "y_predict = per_clf.predict(X_new)\n",
    "zz = y_predict.reshape(x0.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(X[y==0, 0], X[y==0, 1], \"bs\", label=\"Iris-Setosa 아님\")\n",
    "plt.plot(X[y==1, 0], X[y==1, 1], \"yo\", label=\"Iris-Setosa\")\n",
    "\n",
    "plt.plot([axes[0], axes[1]], [a * axes[0] + b, a * axes[1] + b], \"k-\", linewidth=3)\n",
    "from matplotlib.colors import ListedColormap\n",
    "custom_cmap = ListedColormap(['#9898ff', '#fafab0'])\n",
    "\n",
    "plt.contourf(x0, x1, zz, cmap=custom_cmap)\n",
    "plt.xlabel(\"꽃잎 길이\", fontsize=14)\n",
    "plt.ylabel(\"꽃잎 너비\", fontsize=14)\n",
    "plt.legend(loc=\"lower right\", fontsize=14)\n",
    "plt.axis(axes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. 다층 퍼셉트론과 역전파\n",
    "* 여러 퍼셉트론을 쌓아올려 일부 제약을 줄이는 **다층 퍼셉트론**(MLP, Multi-Layer Perceptron) 인공 신경망은 퍼셉트론이 풀지 못하는 XOR문제를 풀 수 있다.\n",
    "* 다층 퍼셉트론은 (통과) **입력층** 하나 + **은닉층**(hidden layer)이라는 하나 이상의 TLU층 + **출력층**(output layer)으로 구성된다.\n",
    "* 출력층을 제외하고 모든 층은 편향 뉴런을 포함하며 다음 층과 완전히 연결되어 있다.\n",
    "* **심층 신경망**(DNN, deep neural network) : 인공 신경망의 은닉층이 2개 이상일 때\n",
    "\n",
    "#### 역전파(backpropagation)\n",
    "1. 알고리즘이 각 훈련 샘플을 네트워크에 주입하고 연속되는 각 층의 뉴런마다 출력을 계산한다 (정방향 계산)\n",
    "2. 네트워크의 출력 오차(기댓값과 네트워크 실제 출력과의 차이)를 계산한다.\n",
    "3. 각 출력 뉴런의 오차에 마지막 은닉층의 뉴런이 얼마나 기여했는지 측정한다.\n",
    "> 여기서는 뉴런의 입력값에 대한 비용 함수의 편미분을 오차에 기여한 정도 또는 오차 그래디언트라고 표현한다.\n",
    "4. 이전 은닉층의 뉴런이 여기에 또 얼마나 기여했는지 측정한다. 이런 식으로 입력층에 도달할 때까지 계속 측정한다.\n",
    "\n",
    "이 역방향 과정은 오차 그래디언트를 후방으로 전파함으로써 네트워크의 모든 연결 가중치에 대한 오차 그래디언트를 효율적으로 계산한다(그래서 역전파라고 한다).\n",
    "* 부록 D의 후진 모드 자동 미분 알고리즘을 보면 역전파의 정방향과 역방향 계산이 후진 모드 자동 미분을 수행하는 것임을 알 수 있다.\n",
    "* 역전파 알고리즘의 마지막 단계는 앞서 계산한 오차 그래디언트를 네트워크의 모든 연결 가중치에 반영하는 경사 하강법 스텝이다.\n",
    "\n",
    "#### 간단한 설명\n",
    "1. 각 훈련 샘플에 대해 역전파 알고리즘이 먼저 예측을 만들고(정방향 계산), 오차를 측정하고, \n",
    "2. 역방향으로 각 층을 거치면서 각 연결이 오차에 기여한 정도를 측정한다(역방향 계산). \n",
    "3. 마지막으로 이 오차가 감소하도록 가중치를 조금씩 조정한다(경사하강법 스텝).\n",
    "\n",
    "#### 역전파 알고리즘 활성화 함수\n",
    "* 이 알고리즘을 잘 작동시키기 위해 계단 함수를 로지스틱 함수로 바꿔서 다층 퍼셉트론 구조에 변화를 주었다.  \n",
    "$$ \\sigma(z) = \\frac{1}{1 + exp^{-z}}$$  \n",
    "    * 계단 함수에는 수평선밖에 없으니 계산할 그래디언트가 없다(경사 하강법은 평편한 곳을 이동할 수 없다).\n",
    "    * 반면 로지스틱 함수는 어디서든지 0이 아닌 그래디언트가 잘 정의되어 있다.\n",
    "* 이처럼 역전파 알고리즘에 계단 함수나 로지스틱 함수 대신 다른 **활성화 함수**(activation function)도 사용할 수 있다.\n",
    "* 널리 쓰이는 활성화 함수\n",
    "    * **하이퍼볼릭 탄젠트 함수(쌍곡 탄젠트 함수))**  \n",
    "        $$ \\mbox{tanh} = 2\\sigma(2z) -1 $$   \n",
    "        * 로지스틱 함수처럼 S자 모양이고 연속적이며 미분 가능하다.\n",
    "        * 출력범위가 -1 ~ 1이여서 훈련 초기에 각 층의 출력이 다소 정규화되는 경향이 있다(즉, 원점 주위로 몰리게 된다).\n",
    "        * 이는 종종 빠르게 수렴되도록 도와준다.\n",
    "    * **ReLU 함수**(9장 참조)  \n",
    "        $$ \\mbox{ReLU}(z) = \\mbox{max}(0, z) $$    \n",
    "        * 이 함수는 연속적이지만 $z = 0$에서는 미분이 불가능하다(기울기가 갑자기 변해서 경사 하강법이 엉뚱한 곳으로 튈 수 있다).\n",
    "        > ReLU 함수 값이 0보다 클 때 기울기는 항상 1이므로 오차 그래디언트를 그대로  역전파 시킨다.  \n",
    "        원점에서는 기울기가 정의되지 않지만 텐서플로를 포함해 일반적으로 0을 사용한다.  \n",
    "        따라서 ReLU 함수 값이 0보다 작거나 같을 때는 오차 그래디언트를 역전파시키지 않는다.\n",
    "        * 그러나 실제로는 잘 작동하고 계산 속도가 빠르다는 장점이 있다.\n",
    "        * 무엇보다 중요한 점은 출력에 최댓값이 없다는 점이 경사 하강법에 있는 일부 문제를 완화해준다.\n",
    "        > 로지스틱 함수나 하이퍼볼릭 탄젠트 함수는 출력 범위가 0~1 또는 -1~1 사이로 한정되어 양극단에서 기울기가 급격히 감소하므로 오차 그래디언트를 잘 역전파시키지 못한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def derivative(f, z, eps=0.000001):\n",
    "    return (f(z + eps) - f(z - eps))/(2 * eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.figure(figsize=(11,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(z, np.sign(z), \"r-\", linewidth=2, label=\"스텝\")\n",
    "plt.plot(z, logit(z), \"g--\", linewidth=2, label=\"로지스틱\")\n",
    "plt.plot(z, np.tanh(z), \"b-\", linewidth=2, label=\"Tanh\")\n",
    "plt.plot(z, relu(z), \"m-.\", linewidth=2, label=\"ReLU\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc=\"center right\", fontsize=14)\n",
    "plt.title(\"활성화 함수\", fontsize=14)\n",
    "plt.axis([-5, 5, -1.2, 1.2])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(z, derivative(np.sign, z), \"r-\", linewidth=2, label=\"Step\")\n",
    "plt.plot(0, 0, \"ro\", markersize=5)\n",
    "plt.plot(0, 0, \"rx\", markersize=10)\n",
    "plt.plot(z, derivative(logit, z), \"g--\", linewidth=2, label=\"Logit\")\n",
    "plt.plot(z, derivative(np.tanh, z), \"b-\", linewidth=2, label=\"Tanh\")\n",
    "plt.plot(z, derivative(relu, z), \"m-.\", linewidth=2, label=\"ReLU\")\n",
    "plt.grid(True)\n",
    "plt.title(\"도함수\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.2, 1.2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heaviside(z):\n",
    "    return (z >= 0).astype(z.dtype)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def mlp_xor(x1, x2, activation=heaviside):\n",
    "    return activation(-activation(x1 + x2 - 1.5) + activation(x1 + x2 - 0.5) - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x1s = np.linspace(-0.2, 1.2, 100)\n",
    "x2s = np.linspace(-0.2, 1.2, 100)\n",
    "x1, x2 = np.meshgrid(x1s, x2s)\n",
    "\n",
    "z1 = mlp_xor(x1, x2, activation=heaviside)\n",
    "z2 = mlp_xor(x1, x2, activation=sigmoid)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.contourf(x1, x2, z1)\n",
    "plt.plot([0, 1], [0, 1], \"gs\", markersize=20)\n",
    "plt.plot([0, 1], [1, 0], \"y^\", markersize=20)\n",
    "plt.title(\"활성화 함수: 헤비사이드\", fontsize=14)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.contourf(x1, x2, z2)\n",
    "plt.plot([0, 1], [0, 1], \"gs\", markersize=20)\n",
    "plt.plot([0, 1], [1, 0], \"y^\", markersize=20)\n",
    "plt.title(\"활성화 함수: 시그모이드\", fontsize=14)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다층 퍼셉트론과 분류\n",
    "* 다층 퍼셉트론은 각 출력이 서로 다른 이진 클래스에 대응되는 분류 문제에 자주 사용된다.\n",
    "* 클래스가 배타적일 때(예. 숫자 이미지 분류의 0 ~ 9까지 클래스일 때)는 전형적으로 출력층의 활성화 함수를 **소프트맥스**(softmax) 함수로 바꿔준다.\n",
    "> 소프트맥스 함수의 분모는 모든 클래스의 출력에 지수 함수를 적용하여 더한 값이다. 그래서 소프트맥스 함수가 출력 뉴런 전체에 걸쳐 있다.\n",
    "> 소프트맥스 함수  \n",
    "$ \\hat p_k = \\sigma(s(X))_k = \\frac{exp(s_k(X)}{\\sum_{j=1}^K exp(s_j(X))} $\n",
    "    * $K$ : 클래스 수\n",
    "    * $s(X)$ : 샘플 $X$에 대한 각 클래스의 점수를 담은 벡터\n",
    "    * $\\sigma(s(X))_k$ : 샘플 $X$에 대한 각 클래스의 점수가 주어졌을 때 이 샘플이 클래스 $k$에 속할 추정 확률\n",
    "* 각 뉴런의 출력은 이에 상응하는 클래스의 추정 확률이 된다.\n",
    "* 신호가 (입력 → 출력) 한 방향으로만 흐르기 때문에 이런 구조를 **피드포워드 신경망**(FNN, feed forward neural network)이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 텐서플로의 고수준 API로 다층 퍼셉트론 훈련하기\n",
    "\n",
    "#### 텐서플로로 다층 퍼셉트론(MLP)을 훈련시키는 가장 간단한 방법\n",
    "scikit-learn과 호환되는 고수준 API인 `TF.Learn`을 사용하는 것\n",
    "* `DNNClassifier` 클래스 : 여러 개의 은닉층과 클래스의 확률 추정을 위한 softmax 출력층으로 구성된 심층 신경망(DNN)을 매우 쉽게 훈련시켜준다.\n",
    "\n",
    "#### MNIST를 위한 FNN\n",
    "은닉층 2개(각각 뉴런 수 300개, 100개)와 10개의 뉴런을 가진 softmax 출력층 하나로 구성된 분류 문제용 심층 신경망(DNN) 훈련시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28 * 28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28 * 28) / 255.0\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_vaild, X_train = X_train[:5000], X_train[5000:]\n",
    "y_vaild, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Estimator API를 사용\n",
    "> **CAUTION**\n",
    "* `tf.examples.tutorials.mnist` - 삭제될 예정이므로 대신 `tf.keras.datasets.mnist`를 사용한다.\n",
    "* `tf.contrib.learn` API : `tf.estimator`와 `tf.feature_column`으로 옮겨졌고 상당히 많이 바뀌었다.\n",
    "    * 특히 `infer_real_valued_columns_from_input()` 함수와 `SKCompat` 클래스가 없어졌다.\n",
    "    \n",
    "**바뀐 것 때문에 과정 주의!!**\n",
    "\n",
    "1. 먼저 훈련 세트로부터 실숫값으로 된 열을 만든다(범주형 같은 열도 가능하다).\n",
    " > `infer_real_valued_columns_from_input()` 함수는 `tf.contrib.learn` 하위의 `DNNClassifier`, `LinearClassifier`, `LinearRegressor` 등의 클래스에 정수/실수로 된 특성을 매핑하기 위한 `FeatureColumn` 객체를 만든다.  \n",
    "범주형 데이터의 경우 `sparse_column_with_keys()` 함수 등을 사용할 수 있다.\n",
    "\n",
    "2. `DNNClassifier`의 객체를 만들고 scikit-learn 인터페이스와 호환되게 만들어 주는 `SKCompat` 클래스로 감싼다.\n",
    "\n",
    "3. 마지막으로 샘플이 50개인 배치로 훈련을 40,000번 반복한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\jeong\\AppData\\Local\\Temp\\tmp8acdsdbe\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\jeong\\\\AppData\\\\Local\\\\Temp\\\\tmp8acdsdbe', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000295DFC1BF28>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\inputs\\queues\\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\jeong\\AppData\\Local\\Temp\\tmp8acdsdbe\\model.ckpt.\n",
      "INFO:tensorflow:loss = 116.58923, step = 1\n",
      "INFO:tensorflow:global_step/sec: 190.56\n",
      "INFO:tensorflow:loss = 21.486332, step = 101 (0.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.301\n",
      "INFO:tensorflow:loss = 13.711636, step = 201 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.314\n",
      "INFO:tensorflow:loss = 2.3307304, step = 301 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.012\n",
      "INFO:tensorflow:loss = 5.410336, step = 401 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.012\n",
      "INFO:tensorflow:loss = 16.863813, step = 501 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.684\n",
      "INFO:tensorflow:loss = 16.043808, step = 601 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.962\n",
      "INFO:tensorflow:loss = 8.115423, step = 701 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.121\n",
      "INFO:tensorflow:loss = 5.0287743, step = 801 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.825\n",
      "INFO:tensorflow:loss = 8.4692, step = 901 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.052\n",
      "INFO:tensorflow:loss = 0.39756483, step = 1001 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.938\n",
      "INFO:tensorflow:loss = 11.684203, step = 1101 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.675\n",
      "INFO:tensorflow:loss = 3.1666903, step = 1201 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.496\n",
      "INFO:tensorflow:loss = 7.8494987, step = 1301 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.807\n",
      "INFO:tensorflow:loss = 1.7123101, step = 1401 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.007\n",
      "INFO:tensorflow:loss = 2.26128, step = 1501 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.513\n",
      "INFO:tensorflow:loss = 2.9766634, step = 1601 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.581\n",
      "INFO:tensorflow:loss = 2.6590703, step = 1701 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.138\n",
      "INFO:tensorflow:loss = 1.416274, step = 1801 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.021\n",
      "INFO:tensorflow:loss = 5.891101, step = 1901 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.234\n",
      "INFO:tensorflow:loss = 6.6132727, step = 2001 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.652\n",
      "INFO:tensorflow:loss = 7.87651, step = 2101 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.616\n",
      "INFO:tensorflow:loss = 2.648086, step = 2201 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.616\n",
      "INFO:tensorflow:loss = 0.80406064, step = 2301 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.615\n",
      "INFO:tensorflow:loss = 4.364194, step = 2401 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.514\n",
      "INFO:tensorflow:loss = 4.4541407, step = 2501 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.304\n",
      "INFO:tensorflow:loss = 2.091975, step = 2601 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.527\n",
      "INFO:tensorflow:loss = 1.0635264, step = 2701 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.552\n",
      "INFO:tensorflow:loss = 0.61297524, step = 2801 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.869\n",
      "INFO:tensorflow:loss = 3.2357666, step = 2901 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.871\n",
      "INFO:tensorflow:loss = 0.82872593, step = 3001 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.38\n",
      "INFO:tensorflow:loss = 1.5366973, step = 3101 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.243\n",
      "INFO:tensorflow:loss = 5.458377, step = 3201 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.188\n",
      "INFO:tensorflow:loss = 1.2816123, step = 3301 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.815\n",
      "INFO:tensorflow:loss = 1.3843824, step = 3401 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.02\n",
      "INFO:tensorflow:loss = 1.4522595, step = 3501 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.04\n",
      "INFO:tensorflow:loss = 3.590499, step = 3601 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.403\n",
      "INFO:tensorflow:loss = 5.0494266, step = 3701 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.02\n",
      "INFO:tensorflow:loss = 0.525448, step = 3801 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.816\n",
      "INFO:tensorflow:loss = 4.3003893, step = 3901 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.831\n",
      "INFO:tensorflow:loss = 1.0620227, step = 4001 (0.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.019\n",
      "INFO:tensorflow:loss = 3.7447639, step = 4101 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.097\n",
      "INFO:tensorflow:loss = 2.5516255, step = 4201 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.04\n",
      "INFO:tensorflow:loss = 0.68800795, step = 4301 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.857\n",
      "INFO:tensorflow:loss = 0.8738433, step = 4401 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.55\n",
      "INFO:tensorflow:loss = 1.6986836, step = 4501 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 318\n",
      "INFO:tensorflow:loss = 6.5627513, step = 4601 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.649\n",
      "INFO:tensorflow:loss = 2.4555895, step = 4701 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.341\n",
      "INFO:tensorflow:loss = 1.5316267, step = 4801 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.063\n",
      "INFO:tensorflow:loss = 3.0255773, step = 4901 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.007\n",
      "INFO:tensorflow:loss = 0.33795986, step = 5001 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.402\n",
      "INFO:tensorflow:loss = 1.0741265, step = 5101 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.581\n",
      "INFO:tensorflow:loss = 0.56546855, step = 5201 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.504\n",
      "INFO:tensorflow:loss = 1.5604244, step = 5301 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.182\n",
      "INFO:tensorflow:loss = 0.1967237, step = 5401 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.504\n",
      "INFO:tensorflow:loss = 0.13094664, step = 5501 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.697\n",
      "INFO:tensorflow:loss = 1.036192, step = 5601 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.678\n",
      "INFO:tensorflow:loss = 0.10209872, step = 5701 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.941\n",
      "INFO:tensorflow:loss = 0.14043622, step = 5801 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.897\n",
      "INFO:tensorflow:loss = 0.65223014, step = 5901 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.5969368, step = 6001 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.571\n",
      "INFO:tensorflow:loss = 0.34215584, step = 6101 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.348\n",
      "INFO:tensorflow:loss = 0.67550355, step = 6201 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.277\n",
      "INFO:tensorflow:loss = 0.5627179, step = 6301 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.807\n",
      "INFO:tensorflow:loss = 2.4058158, step = 6401 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.007\n",
      "INFO:tensorflow:loss = 0.056419168, step = 6501 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.008\n",
      "INFO:tensorflow:loss = 2.0790472, step = 6601 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.579\n",
      "INFO:tensorflow:loss = 0.16584256, step = 6701 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.914\n",
      "INFO:tensorflow:loss = 1.5118386, step = 6801 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.501\n",
      "INFO:tensorflow:loss = 0.6090261, step = 6901 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.552\n",
      "INFO:tensorflow:loss = 0.7387519, step = 7001 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.063\n",
      "INFO:tensorflow:loss = 0.32610756, step = 7101 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.094\n",
      "INFO:tensorflow:loss = 0.24472922, step = 7201 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.337\n",
      "INFO:tensorflow:loss = 0.8017057, step = 7301 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.066\n",
      "INFO:tensorflow:loss = 0.18349965, step = 7401 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.549\n",
      "INFO:tensorflow:loss = 1.3500599, step = 7501 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.531\n",
      "INFO:tensorflow:loss = 0.20171207, step = 7601 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.869\n",
      "INFO:tensorflow:loss = 0.3674268, step = 7701 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.931\n",
      "INFO:tensorflow:loss = 0.9194077, step = 7801 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.427\n",
      "INFO:tensorflow:loss = 1.3188441, step = 7901 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.697\n",
      "INFO:tensorflow:loss = 0.12078525, step = 8001 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.002\n",
      "INFO:tensorflow:loss = 1.2290993, step = 8101 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.511\n",
      "INFO:tensorflow:loss = 0.09557147, step = 8201 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.004\n",
      "INFO:tensorflow:loss = 0.4443504, step = 8301 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.504\n",
      "INFO:tensorflow:loss = 1.75257, step = 8401 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.001\n",
      "INFO:tensorflow:loss = 0.10668941, step = 8501 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.182\n",
      "INFO:tensorflow:loss = 1.2296388, step = 8601 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.529\n",
      "INFO:tensorflow:loss = 0.62076885, step = 8701 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.696\n",
      "INFO:tensorflow:loss = 0.1634975, step = 8801 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.827\n",
      "INFO:tensorflow:loss = 0.612033, step = 8901 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.466\n",
      "INFO:tensorflow:loss = 0.10314046, step = 9001 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.65\n",
      "INFO:tensorflow:loss = 2.457348, step = 9101 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.708\n",
      "INFO:tensorflow:loss = 0.15736891, step = 9201 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.678\n",
      "INFO:tensorflow:loss = 0.90630376, step = 9301 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.364\n",
      "INFO:tensorflow:loss = 0.13348068, step = 9401 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.131\n",
      "INFO:tensorflow:loss = 0.2664503, step = 9501 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.277\n",
      "INFO:tensorflow:loss = 0.060283516, step = 9601 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.365\n",
      "INFO:tensorflow:loss = 0.6503866, step = 9701 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.186\n",
      "INFO:tensorflow:loss = 0.16003639, step = 9801 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.179\n",
      "INFO:tensorflow:loss = 0.69780797, step = 9901 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.275\n",
      "INFO:tensorflow:loss = 0.56437135, step = 10001 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.697\n",
      "INFO:tensorflow:loss = 0.10127845, step = 10101 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.62\n",
      "INFO:tensorflow:loss = 0.2916431, step = 10201 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.094\n",
      "INFO:tensorflow:loss = 3.183115, step = 10301 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.571\n",
      "INFO:tensorflow:loss = 0.542058, step = 10401 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.259\n",
      "INFO:tensorflow:loss = 0.6856138, step = 10501 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.39\n",
      "INFO:tensorflow:loss = 0.015568632, step = 10601 (0.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.75\n",
      "INFO:tensorflow:loss = 0.42236054, step = 10701 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.517\n",
      "INFO:tensorflow:loss = 0.14542009, step = 10801 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.021\n",
      "INFO:tensorflow:loss = 0.18415274, step = 10901 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.136\n",
      "INFO:tensorflow:loss = 0.38750604, step = 11001 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.825\n",
      "INFO:tensorflow:loss = 0.4252187, step = 11101 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.529\n",
      "INFO:tensorflow:loss = 0.2995029, step = 11201 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.551\n",
      "INFO:tensorflow:loss = 0.18791832, step = 11301 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.58\n",
      "INFO:tensorflow:loss = 0.037296727, step = 11401 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.504\n",
      "INFO:tensorflow:loss = 0.485224, step = 11501 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.001\n",
      "INFO:tensorflow:loss = 0.016625922, step = 11601 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.517\n",
      "INFO:tensorflow:loss = 0.87116545, step = 11701 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.804\n",
      "INFO:tensorflow:loss = 0.14596091, step = 11801 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.749\n",
      "INFO:tensorflow:loss = 0.119700186, step = 11901 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.651\n",
      "INFO:tensorflow:loss = 0.201757, step = 12001 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.581\n",
      "INFO:tensorflow:loss = 0.028864173, step = 12101 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.869\n",
      "INFO:tensorflow:loss = 0.632051, step = 12201 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.064\n",
      "INFO:tensorflow:loss = 0.059195798, step = 12301 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.039\n",
      "INFO:tensorflow:loss = 0.016783338, step = 12401 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.403\n",
      "INFO:tensorflow:loss = 0.088354275, step = 12501 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.013\n",
      "INFO:tensorflow:loss = 0.19060169, step = 12601 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.098\n",
      "INFO:tensorflow:loss = 0.8462033, step = 12701 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.55\n",
      "INFO:tensorflow:loss = 0.24816376, step = 12801 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.501\n",
      "INFO:tensorflow:loss = 0.13580763, step = 12901 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.673\n",
      "INFO:tensorflow:loss = 0.06733804, step = 13001 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.095\n",
      "INFO:tensorflow:loss = 0.028583305, step = 13101 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.652\n",
      "INFO:tensorflow:loss = 0.047620054, step = 13201 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.652\n",
      "INFO:tensorflow:loss = 0.5568242, step = 13301 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.619\n",
      "INFO:tensorflow:loss = 0.117144026, step = 13401 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.79\n",
      "INFO:tensorflow:loss = 0.13840438, step = 13501 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.234\n",
      "INFO:tensorflow:loss = 0.17273906, step = 13601 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.002\n",
      "INFO:tensorflow:loss = 0.090042576, step = 13701 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.174\n",
      "INFO:tensorflow:loss = 0.031738326, step = 13801 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.177\n",
      "INFO:tensorflow:loss = 0.2742188, step = 13901 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.748\n",
      "INFO:tensorflow:loss = 1.1075518, step = 14001 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.652\n",
      "INFO:tensorflow:loss = 0.103785925, step = 14101 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.19228835, step = 14201 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.222\n",
      "INFO:tensorflow:loss = 0.112812564, step = 14301 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.513\n",
      "INFO:tensorflow:loss = 0.30240288, step = 14401 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.514\n",
      "INFO:tensorflow:loss = 0.04321298, step = 14501 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.021\n",
      "INFO:tensorflow:loss = 0.0630395, step = 14601 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.529\n",
      "INFO:tensorflow:loss = 0.045541193, step = 14701 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.137\n",
      "INFO:tensorflow:loss = 0.05754641, step = 14801 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.001\n",
      "INFO:tensorflow:loss = 0.019886006, step = 14901 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 317\n",
      "INFO:tensorflow:loss = 0.037355676, step = 15001 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.554\n",
      "INFO:tensorflow:loss = 0.027062211, step = 15101 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.276\n",
      "INFO:tensorflow:loss = 0.014688078, step = 15201 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.467\n",
      "INFO:tensorflow:loss = 0.06361385, step = 15301 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.04\n",
      "INFO:tensorflow:loss = 0.6213593, step = 15401 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.173\n",
      "INFO:tensorflow:loss = 0.050863773, step = 15501 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.064\n",
      "INFO:tensorflow:loss = 0.010508629, step = 15601 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.58\n",
      "INFO:tensorflow:loss = 0.07831684, step = 15701 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.092\n",
      "INFO:tensorflow:loss = 0.04796457, step = 15801 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.612\n",
      "INFO:tensorflow:loss = 0.033205606, step = 15901 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.222\n",
      "INFO:tensorflow:loss = 0.040476743, step = 16001 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.501\n",
      "INFO:tensorflow:loss = 0.19931108, step = 16101 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.007\n",
      "INFO:tensorflow:loss = 0.043902475, step = 16201 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.338\n",
      "INFO:tensorflow:loss = 0.05358656, step = 16301 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.335\n",
      "INFO:tensorflow:loss = 0.07209507, step = 16401 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.674\n",
      "INFO:tensorflow:loss = 0.061709024, step = 16501 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.098\n",
      "INFO:tensorflow:loss = 0.044062603, step = 16601 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.501\n",
      "INFO:tensorflow:loss = 0.037283592, step = 16701 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.685\n",
      "INFO:tensorflow:loss = 0.097473845, step = 16801 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.787\n",
      "INFO:tensorflow:loss = 0.047118567, step = 16901 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.235\n",
      "INFO:tensorflow:loss = 0.19816628, step = 17001 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.844\n",
      "INFO:tensorflow:loss = 0.18563597, step = 17101 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.276\n",
      "INFO:tensorflow:loss = 1.0058981, step = 17201 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.02\n",
      "INFO:tensorflow:loss = 0.04370185, step = 17301 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.764\n",
      "INFO:tensorflow:loss = 0.098393366, step = 17401 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.879\n",
      "INFO:tensorflow:loss = 0.08123408, step = 17501 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.038\n",
      "INFO:tensorflow:loss = 0.008505832, step = 17601 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.482\n",
      "INFO:tensorflow:loss = 0.052075956, step = 17701 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.607\n",
      "INFO:tensorflow:loss = 0.16734523, step = 17801 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.897\n",
      "INFO:tensorflow:loss = 0.015022509, step = 17901 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.976\n",
      "INFO:tensorflow:loss = 0.387591, step = 18001 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.092\n",
      "INFO:tensorflow:loss = 0.036231108, step = 18101 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.02\n",
      "INFO:tensorflow:loss = 0.060664058, step = 18201 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.879\n",
      "INFO:tensorflow:loss = 0.0997779, step = 18301 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.846\n",
      "INFO:tensorflow:loss = 0.04017047, step = 18401 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.054\n",
      "INFO:tensorflow:loss = 0.062370356, step = 18501 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.856\n",
      "INFO:tensorflow:loss = 0.06859529, step = 18601 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.432\n",
      "INFO:tensorflow:loss = 0.13303998, step = 18701 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.02\n",
      "INFO:tensorflow:loss = 0.041182585, step = 18801 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.6\n",
      "INFO:tensorflow:loss = 0.026497038, step = 18901 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.638\n",
      "INFO:tensorflow:loss = 0.20979287, step = 19001 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.879\n",
      "INFO:tensorflow:loss = 0.0019135968, step = 19101 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.988\n",
      "INFO:tensorflow:loss = 0.13263468, step = 19201 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.717\n",
      "INFO:tensorflow:loss = 0.0029513752, step = 19301 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.097\n",
      "INFO:tensorflow:loss = 0.007575876, step = 19401 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.679\n",
      "INFO:tensorflow:loss = 0.21172146, step = 19501 (0.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.33\n",
      "INFO:tensorflow:loss = 0.045700092, step = 19601 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.563\n",
      "INFO:tensorflow:loss = 0.025713991, step = 19701 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.014\n",
      "INFO:tensorflow:loss = 0.0026160225, step = 19801 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.541\n",
      "INFO:tensorflow:loss = 0.10787608, step = 19901 (0.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.207\n",
      "INFO:tensorflow:loss = 0.037653804, step = 20001 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.448\n",
      "INFO:tensorflow:loss = 0.023240687, step = 20101 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.586\n",
      "INFO:tensorflow:loss = 0.04265459, step = 20201 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.042\n",
      "INFO:tensorflow:loss = 0.021643091, step = 20301 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.291\n",
      "INFO:tensorflow:loss = 0.060978167, step = 20401 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.739\n",
      "INFO:tensorflow:loss = 0.14101139, step = 20501 (0.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.618\n",
      "INFO:tensorflow:loss = 0.02550784, step = 20601 (0.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.079\n",
      "INFO:tensorflow:loss = 0.12878802, step = 20701 (0.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.636\n",
      "INFO:tensorflow:loss = 0.07150811, step = 20801 (0.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.073\n",
      "INFO:tensorflow:loss = 0.013635546, step = 20901 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.556\n",
      "INFO:tensorflow:loss = 0.02472791, step = 21001 (0.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.739\n",
      "INFO:tensorflow:loss = 0.05550095, step = 21101 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.103\n",
      "INFO:tensorflow:loss = 0.03286851, step = 21201 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.531\n",
      "INFO:tensorflow:loss = 0.087597534, step = 21301 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.92\n",
      "INFO:tensorflow:loss = 0.001765556, step = 21401 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.921\n",
      "INFO:tensorflow:loss = 0.026595252, step = 21501 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.584\n",
      "INFO:tensorflow:loss = 0.009230725, step = 21601 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.814\n",
      "INFO:tensorflow:loss = 0.04495737, step = 21701 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.843\n",
      "INFO:tensorflow:loss = 0.021201544, step = 21801 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.881\n",
      "INFO:tensorflow:loss = 0.032849856, step = 21901 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.277\n",
      "INFO:tensorflow:loss = 0.0013476217, step = 22001 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.763\n",
      "INFO:tensorflow:loss = 0.04072228, step = 22101 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.145\n",
      "INFO:tensorflow:loss = 0.022291662, step = 22201 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.04711197, step = 22301 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.02\n",
      "INFO:tensorflow:loss = 0.023736654, step = 22401 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.278\n",
      "INFO:tensorflow:loss = 0.03293419, step = 22501 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.297\n",
      "INFO:tensorflow:loss = 0.03715956, step = 22601 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.197\n",
      "INFO:tensorflow:loss = 0.10973466, step = 22701 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.879\n",
      "INFO:tensorflow:loss = 0.028407732, step = 22801 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.277\n",
      "INFO:tensorflow:loss = 0.044864442, step = 22901 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.245\n",
      "INFO:tensorflow:loss = 0.014238668, step = 23001 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.561\n",
      "INFO:tensorflow:loss = 0.059341755, step = 23101 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.82\n",
      "INFO:tensorflow:loss = 0.2070167, step = 23201 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.718\n",
      "INFO:tensorflow:loss = 0.026845302, step = 23301 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.415\n",
      "INFO:tensorflow:loss = 0.006735508, step = 23401 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.639\n",
      "INFO:tensorflow:loss = 0.0030479375, step = 23501 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.296\n",
      "INFO:tensorflow:loss = 0.026648961, step = 23601 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.463\n",
      "INFO:tensorflow:loss = 0.019386819, step = 23701 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.277\n",
      "INFO:tensorflow:loss = 0.017153617, step = 23801 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.81\n",
      "INFO:tensorflow:loss = 0.016260179, step = 23901 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.278\n",
      "INFO:tensorflow:loss = 0.044779427, step = 24001 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.638\n",
      "INFO:tensorflow:loss = 0.073692076, step = 24101 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.717\n",
      "INFO:tensorflow:loss = 0.024258679, step = 24201 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.563\n",
      "INFO:tensorflow:loss = 0.093960196, step = 24301 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.529\n",
      "INFO:tensorflow:loss = 0.050714966, step = 24401 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.717\n",
      "INFO:tensorflow:loss = 0.0117009105, step = 24501 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.844\n",
      "INFO:tensorflow:loss = 0.02919381, step = 24601 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.472\n",
      "INFO:tensorflow:loss = 0.010186611, step = 24701 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.19\n",
      "INFO:tensorflow:loss = 0.029644905, step = 24801 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.293\n",
      "INFO:tensorflow:loss = 0.13603584, step = 24901 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.581\n",
      "INFO:tensorflow:loss = 0.051331986, step = 25001 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.615\n",
      "INFO:tensorflow:loss = 0.037599526, step = 25101 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.552\n",
      "INFO:tensorflow:loss = 0.049539465, step = 25201 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.501\n",
      "INFO:tensorflow:loss = 0.030918423, step = 25301 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.658\n",
      "INFO:tensorflow:loss = 0.049465664, step = 25401 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.659\n",
      "INFO:tensorflow:loss = 0.008883159, step = 25501 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.824\n",
      "INFO:tensorflow:loss = 0.026014615, step = 25601 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.067\n",
      "INFO:tensorflow:loss = 0.018360266, step = 25701 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.433\n",
      "INFO:tensorflow:loss = 0.008410704, step = 25801 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.097\n",
      "INFO:tensorflow:loss = 0.0018663822, step = 25901 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.764\n",
      "INFO:tensorflow:loss = 0.13577381, step = 26001 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.826\n",
      "INFO:tensorflow:loss = 0.09360829, step = 26101 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.615\n",
      "INFO:tensorflow:loss = 0.023803687, step = 26201 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.826\n",
      "INFO:tensorflow:loss = 0.045332354, step = 26301 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.552\n",
      "INFO:tensorflow:loss = 0.07137604, step = 26401 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.469\n",
      "INFO:tensorflow:loss = 0.05239744, step = 26501 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.243\n",
      "INFO:tensorflow:loss = 0.028035617, step = 26601 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.098\n",
      "INFO:tensorflow:loss = 0.0049515357, step = 26701 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.294\n",
      "INFO:tensorflow:loss = 0.004841755, step = 26801 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.58\n",
      "INFO:tensorflow:loss = 0.02716945, step = 26901 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.503\n",
      "INFO:tensorflow:loss = 0.033361226, step = 27001 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.505\n",
      "INFO:tensorflow:loss = 0.05526428, step = 27101 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.097\n",
      "INFO:tensorflow:loss = 0.056819167, step = 27201 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.659\n",
      "INFO:tensorflow:loss = 0.017581986, step = 27301 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.58\n",
      "INFO:tensorflow:loss = 0.008064799, step = 27401 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.04\n",
      "INFO:tensorflow:loss = 0.027165126, step = 27501 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.04\n",
      "INFO:tensorflow:loss = 0.013088355, step = 27601 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.098\n",
      "INFO:tensorflow:loss = 0.023121804, step = 27701 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.235\n",
      "INFO:tensorflow:loss = 0.0075894673, step = 27801 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.803\n",
      "INFO:tensorflow:loss = 0.13724566, step = 27901 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.767\n",
      "INFO:tensorflow:loss = 0.022933679, step = 28001 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.515\n",
      "INFO:tensorflow:loss = 0.0014788427, step = 28101 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.019\n",
      "INFO:tensorflow:loss = 0.08005433, step = 28201 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.295\n",
      "INFO:tensorflow:loss = 0.008248318, step = 28301 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.182\n",
      "INFO:tensorflow:loss = 0.0030656534, step = 28401 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.097\n",
      "INFO:tensorflow:loss = 0.019606974, step = 28501 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.295\n",
      "INFO:tensorflow:loss = 0.023108318, step = 28601 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.528\n",
      "INFO:tensorflow:loss = 0.022020346, step = 28701 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.183\n",
      "INFO:tensorflow:loss = 0.0032337136, step = 28801 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.513\n",
      "INFO:tensorflow:loss = 0.005418091, step = 28901 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.706\n",
      "INFO:tensorflow:loss = 0.0042622793, step = 29001 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.431\n",
      "INFO:tensorflow:loss = 0.020911785, step = 29101 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.573\n",
      "INFO:tensorflow:loss = 0.007993084, step = 29201 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.472\n",
      "INFO:tensorflow:loss = 0.00096425205, step = 29301 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.915\n",
      "INFO:tensorflow:loss = 0.00698281, step = 29401 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.187\n",
      "INFO:tensorflow:loss = 0.021394376, step = 29501 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.451\n",
      "INFO:tensorflow:loss = 0.015168247, step = 29601 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.583\n",
      "INFO:tensorflow:loss = 0.025098426, step = 29701 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.798\n",
      "INFO:tensorflow:loss = 0.028108787, step = 29801 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.146\n",
      "INFO:tensorflow:loss = 0.008385321, step = 29901 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.697\n",
      "INFO:tensorflow:loss = 0.015592864, step = 30001 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.598\n",
      "INFO:tensorflow:loss = 0.004498259, step = 30101 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.819\n",
      "INFO:tensorflow:loss = 0.02083147, step = 30201 (0.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.895\n",
      "INFO:tensorflow:loss = 0.02363854, step = 30301 (0.340 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 319.009\n",
      "INFO:tensorflow:loss = 0.015131084, step = 30401 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.616\n",
      "INFO:tensorflow:loss = 0.03946775, step = 30501 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.064\n",
      "INFO:tensorflow:loss = 0.017163537, step = 30601 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.617\n",
      "INFO:tensorflow:loss = 0.01722853, step = 30701 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.181\n",
      "INFO:tensorflow:loss = 0.0028859582, step = 30801 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.055\n",
      "INFO:tensorflow:loss = 0.033945613, step = 30901 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.007\n",
      "INFO:tensorflow:loss = 0.027603608, step = 31001 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.897\n",
      "INFO:tensorflow:loss = 0.022059305, step = 31101 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.173\n",
      "INFO:tensorflow:loss = 0.00028167965, step = 31201 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.845\n",
      "INFO:tensorflow:loss = 0.017346025, step = 31301 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.513\n",
      "INFO:tensorflow:loss = 0.0069917534, step = 31401 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.846\n",
      "INFO:tensorflow:loss = 0.006120302, step = 31501 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.651\n",
      "INFO:tensorflow:loss = 0.0088182315, step = 31601 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.095\n",
      "INFO:tensorflow:loss = 0.012703214, step = 31701 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.717\n",
      "INFO:tensorflow:loss = 0.007052093, step = 31801 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.02\n",
      "INFO:tensorflow:loss = 0.0061752107, step = 31901 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.365\n",
      "INFO:tensorflow:loss = 0.039902825, step = 32001 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.637\n",
      "INFO:tensorflow:loss = 0.027020346, step = 32101 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.128\n",
      "INFO:tensorflow:loss = 0.015809778, step = 32201 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.715\n",
      "INFO:tensorflow:loss = 0.010423603, step = 32301 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.765\n",
      "INFO:tensorflow:loss = 0.037750483, step = 32401 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.293\n",
      "INFO:tensorflow:loss = 0.01013202, step = 32501 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.6\n",
      "INFO:tensorflow:loss = 0.051419076, step = 32601 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.139\n",
      "INFO:tensorflow:loss = 0.04210964, step = 32701 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.469\n",
      "INFO:tensorflow:loss = 0.042427257, step = 32801 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.474\n",
      "INFO:tensorflow:loss = 0.042565607, step = 32901 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.245\n",
      "INFO:tensorflow:loss = 0.011023395, step = 33001 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.277\n",
      "INFO:tensorflow:loss = 0.009380928, step = 33101 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.676\n",
      "INFO:tensorflow:loss = 0.018012486, step = 33201 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.275\n",
      "INFO:tensorflow:loss = 0.060437933, step = 33301 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.618\n",
      "INFO:tensorflow:loss = 0.055445, step = 33401 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.49\n",
      "INFO:tensorflow:loss = 0.011771059, step = 33501 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.584\n",
      "INFO:tensorflow:loss = 0.004767617, step = 33601 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.189\n",
      "INFO:tensorflow:loss = 0.0043661944, step = 33701 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.879\n",
      "INFO:tensorflow:loss = 0.010116158, step = 33801 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.337\n",
      "INFO:tensorflow:loss = 0.0073103937, step = 33901 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.019\n",
      "INFO:tensorflow:loss = 0.02640384, step = 34001 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.415\n",
      "INFO:tensorflow:loss = 0.009867463, step = 34101 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.51\n",
      "INFO:tensorflow:loss = 0.011333032, step = 34201 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.097\n",
      "INFO:tensorflow:loss = 0.030286826, step = 34301 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.092\n",
      "INFO:tensorflow:loss = 0.038977243, step = 34401 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.634\n",
      "INFO:tensorflow:loss = 0.013973473, step = 34501 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.564\n",
      "INFO:tensorflow:loss = 0.011356727, step = 34601 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.019\n",
      "INFO:tensorflow:loss = 0.079231165, step = 34701 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.531\n",
      "INFO:tensorflow:loss = 0.03362925, step = 34801 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.974\n",
      "INFO:tensorflow:loss = 0.034159034, step = 34901 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.718\n",
      "INFO:tensorflow:loss = 0.010217876, step = 35001 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.764\n",
      "INFO:tensorflow:loss = 0.01988252, step = 35101 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.466\n",
      "INFO:tensorflow:loss = 0.0068276245, step = 35201 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.695\n",
      "INFO:tensorflow:loss = 0.016478553, step = 35301 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.795\n",
      "INFO:tensorflow:loss = 0.013238734, step = 35401 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.804\n",
      "INFO:tensorflow:loss = 0.014382575, step = 35501 (0.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.501\n",
      "INFO:tensorflow:loss = 0.024007186, step = 35601 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.708\n",
      "INFO:tensorflow:loss = 0.032662988, step = 35701 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.762\n",
      "INFO:tensorflow:loss = 0.060626663, step = 35801 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.298\n",
      "INFO:tensorflow:loss = 0.009208001, step = 35901 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.878\n",
      "INFO:tensorflow:loss = 0.03395463, step = 36001 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.147\n",
      "INFO:tensorflow:loss = 0.009854412, step = 36101 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.174\n",
      "INFO:tensorflow:loss = 0.038390875, step = 36201 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.613\n",
      "INFO:tensorflow:loss = 0.02028842, step = 36301 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.529\n",
      "INFO:tensorflow:loss = 0.00694484, step = 36401 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.244\n",
      "INFO:tensorflow:loss = 0.03631453, step = 36501 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.023\n",
      "INFO:tensorflow:loss = 0.02339653, step = 36601 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.512\n",
      "INFO:tensorflow:loss = 0.01564426, step = 36701 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.245\n",
      "INFO:tensorflow:loss = 0.015404871, step = 36801 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.244\n",
      "INFO:tensorflow:loss = 0.01872774, step = 36901 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.462\n",
      "INFO:tensorflow:loss = 0.0033925807, step = 37001 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.349\n",
      "INFO:tensorflow:loss = 0.0110594155, step = 37101 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.462\n",
      "INFO:tensorflow:loss = 0.014667411, step = 37201 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.323\n",
      "INFO:tensorflow:loss = 0.03495404, step = 37301 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.809\n",
      "INFO:tensorflow:loss = 0.0038725003, step = 37401 (0.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.915\n",
      "INFO:tensorflow:loss = 0.02090538, step = 37501 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.294\n",
      "INFO:tensorflow:loss = 0.03055623, step = 37601 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.043\n",
      "INFO:tensorflow:loss = 0.011866359, step = 37701 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.513\n",
      "INFO:tensorflow:loss = 0.00507013, step = 37801 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.6\n",
      "INFO:tensorflow:loss = 0.019282453, step = 37901 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.137\n",
      "INFO:tensorflow:loss = 0.038448587, step = 38001 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.091\n",
      "INFO:tensorflow:loss = 0.015820842, step = 38101 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.197\n",
      "INFO:tensorflow:loss = 0.01789013, step = 38201 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.146\n",
      "INFO:tensorflow:loss = 0.0059232, step = 38301 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.054\n",
      "INFO:tensorflow:loss = 0.0034145694, step = 38401 (0.337 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 322.58\n",
      "INFO:tensorflow:loss = 0.021211054, step = 38501 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.092\n",
      "INFO:tensorflow:loss = 0.007803443, step = 38601 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.348\n",
      "INFO:tensorflow:loss = 0.012723366, step = 38701 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.013\n",
      "INFO:tensorflow:loss = 0.0032236779, step = 38801 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.512\n",
      "INFO:tensorflow:loss = 0.023477228, step = 38901 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.145\n",
      "INFO:tensorflow:loss = 0.008342049, step = 39001 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.897\n",
      "INFO:tensorflow:loss = 0.0032565354, step = 39101 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.528\n",
      "INFO:tensorflow:loss = 0.04876249, step = 39201 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.51\n",
      "INFO:tensorflow:loss = 0.003104611, step = 39301 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.293\n",
      "INFO:tensorflow:loss = 0.028977878, step = 39401 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.04\n",
      "INFO:tensorflow:loss = 0.023847979, step = 39501 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.137\n",
      "INFO:tensorflow:loss = 0.014112674, step = 39601 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.896\n",
      "INFO:tensorflow:loss = 0.0065757227, step = 39701 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.181\n",
      "INFO:tensorflow:loss = 0.0038417256, step = 39801 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.47\n",
      "INFO:tensorflow:loss = 0.0164116, step = 39901 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.335\n",
      "INFO:tensorflow:loss = 0.0019389619, step = 40001 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.906\n",
      "INFO:tensorflow:loss = 0.0043155556, step = 40101 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.749\n",
      "INFO:tensorflow:loss = 0.019937187, step = 40201 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.686\n",
      "INFO:tensorflow:loss = 0.014997156, step = 40301 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.177\n",
      "INFO:tensorflow:loss = 0.01400532, step = 40401 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.807\n",
      "INFO:tensorflow:loss = 0.008218212, step = 40501 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.234\n",
      "INFO:tensorflow:loss = 0.008472962, step = 40601 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.012\n",
      "INFO:tensorflow:loss = 0.028301343, step = 40701 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.551\n",
      "INFO:tensorflow:loss = 0.0069537302, step = 40801 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.612\n",
      "INFO:tensorflow:loss = 0.0281752, step = 40901 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.348\n",
      "INFO:tensorflow:loss = 0.04151768, step = 41001 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.716\n",
      "INFO:tensorflow:loss = 0.0019478383, step = 41101 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.709\n",
      "INFO:tensorflow:loss = 0.06894539, step = 41201 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.13\n",
      "INFO:tensorflow:loss = 0.01499956, step = 41301 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.137\n",
      "INFO:tensorflow:loss = 0.0011112952, step = 41401 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.147\n",
      "INFO:tensorflow:loss = 0.0030193767, step = 41501 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.928\n",
      "INFO:tensorflow:loss = 0.009511845, step = 41601 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.819\n",
      "INFO:tensorflow:loss = 0.0005387839, step = 41701 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.363\n",
      "INFO:tensorflow:loss = 0.013869493, step = 41801 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.879\n",
      "INFO:tensorflow:loss = 0.0011733858, step = 41901 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.56\n",
      "INFO:tensorflow:loss = 0.013391124, step = 42001 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.677\n",
      "INFO:tensorflow:loss = 0.025036467, step = 42101 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.408\n",
      "INFO:tensorflow:loss = 0.014032267, step = 42201 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.467\n",
      "INFO:tensorflow:loss = 0.006305003, step = 42301 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.512\n",
      "INFO:tensorflow:loss = 0.021769227, step = 42401 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.514\n",
      "INFO:tensorflow:loss = 0.00463281, step = 42501 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.748\n",
      "INFO:tensorflow:loss = 0.009395065, step = 42601 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.129\n",
      "INFO:tensorflow:loss = 0.020314388, step = 42701 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.02\n",
      "INFO:tensorflow:loss = 0.0011049364, step = 42801 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.009\n",
      "INFO:tensorflow:loss = 0.017299846, step = 42901 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.268\n",
      "INFO:tensorflow:loss = 0.003005641, step = 43001 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.601\n",
      "INFO:tensorflow:loss = 0.014462798, step = 43101 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.562\n",
      "INFO:tensorflow:loss = 0.009086992, step = 43201 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.988\n",
      "INFO:tensorflow:loss = 0.0040752264, step = 43301 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.276\n",
      "INFO:tensorflow:loss = 0.0060179406, step = 43401 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.584\n",
      "INFO:tensorflow:loss = 0.004954128, step = 43501 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.276\n",
      "INFO:tensorflow:loss = 0.005526409, step = 43601 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.433\n",
      "INFO:tensorflow:loss = 0.01881664, step = 43701 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.615\n",
      "INFO:tensorflow:loss = 0.0054247906, step = 43801 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.608\n",
      "INFO:tensorflow:loss = 0.009961581, step = 43901 (0.348 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 44000 into C:\\Users\\jeong\\AppData\\Local\\Temp\\tmp8acdsdbe\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.024192128.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x295dfc1bf98>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature_cols = tf.contrib.learn.infer_real_valued_columns_from_input(X_train)\n",
    "# dnn_clf = tf.contrib.learn.DNNClassifier(hidden_units=[300, 100, n_classes=10,\n",
    "#                                  feature_columns=feature_cols])\n",
    "# dnn_clf = tf.contrib.learn.SKCompat(dnn_clf) # 텐서플로 1.1 이상일 때\n",
    "# dnn_clf.fit(X_train, y_train, batch_size=50, steps=40000)\n",
    "feature_cols = [tf.feature_column.numeric_column('X', shape=[28 * 28])]\n",
    "dnn_clf = tf.estimator.DNNClassifier(hidden_units=[300, 100], n_classes=10,\n",
    "                                   feature_columns=feature_cols)\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(x={'X': X_train}, y=y_train,\n",
    "                                        num_epochs=40, batch_size=50, shuffle=True)\n",
    "dnn_clf.train(input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 코드를 (scikit-learn의 `StandardScaler` 같은 것으로 스케일 조정 후) MNIST 데이터셋에 대해 실행하면 테스트 세트에서 98.2% 정도의 정확도를 내는 모델을 얻을 것이다.\n",
    "> 이는 3장에서 훈련시킨 가장 좋은 모델보다도 성능이 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-15-11:40:05\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\jeong\\AppData\\Local\\Temp\\tmp8acdsdbe\\model.ckpt-44000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-15-11:40:05\n",
      "INFO:tensorflow:Saving dict for global step 44000: accuracy = 0.9808, average_loss = 0.09843598, global_step = 44000, loss = 12.460252\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 44000: C:\\Users\\jeong\\AppData\\Local\\Temp\\tmp8acdsdbe\\model.ckpt-44000\n"
     ]
    }
   ],
   "source": [
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(x={'X': X_test}, y=y_test,\n",
    "                                                  shuffle=False)\n",
    "eval_results = dnn_clf.evaluate(input_fn=test_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9808,\n",
       " 'average_loss': 0.09843598,\n",
       " 'loss': 12.460252,\n",
       " 'global_step': 44000}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\jeong\\AppData\\Local\\Temp\\tmp8acdsdbe\\model.ckpt-44000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'logits': array([ -7.845613  ,  -2.544741  ,   0.79239553,   3.735981  ,\n",
       "         -9.8576765 ,  -8.508776  , -16.643377  ,  22.948847  ,\n",
       "          1.0697927 ,   3.5569172 ], dtype=float32),\n",
       " 'probabilities': array([4.2280083e-14, 8.4776526e-12, 2.3854763e-10, 4.5285420e-09,\n",
       "        5.6533825e-15, 2.1783522e-14, 6.3872736e-18, 1.0000000e+00,\n",
       "        3.1480901e-10, 3.7860990e-09], dtype=float32),\n",
       " 'class_ids': array([7], dtype=int64),\n",
       " 'classes': array([b'7'], dtype=object)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_iter = dnn_clf.predict(input_fn=test_input_fn)\n",
    "y_pred = list(y_pred_iter)\n",
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * 내부를 보면 `DNNClassifier` 클래스가 ReLU 활성화 함수(`activation_fn` 매개변수로 변경 가능)를 기반으로 한 뉴런 층을 만든다.  \n",
    "* 출력층은 softmax 함수고 비용함수는 cross entropy이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. `tf.conrib.learn` 사용 (구버전 API 인 듯)\n",
    "> **CAUTION**  \n",
    "`tensorflow.contrib` 패키지는 유용한 함수를 많이 포함하고 있지만 이곳의 코드는 실험적이며 텐서플로의 핵심 API로 편입된다는 보장이 없다.  \n",
    "그러므로 `DNNClassifier` (그리고 다른 `contrib` 패키지)는 미래에 예고없이 변경될 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "# mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "\n",
    "# X_train = mnist.train.images\n",
    "# X_test = mnist.test.images\n",
    "# y_train = mnist.train.labels.astype(\"int\")\n",
    "# y_test = mnist.test.labels.astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-19-2c799017b513>:1: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "WARNING:tensorflow:From <ipython-input-19-2c799017b513>:3: infer_real_valued_columns_from_input (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please specify feature columns explicitly.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:143: setup_train_data_feeder (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\data_feeder.py:96: extract_dask_data (from tensorflow.contrib.learn.python.learn.learn_io.dask_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please feed input to tf.data to support dask.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\data_feeder.py:100: extract_pandas_data (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please access pandas data directly.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\data_feeder.py:159: DataFeeder.__init__ (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\data_feeder.py:340: check_array (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please convert numpy dtypes explicitly.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:183: infer_real_valued_columns_from_input_fn (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please specify feature columns explicitly.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:378: multi_class_head (from tensorflow.contrib.learn.python.learn.estimators.head) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.contrib.estimator.*_head.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:1180: BaseEstimator.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please replace uses of any Estimator from tf.contrib.learn with an Estimator from tf.estimator.*\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\jeong\\AppData\\Local\\Temp\\tmp4kztcz7v\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000029585E53E10>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': 42, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'C:\\\\Users\\\\jeong\\\\AppData\\\\Local\\\\Temp\\\\tmp4kztcz7v'}\n",
      "WARNING:tensorflow:From <ipython-input-19-2c799017b513>:6: SKCompat.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to the Estimator interface.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\data_feeder.py:98: extract_dask_labels (from tensorflow.contrib.learn.python.learn.learn_io.dask_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please feed input to tf.data to support dask.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\data_feeder.py:102: extract_pandas_labels (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please access pandas data directly.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:678: ModelFnOps.__new__ (from tensorflow.contrib.learn.python.learn.estimators.model_fn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.EstimatorSpec. You can use the `estimator_spec` method to create an equivalent one.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\jeong\\AppData\\Local\\Temp\\tmp4kztcz7v\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.4005778, step = 1\n",
      "INFO:tensorflow:global_step/sec: 301.368\n",
      "INFO:tensorflow:loss = 0.31267586, step = 101 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.182\n",
      "INFO:tensorflow:loss = 0.29636884, step = 201 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.551\n",
      "INFO:tensorflow:loss = 0.40807673, step = 301 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.313\n",
      "INFO:tensorflow:loss = 0.23435777, step = 401 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.962\n",
      "INFO:tensorflow:loss = 0.2913079, step = 501 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.388\n",
      "INFO:tensorflow:loss = 0.07167664, step = 601 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.202\n",
      "INFO:tensorflow:loss = 0.14161874, step = 701 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.492\n",
      "INFO:tensorflow:loss = 0.20138769, step = 801 (0.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.208\n",
      "INFO:tensorflow:loss = 0.11518532, step = 901 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.966\n",
      "INFO:tensorflow:loss = 0.24996702, step = 1001 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.169\n",
      "INFO:tensorflow:loss = 0.18783635, step = 1101 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.805\n",
      "INFO:tensorflow:loss = 0.15286086, step = 1201 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.904\n",
      "INFO:tensorflow:loss = 0.18098913, step = 1301 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.383\n",
      "INFO:tensorflow:loss = 0.074944526, step = 1401 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.016\n",
      "INFO:tensorflow:loss = 0.11897224, step = 1501 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.6\n",
      "INFO:tensorflow:loss = 0.08685669, step = 1601 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.179\n",
      "INFO:tensorflow:loss = 0.03668785, step = 1701 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.459\n",
      "INFO:tensorflow:loss = 0.15879871, step = 1801 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.235\n",
      "INFO:tensorflow:loss = 0.10420776, step = 1901 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.338\n",
      "INFO:tensorflow:loss = 0.12085897, step = 2001 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.582\n",
      "INFO:tensorflow:loss = 0.018375002, step = 2101 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.674\n",
      "INFO:tensorflow:loss = 0.023164783, step = 2201 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.019\n",
      "INFO:tensorflow:loss = 0.062178582, step = 2301 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.463\n",
      "INFO:tensorflow:loss = 0.05675999, step = 2401 (0.298 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 363.921\n",
      "INFO:tensorflow:loss = 0.09905958, step = 2501 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.954\n",
      "INFO:tensorflow:loss = 0.052334595, step = 2601 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.296\n",
      "INFO:tensorflow:loss = 0.013862053, step = 2701 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.615\n",
      "INFO:tensorflow:loss = 0.05593559, step = 2801 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.612\n",
      "INFO:tensorflow:loss = 0.17267086, step = 2901 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.47\n",
      "INFO:tensorflow:loss = 0.017047884, step = 3001 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.613\n",
      "INFO:tensorflow:loss = 0.0526542, step = 3101 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.382\n",
      "INFO:tensorflow:loss = 0.0091343345, step = 3201 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.613\n",
      "INFO:tensorflow:loss = 0.0392903, step = 3301 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.241\n",
      "INFO:tensorflow:loss = 0.23619813, step = 3401 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.255\n",
      "INFO:tensorflow:loss = 0.103625685, step = 3501 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.241\n",
      "INFO:tensorflow:loss = 0.1859112, step = 3601 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.568\n",
      "INFO:tensorflow:loss = 0.030802317, step = 3701 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.243\n",
      "INFO:tensorflow:loss = 0.011959711, step = 3801 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.978\n",
      "INFO:tensorflow:loss = 0.058215715, step = 3901 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.904\n",
      "INFO:tensorflow:loss = 0.105658635, step = 4001 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.206\n",
      "INFO:tensorflow:loss = 0.024551766, step = 4101 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.238\n",
      "INFO:tensorflow:loss = 0.05455285, step = 4201 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.47\n",
      "INFO:tensorflow:loss = 0.18137306, step = 4301 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.856\n",
      "INFO:tensorflow:loss = 0.14276299, step = 4401 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.577\n",
      "INFO:tensorflow:loss = 0.01632708, step = 4501 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.229\n",
      "INFO:tensorflow:loss = 0.017191919, step = 4601 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.741\n",
      "INFO:tensorflow:loss = 0.009409002, step = 4701 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.241\n",
      "INFO:tensorflow:loss = 0.025333235, step = 4801 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.528\n",
      "INFO:tensorflow:loss = 0.07839102, step = 4901 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.024\n",
      "INFO:tensorflow:loss = 0.08685464, step = 5001 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.582\n",
      "INFO:tensorflow:loss = 0.014134079, step = 5101 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.383\n",
      "INFO:tensorflow:loss = 0.028086051, step = 5201 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.021\n",
      "INFO:tensorflow:loss = 0.02976975, step = 5301 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.329\n",
      "INFO:tensorflow:loss = 0.03391004, step = 5401 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.095\n",
      "INFO:tensorflow:loss = 0.017171334, step = 5501 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.803\n",
      "INFO:tensorflow:loss = 0.054202244, step = 5601 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.55\n",
      "INFO:tensorflow:loss = 0.008595091, step = 5701 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.653\n",
      "INFO:tensorflow:loss = 0.0073279287, step = 5801 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.512\n",
      "INFO:tensorflow:loss = 0.06256443, step = 5901 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.022\n",
      "INFO:tensorflow:loss = 0.086219504, step = 6001 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.018\n",
      "INFO:tensorflow:loss = 0.014367444, step = 6101 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.516\n",
      "INFO:tensorflow:loss = 0.011423751, step = 6201 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.433\n",
      "INFO:tensorflow:loss = 0.049542535, step = 6301 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.137\n",
      "INFO:tensorflow:loss = 0.028344609, step = 6401 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.584\n",
      "INFO:tensorflow:loss = 0.010745696, step = 6501 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.241\n",
      "INFO:tensorflow:loss = 0.014236839, step = 6601 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.38\n",
      "INFO:tensorflow:loss = 0.01633907, step = 6701 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.33\n",
      "INFO:tensorflow:loss = 0.006029141, step = 6801 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.312\n",
      "INFO:tensorflow:loss = 0.013037648, step = 6901 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.256\n",
      "INFO:tensorflow:loss = 0.021095105, step = 7001 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.104\n",
      "INFO:tensorflow:loss = 0.009951383, step = 7101 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.238\n",
      "INFO:tensorflow:loss = 0.059806768, step = 7201 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.613\n",
      "INFO:tensorflow:loss = 0.009822781, step = 7301 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.022\n",
      "INFO:tensorflow:loss = 0.01747306, step = 7401 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.207\n",
      "INFO:tensorflow:loss = 0.011600788, step = 7501 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.313\n",
      "INFO:tensorflow:loss = 0.0119628105, step = 7601 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.382\n",
      "INFO:tensorflow:loss = 0.0056754327, step = 7701 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.569\n",
      "INFO:tensorflow:loss = 0.004166578, step = 7801 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.838\n",
      "INFO:tensorflow:loss = 0.0064070313, step = 7901 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.38\n",
      "INFO:tensorflow:loss = 0.0022689768, step = 8001 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.668\n",
      "INFO:tensorflow:loss = 0.007141009, step = 8101 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.666\n",
      "INFO:tensorflow:loss = 0.028701648, step = 8201 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.962\n",
      "INFO:tensorflow:loss = 0.024378095, step = 8301 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.837\n",
      "INFO:tensorflow:loss = 0.0057293708, step = 8401 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.569\n",
      "INFO:tensorflow:loss = 0.0048603495, step = 8501 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.471\n",
      "INFO:tensorflow:loss = 0.0071072606, step = 8601 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.579\n",
      "INFO:tensorflow:loss = 0.005018617, step = 8701 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.469\n",
      "INFO:tensorflow:loss = 0.007801614, step = 8801 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.571\n",
      "INFO:tensorflow:loss = 0.0026770572, step = 8901 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.105\n",
      "INFO:tensorflow:loss = 0.0044298144, step = 9001 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.236\n",
      "INFO:tensorflow:loss = 0.008932513, step = 9101 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.312\n",
      "INFO:tensorflow:loss = 0.0043963008, step = 9201 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.315\n",
      "INFO:tensorflow:loss = 0.0051603056, step = 9301 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.47\n",
      "INFO:tensorflow:loss = 0.06253308, step = 9401 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.963\n",
      "INFO:tensorflow:loss = 0.0027877572, step = 9501 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.266\n",
      "INFO:tensorflow:loss = 0.02293391, step = 9601 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.741\n",
      "INFO:tensorflow:loss = 0.005885278, step = 9701 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.383\n",
      "INFO:tensorflow:loss = 0.0018778109, step = 9801 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.58\n",
      "INFO:tensorflow:loss = 0.015558522, step = 9901 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.105\n",
      "INFO:tensorflow:loss = 0.005011304, step = 10001 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.922\n",
      "INFO:tensorflow:loss = 0.0046623275, step = 10101 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.922\n",
      "INFO:tensorflow:loss = 0.010064541, step = 10201 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.237\n",
      "INFO:tensorflow:loss = 0.0021473807, step = 10301 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.207\n",
      "INFO:tensorflow:loss = 0.004164479, step = 10401 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.921\n",
      "INFO:tensorflow:loss = 0.004186794, step = 10501 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.016692484, step = 10601 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.023\n",
      "INFO:tensorflow:loss = 0.023618586, step = 10701 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.904\n",
      "INFO:tensorflow:loss = 0.007049325, step = 10801 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.962\n",
      "INFO:tensorflow:loss = 0.0015864731, step = 10901 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.63\n",
      "INFO:tensorflow:loss = 0.018889226, step = 11001 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.209\n",
      "INFO:tensorflow:loss = 0.0032466408, step = 11101 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.931\n",
      "INFO:tensorflow:loss = 0.0011232384, step = 11201 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.631\n",
      "INFO:tensorflow:loss = 0.008221973, step = 11301 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.613\n",
      "INFO:tensorflow:loss = 0.0057003284, step = 11401 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.741\n",
      "INFO:tensorflow:loss = 0.012616495, step = 11501 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.908\n",
      "INFO:tensorflow:loss = 0.0010653749, step = 11601 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.58\n",
      "INFO:tensorflow:loss = 0.003836335, step = 11701 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.569\n",
      "INFO:tensorflow:loss = 0.00050720846, step = 11801 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.667\n",
      "INFO:tensorflow:loss = 0.0048302053, step = 11901 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.907\n",
      "INFO:tensorflow:loss = 0.0005846591, step = 12001 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.313\n",
      "INFO:tensorflow:loss = 0.0018550919, step = 12101 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.277\n",
      "INFO:tensorflow:loss = 0.002895166, step = 12201 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.763\n",
      "INFO:tensorflow:loss = 0.0057522734, step = 12301 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.896\n",
      "INFO:tensorflow:loss = 0.00047514884, step = 12401 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.562\n",
      "INFO:tensorflow:loss = 0.0014183105, step = 12501 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.294\n",
      "INFO:tensorflow:loss = 0.0032940174, step = 12601 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.187\n",
      "INFO:tensorflow:loss = 0.0031039738, step = 12701 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.349\n",
      "INFO:tensorflow:loss = 0.014574774, step = 12801 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.694\n",
      "INFO:tensorflow:loss = 0.0022034643, step = 12901 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.764\n",
      "INFO:tensorflow:loss = 0.0046686567, step = 13001 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.739\n",
      "INFO:tensorflow:loss = 0.0033246197, step = 13101 (0.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.303\n",
      "INFO:tensorflow:loss = 0.001746688, step = 13201 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.711\n",
      "INFO:tensorflow:loss = 0.010117489, step = 13301 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.276\n",
      "INFO:tensorflow:loss = 0.0064459085, step = 13401 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.462\n",
      "INFO:tensorflow:loss = 0.0036435097, step = 13501 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.933\n",
      "INFO:tensorflow:loss = 0.003998911, step = 13601 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.621\n",
      "INFO:tensorflow:loss = 0.002519967, step = 13701 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.165\n",
      "INFO:tensorflow:loss = 0.0063926624, step = 13801 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.708\n",
      "INFO:tensorflow:loss = 0.0048017786, step = 13901 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.826\n",
      "INFO:tensorflow:loss = 0.0023772058, step = 14001 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.582\n",
      "INFO:tensorflow:loss = 0.008492131, step = 14101 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.583\n",
      "INFO:tensorflow:loss = 0.003959523, step = 14201 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.975\n",
      "INFO:tensorflow:loss = 0.00085805845, step = 14301 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.496\n",
      "INFO:tensorflow:loss = 0.0011030248, step = 14401 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.629\n",
      "INFO:tensorflow:loss = 0.0007836893, step = 14501 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.495\n",
      "INFO:tensorflow:loss = 0.0038890452, step = 14601 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.28\n",
      "INFO:tensorflow:loss = 0.0015271998, step = 14701 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.906\n",
      "INFO:tensorflow:loss = 0.0012357177, step = 14801 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.941\n",
      "INFO:tensorflow:loss = 0.0025138273, step = 14901 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.101\n",
      "INFO:tensorflow:loss = 0.0014113168, step = 15001 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.012\n",
      "INFO:tensorflow:loss = 0.0022498202, step = 15101 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.709\n",
      "INFO:tensorflow:loss = 0.001128718, step = 15201 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.182\n",
      "INFO:tensorflow:loss = 0.0021587685, step = 15301 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.21\n",
      "INFO:tensorflow:loss = 0.002613993, step = 15401 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.616\n",
      "INFO:tensorflow:loss = 0.004930777, step = 15501 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.845\n",
      "INFO:tensorflow:loss = 0.0034484405, step = 15601 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.718\n",
      "INFO:tensorflow:loss = 0.0060245395, step = 15701 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.364\n",
      "INFO:tensorflow:loss = 0.00068643724, step = 15801 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.009\n",
      "INFO:tensorflow:loss = 0.0009352878, step = 15901 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.953\n",
      "INFO:tensorflow:loss = 0.0073236674, step = 16001 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.413\n",
      "INFO:tensorflow:loss = 0.0029350412, step = 16101 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.413\n",
      "INFO:tensorflow:loss = 0.00013800817, step = 16201 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.353\n",
      "INFO:tensorflow:loss = 0.0033148676, step = 16301 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.137\n",
      "INFO:tensorflow:loss = 0.0015652758, step = 16401 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.056\n",
      "INFO:tensorflow:loss = 0.0017796434, step = 16501 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.049\n",
      "INFO:tensorflow:loss = 0.0026532058, step = 16601 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.952\n",
      "INFO:tensorflow:loss = 0.0021445206, step = 16701 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.895\n",
      "INFO:tensorflow:loss = 0.0025497633, step = 16801 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.243\n",
      "INFO:tensorflow:loss = 0.0016692068, step = 16901 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.951\n",
      "INFO:tensorflow:loss = 0.0037436988, step = 17001 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.954\n",
      "INFO:tensorflow:loss = 0.0024644723, step = 17101 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.462\n",
      "INFO:tensorflow:loss = 0.002229899, step = 17201 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.209\n",
      "INFO:tensorflow:loss = 0.0011393703, step = 17301 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.706\n",
      "INFO:tensorflow:loss = 0.0014016031, step = 17401 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.563\n",
      "INFO:tensorflow:loss = 0.0011036354, step = 17501 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.988\n",
      "INFO:tensorflow:loss = 0.0007968225, step = 17601 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.974\n",
      "INFO:tensorflow:loss = 0.0008570232, step = 17701 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.63\n",
      "INFO:tensorflow:loss = 0.00015305693, step = 17801 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.528\n",
      "INFO:tensorflow:loss = 0.0017441325, step = 17901 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.471\n",
      "INFO:tensorflow:loss = 0.0004916916, step = 18001 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.463\n",
      "INFO:tensorflow:loss = 0.00096607907, step = 18101 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.296\n",
      "INFO:tensorflow:loss = 0.0033274489, step = 18201 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.098\n",
      "INFO:tensorflow:loss = 0.007315417, step = 18301 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.348\n",
      "INFO:tensorflow:loss = 0.0028587359, step = 18401 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.58\n",
      "INFO:tensorflow:loss = 0.01164608, step = 18501 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.004098156, step = 18601 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.856\n",
      "INFO:tensorflow:loss = 0.0019156395, step = 18701 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.416\n",
      "INFO:tensorflow:loss = 0.0021057362, step = 18801 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.811\n",
      "INFO:tensorflow:loss = 0.0028408756, step = 18901 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.906\n",
      "INFO:tensorflow:loss = 0.0015907907, step = 19001 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.414\n",
      "INFO:tensorflow:loss = 0.00048667434, step = 19101 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.105\n",
      "INFO:tensorflow:loss = 0.001026828, step = 19201 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.6\n",
      "INFO:tensorflow:loss = 0.005833575, step = 19301 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.416\n",
      "INFO:tensorflow:loss = 0.0015231998, step = 19401 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.905\n",
      "INFO:tensorflow:loss = 0.0020214983, step = 19501 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.811\n",
      "INFO:tensorflow:loss = 0.0006123014, step = 19601 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.36\n",
      "INFO:tensorflow:loss = 8.731253e-05, step = 19701 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.838\n",
      "INFO:tensorflow:loss = 0.00045870445, step = 19801 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.609\n",
      "INFO:tensorflow:loss = 0.0022438592, step = 19901 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.147\n",
      "INFO:tensorflow:loss = 0.0027030185, step = 20001 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.38\n",
      "INFO:tensorflow:loss = 0.0004533298, step = 20101 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.471\n",
      "INFO:tensorflow:loss = 0.0024272925, step = 20201 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.854\n",
      "INFO:tensorflow:loss = 0.0009788466, step = 20301 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.415\n",
      "INFO:tensorflow:loss = 0.00013335403, step = 20401 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.667\n",
      "INFO:tensorflow:loss = 0.0012923597, step = 20501 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.05\n",
      "INFO:tensorflow:loss = 0.000768231, step = 20601 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.578\n",
      "INFO:tensorflow:loss = 0.00092462293, step = 20701 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.856\n",
      "INFO:tensorflow:loss = 0.00097374304, step = 20801 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.74\n",
      "INFO:tensorflow:loss = 0.0009798963, step = 20901 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.011\n",
      "INFO:tensorflow:loss = 0.0026043747, step = 21001 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.021\n",
      "INFO:tensorflow:loss = 0.0011516297, step = 21101 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.019\n",
      "INFO:tensorflow:loss = 0.0045016776, step = 21201 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.463\n",
      "INFO:tensorflow:loss = 0.0005191799, step = 21301 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.63\n",
      "INFO:tensorflow:loss = 0.0019947311, step = 21401 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.243\n",
      "INFO:tensorflow:loss = 0.00039741493, step = 21501 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.741\n",
      "INFO:tensorflow:loss = 0.00091909996, step = 21601 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.209\n",
      "INFO:tensorflow:loss = 0.00079488195, step = 21701 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.58\n",
      "INFO:tensorflow:loss = 0.00037160938, step = 21801 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.513\n",
      "INFO:tensorflow:loss = 0.000540047, step = 21901 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.242\n",
      "INFO:tensorflow:loss = 4.7364403e-05, step = 22001 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.631\n",
      "INFO:tensorflow:loss = 0.00020969367, step = 22101 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.742\n",
      "INFO:tensorflow:loss = 0.0012631826, step = 22201 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.146\n",
      "INFO:tensorflow:loss = 0.0014378496, step = 22301 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.844\n",
      "INFO:tensorflow:loss = 0.0018406921, step = 22401 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.927\n",
      "INFO:tensorflow:loss = 0.0013936902, step = 22501 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.856\n",
      "INFO:tensorflow:loss = 0.002508576, step = 22601 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.293\n",
      "INFO:tensorflow:loss = 0.00080863514, step = 22701 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.259\n",
      "INFO:tensorflow:loss = 0.00075980986, step = 22801 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.536\n",
      "INFO:tensorflow:loss = 0.0019926738, step = 22901 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.382\n",
      "INFO:tensorflow:loss = 0.00044965593, step = 23001 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.207\n",
      "INFO:tensorflow:loss = 0.0026659474, step = 23101 (0.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.361\n",
      "INFO:tensorflow:loss = 0.001806035, step = 23201 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.764\n",
      "INFO:tensorflow:loss = 0.002085761, step = 23301 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.82\n",
      "INFO:tensorflow:loss = 0.0005175256, step = 23401 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.056\n",
      "INFO:tensorflow:loss = 0.00084793364, step = 23501 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.489\n",
      "INFO:tensorflow:loss = 0.0006455955, step = 23601 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.621\n",
      "INFO:tensorflow:loss = 0.00011781148, step = 23701 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.615\n",
      "INFO:tensorflow:loss = 0.00090206123, step = 23801 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.168\n",
      "INFO:tensorflow:loss = 0.0018813056, step = 23901 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.092\n",
      "INFO:tensorflow:loss = 0.0013822758, step = 24001 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.245\n",
      "INFO:tensorflow:loss = 0.0006361419, step = 24101 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.935\n",
      "INFO:tensorflow:loss = 0.0017943095, step = 24201 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.654\n",
      "INFO:tensorflow:loss = 0.00023451612, step = 24301 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.721\n",
      "INFO:tensorflow:loss = 0.0018999608, step = 24401 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.47\n",
      "INFO:tensorflow:loss = 0.0011017375, step = 24501 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.551\n",
      "INFO:tensorflow:loss = 0.0008027391, step = 24601 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.208\n",
      "INFO:tensorflow:loss = 0.0010118572, step = 24701 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.632\n",
      "INFO:tensorflow:loss = 0.0011997204, step = 24801 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.182\n",
      "INFO:tensorflow:loss = 0.0013836683, step = 24901 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.843\n",
      "INFO:tensorflow:loss = 0.00056055206, step = 25001 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.465\n",
      "INFO:tensorflow:loss = 0.0008210417, step = 25101 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.297\n",
      "INFO:tensorflow:loss = 0.0017338805, step = 25201 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.228\n",
      "INFO:tensorflow:loss = 0.00014301993, step = 25301 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.844\n",
      "INFO:tensorflow:loss = 0.0006431623, step = 25401 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.415\n",
      "INFO:tensorflow:loss = 0.0010034089, step = 25501 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.416\n",
      "INFO:tensorflow:loss = 0.0007350694, step = 25601 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.348\n",
      "INFO:tensorflow:loss = 0.00038304523, step = 25701 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.013\n",
      "INFO:tensorflow:loss = 0.0007716039, step = 25801 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.476\n",
      "INFO:tensorflow:loss = 0.0014196114, step = 25901 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.211\n",
      "INFO:tensorflow:loss = 9.6377946e-05, step = 26001 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.772\n",
      "INFO:tensorflow:loss = 0.00089567876, step = 26101 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.907\n",
      "INFO:tensorflow:loss = 0.0011402307, step = 26201 (0.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.861\n",
      "INFO:tensorflow:loss = 0.0006351436, step = 26301 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.601\n",
      "INFO:tensorflow:loss = 0.0010770798, step = 26401 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.018\n",
      "INFO:tensorflow:loss = 0.000889986, step = 26501 (0.357 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 290.51\n",
      "INFO:tensorflow:loss = 0.0004145306, step = 26601 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.012\n",
      "INFO:tensorflow:loss = 2.2389202e-05, step = 26701 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.347\n",
      "INFO:tensorflow:loss = 0.0003260985, step = 26801 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.036\n",
      "INFO:tensorflow:loss = 0.00084424816, step = 26901 (0.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.765\n",
      "INFO:tensorflow:loss = 0.0007669385, step = 27001 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.367\n",
      "INFO:tensorflow:loss = 0.0005288195, step = 27101 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.297\n",
      "INFO:tensorflow:loss = 0.00043037103, step = 27201 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.022\n",
      "INFO:tensorflow:loss = 0.0011316728, step = 27301 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.869\n",
      "INFO:tensorflow:loss = 0.0004057486, step = 27401 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.583\n",
      "INFO:tensorflow:loss = 0.00091903383, step = 27501 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.278\n",
      "INFO:tensorflow:loss = 0.0011361982, step = 27601 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.46\n",
      "INFO:tensorflow:loss = 0.00019087989, step = 27701 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.583\n",
      "INFO:tensorflow:loss = 0.00018868118, step = 27801 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.633\n",
      "INFO:tensorflow:loss = 0.00059351546, step = 27901 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.427\n",
      "INFO:tensorflow:loss = 0.0013423169, step = 28001 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.381\n",
      "INFO:tensorflow:loss = 0.0006275566, step = 28101 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.042\n",
      "INFO:tensorflow:loss = 0.000690566, step = 28201 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.463\n",
      "INFO:tensorflow:loss = 0.00080443703, step = 28301 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.577\n",
      "INFO:tensorflow:loss = 0.0010558362, step = 28401 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.764\n",
      "INFO:tensorflow:loss = 0.00011931291, step = 28501 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.049\n",
      "INFO:tensorflow:loss = 0.00056630047, step = 28601 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.227\n",
      "INFO:tensorflow:loss = 0.0013009512, step = 28701 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.106\n",
      "INFO:tensorflow:loss = 0.0010609973, step = 28801 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.381\n",
      "INFO:tensorflow:loss = 0.00033517767, step = 28901 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.105\n",
      "INFO:tensorflow:loss = 0.0012997957, step = 29001 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.427\n",
      "INFO:tensorflow:loss = 0.0011489118, step = 29101 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.513\n",
      "INFO:tensorflow:loss = 0.0012763605, step = 29201 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.907\n",
      "INFO:tensorflow:loss = 0.0013941429, step = 29301 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.084\n",
      "INFO:tensorflow:loss = 0.0012539653, step = 29401 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.676\n",
      "INFO:tensorflow:loss = 0.00088141003, step = 29501 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.191\n",
      "INFO:tensorflow:loss = 0.00027524188, step = 29601 (0.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.571\n",
      "INFO:tensorflow:loss = 0.00022153735, step = 29701 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.453\n",
      "INFO:tensorflow:loss = 0.00042227987, step = 29801 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.452\n",
      "INFO:tensorflow:loss = 0.000881248, step = 29901 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.473\n",
      "INFO:tensorflow:loss = 0.00014224801, step = 30001 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.326\n",
      "INFO:tensorflow:loss = 0.0005660674, step = 30101 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.965\n",
      "INFO:tensorflow:loss = 0.00015896618, step = 30201 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.482\n",
      "INFO:tensorflow:loss = 0.00073615834, step = 30301 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.245\n",
      "INFO:tensorflow:loss = 0.0015980708, step = 30401 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.36\n",
      "INFO:tensorflow:loss = 0.00076599873, step = 30501 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.976\n",
      "INFO:tensorflow:loss = 0.0008836365, step = 30601 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.861\n",
      "INFO:tensorflow:loss = 0.00072137365, step = 30701 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.014\n",
      "INFO:tensorflow:loss = 0.000911802, step = 30801 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.35\n",
      "INFO:tensorflow:loss = 0.0005352926, step = 30901 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.584\n",
      "INFO:tensorflow:loss = 0.0008802587, step = 31001 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.504\n",
      "INFO:tensorflow:loss = 0.0011493338, step = 31101 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.172\n",
      "INFO:tensorflow:loss = 0.00034747281, step = 31201 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.405\n",
      "INFO:tensorflow:loss = 0.00045103766, step = 31301 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.13\n",
      "INFO:tensorflow:loss = 0.0015849296, step = 31401 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.635\n",
      "INFO:tensorflow:loss = 0.00018125605, step = 31501 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.697\n",
      "INFO:tensorflow:loss = 0.0003683104, step = 31601 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.552\n",
      "INFO:tensorflow:loss = 0.00058857707, step = 31701 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.832\n",
      "INFO:tensorflow:loss = 0.00018411642, step = 31801 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.303\n",
      "INFO:tensorflow:loss = 0.0007397288, step = 31901 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.502\n",
      "INFO:tensorflow:loss = 0.00010908352, step = 32001 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.295\n",
      "INFO:tensorflow:loss = 0.00036582001, step = 32101 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.138\n",
      "INFO:tensorflow:loss = 0.0011355418, step = 32201 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.267\n",
      "INFO:tensorflow:loss = 0.00060713926, step = 32301 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.245\n",
      "INFO:tensorflow:loss = 0.00019037753, step = 32401 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.502\n",
      "INFO:tensorflow:loss = 0.00032589407, step = 32501 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.709\n",
      "INFO:tensorflow:loss = 0.00020175455, step = 32601 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.616\n",
      "INFO:tensorflow:loss = 0.0008006417, step = 32701 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.293\n",
      "INFO:tensorflow:loss = 0.00097225094, step = 32801 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.581\n",
      "INFO:tensorflow:loss = 0.00055127364, step = 32901 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.147\n",
      "INFO:tensorflow:loss = 0.00068617606, step = 33001 (0.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.806\n",
      "INFO:tensorflow:loss = 0.0017067079, step = 33101 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.303\n",
      "INFO:tensorflow:loss = 0.00085497746, step = 33201 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.179\n",
      "INFO:tensorflow:loss = 0.00037568127, step = 33301 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.573\n",
      "INFO:tensorflow:loss = 0.0011967594, step = 33401 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.241\n",
      "INFO:tensorflow:loss = 0.0003406815, step = 33501 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.55\n",
      "INFO:tensorflow:loss = 0.0010090199, step = 33601 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.77\n",
      "INFO:tensorflow:loss = 0.0008257888, step = 33701 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.559\n",
      "INFO:tensorflow:loss = 0.000532877, step = 33801 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.819\n",
      "INFO:tensorflow:loss = 0.0008848162, step = 33901 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.226\n",
      "INFO:tensorflow:loss = 0.00065743556, step = 34001 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.695\n",
      "INFO:tensorflow:loss = 0.00057510444, step = 34101 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 317\n",
      "INFO:tensorflow:loss = 0.0009729916, step = 34201 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.768\n",
      "INFO:tensorflow:loss = 0.00014511343, step = 34301 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.086\n",
      "INFO:tensorflow:loss = 0.0004339821, step = 34401 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00046811855, step = 34501 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.476\n",
      "INFO:tensorflow:loss = 0.00046249523, step = 34601 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.819\n",
      "INFO:tensorflow:loss = 0.0012819404, step = 34701 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.762\n",
      "INFO:tensorflow:loss = 0.0005041618, step = 34801 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.536\n",
      "INFO:tensorflow:loss = 0.00073232804, step = 34901 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.843\n",
      "INFO:tensorflow:loss = 0.00028639985, step = 35001 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.329\n",
      "INFO:tensorflow:loss = 0.0007524969, step = 35101 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.089\n",
      "INFO:tensorflow:loss = 0.000246612, step = 35201 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.843\n",
      "INFO:tensorflow:loss = 0.00013894394, step = 35301 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.024\n",
      "INFO:tensorflow:loss = 0.0012439248, step = 35401 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.459\n",
      "INFO:tensorflow:loss = 0.0003172623, step = 35501 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.897\n",
      "INFO:tensorflow:loss = 0.00036029436, step = 35601 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.45\n",
      "INFO:tensorflow:loss = 0.00093216763, step = 35701 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.561\n",
      "INFO:tensorflow:loss = 0.00061326235, step = 35801 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.203\n",
      "INFO:tensorflow:loss = 0.00040565495, step = 35901 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.704\n",
      "INFO:tensorflow:loss = 0.00031746275, step = 36001 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.036\n",
      "INFO:tensorflow:loss = 0.0010431885, step = 36101 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.332\n",
      "INFO:tensorflow:loss = 0.0008417742, step = 36201 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.482\n",
      "INFO:tensorflow:loss = 0.000341626, step = 36301 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.176\n",
      "INFO:tensorflow:loss = 0.00066287076, step = 36401 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.819\n",
      "INFO:tensorflow:loss = 0.0001691611, step = 36501 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.16\n",
      "INFO:tensorflow:loss = 0.0002870801, step = 36601 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.38\n",
      "INFO:tensorflow:loss = 0.00034622557, step = 36701 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.963\n",
      "INFO:tensorflow:loss = 0.00081273576, step = 36801 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.174\n",
      "INFO:tensorflow:loss = 0.00049302087, step = 36901 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.812\n",
      "INFO:tensorflow:loss = 0.0006788952, step = 37001 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.551\n",
      "INFO:tensorflow:loss = 0.0001816258, step = 37101 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.715\n",
      "INFO:tensorflow:loss = 0.00017002286, step = 37201 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.599\n",
      "INFO:tensorflow:loss = 0.0005871778, step = 37301 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.052\n",
      "INFO:tensorflow:loss = 0.00033291214, step = 37401 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.568\n",
      "INFO:tensorflow:loss = 0.0003054405, step = 37501 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.838\n",
      "INFO:tensorflow:loss = 0.00025535378, step = 37601 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.311\n",
      "INFO:tensorflow:loss = 7.358195e-05, step = 37701 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.38\n",
      "INFO:tensorflow:loss = 0.00057673553, step = 37801 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.207\n",
      "INFO:tensorflow:loss = 0.0012681597, step = 37901 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.049\n",
      "INFO:tensorflow:loss = 0.0001888961, step = 38001 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.105\n",
      "INFO:tensorflow:loss = 0.00094997254, step = 38101 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.293\n",
      "INFO:tensorflow:loss = 0.00071790075, step = 38201 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.708\n",
      "INFO:tensorflow:loss = 5.7350193e-05, step = 38301 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.24\n",
      "INFO:tensorflow:loss = 0.00011130114, step = 38401 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.471\n",
      "INFO:tensorflow:loss = 0.00048698462, step = 38501 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.609\n",
      "INFO:tensorflow:loss = 0.00065920054, step = 38601 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.951\n",
      "INFO:tensorflow:loss = 0.00045425666, step = 38701 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.744\n",
      "INFO:tensorflow:loss = 7.410317e-05, step = 38801 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.469\n",
      "INFO:tensorflow:loss = 0.0015053138, step = 38901 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.087\n",
      "INFO:tensorflow:loss = 0.00013840743, step = 39001 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.207\n",
      "INFO:tensorflow:loss = 0.0007568161, step = 39101 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.879\n",
      "INFO:tensorflow:loss = 0.00032950658, step = 39201 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.469\n",
      "INFO:tensorflow:loss = 0.00039500088, step = 39301 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.087\n",
      "INFO:tensorflow:loss = 0.00043586025, step = 39401 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.667\n",
      "INFO:tensorflow:loss = 0.00016400423, step = 39501 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.707\n",
      "INFO:tensorflow:loss = 0.00065093744, step = 39601 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.206\n",
      "INFO:tensorflow:loss = 0.0001718217, step = 39701 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.638\n",
      "INFO:tensorflow:loss = 0.0011465346, step = 39801 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.469\n",
      "INFO:tensorflow:loss = 0.00083251565, step = 39901 (0.279 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into C:\\Users\\jeong\\AppData\\Local\\Temp\\tmp4kztcz7v\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00035462633.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SKCompat()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = tf.contrib.learn.RunConfig(tf_random_seed=42)\n",
    "\n",
    "feature_cols = tf.contrib.learn.infer_real_valued_columns_from_input(X_train)\n",
    "dnn_clf = tf.contrib.learn.DNNClassifier(hidden_units=[300,100], n_classes=10,\n",
    "                                         feature_columns=feature_cols, config=config)\n",
    "dnn_clf = tf.contrib.learn.SKCompat(dnn_clf) # if TensorFlow >= 1.1\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "dnn_clf.fit(X_train, y_train, batch_size=50, steps=40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\jeong\\AppData\\Local\\Temp\\tmp4kztcz7v\\model.ckpt-40000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9835"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = dnn_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred['classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07061212603056193"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "y_pred_proba = y_pred['probabilities']\n",
    "log_loss(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 텐서플로의 저수준 API로 심층 신경망(DNN) 훈련하기\n",
    "네트워크 구조를 더 상세히 제어하고 싶다면 (9장에서 소개한) 텐서플로의 저수준 파이썬 API가 나을지도 모른다.\n",
    "\n",
    "#### 저수준 API로 고수준 API로 만든 모델과 같은 모델을 만들고 미니배치 경사 하강법 구현하기\n",
    "\n",
    "## 3.1. 구성 단계\n",
    "#### 입력, 출력 크기 지정, 은닉층의 뉴런 수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "n_inputs = 28 * 28 # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 플레이스홀더 노드로 훈련 데이터와 타깃 표현\n",
    "* `X` - `(None, n_inputs)`\n",
    "    * 크기는 일부분만 정의된다. 우리가 아는 것은 2D 텐서(즉, 행렬)라는 점\n",
    "    * 특성 수 : 28 × 28 (픽셀 당 하나의 특성)\n",
    "    * 아직 훈련 배치에 몇 개의 샘플이 포함될지 모른다.\n",
    "* `y` - `(None)`\n",
    "    * 값이 샘플 당 하나의 1D 텐서\n",
    "    * 역시 지금 시점엔 훈련 배치의 크기를 알 수 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name='X')\n",
    "y = tf.placeholder(tf.int32, shape=(None), name='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 실제 신경망 만들기\n",
    "* 플레이스홀더 `X`는 입력층의 역할을 한다.\n",
    "* 실행 단계동안 한 번에 하나씩 훈련 배치로 바뀐다(훈련 배치에 있는 모든 샘플이 신경망에서 동시에 처리된다).\n",
    "* 이제 두 개의 은닉층과 하나의 출력층을 만들어야 한다.\n",
    "    * 두 은닉층은 거의 같고 연결된 입력과 뉴런 수만 다르다.\n",
    "    * 출력층도 매우 비슷하며 ReLU 활성화 함수 대신 softmax 활성화 함수를 사용한다.\n",
    "    \n",
    "### 3.1.1. 신경망 층 만들기 방법 1 : 직접 구현\n",
    "#### `neuron_layer()` 함수를 만들어 한 번에 한 개 층씩 만들어보기\n",
    "이 함수에 전달할 매개변수는 입력, 뉴런 수, 층 이름, 활성화 함수\n",
    "\n",
    "1. 층 이름으로 이름 범위를 만든다. 여기에 이 층에서 필요한 모든 계산 노드가 포함된다.  \n",
    "꼭 필요한 것은 아니지만 노드가 잘 정리되어 있으면 텐서보드에서 훨씬 깔끔한 계산 그래프를 볼 수 있다.\n",
    "2. 입력 행렬의 크기에서 두 번째 차원을 사용해 입력 특성 수를 구한다.\n",
    "3. 가중치 행렬을 담을 `W` 변수를 만든다(종종 커널이라고도 부른다). \n",
    "    * 이 행렬은 각 입력과 각 뉴런 사이의 모든 연결 가중치를 담고 있는 2D 텐서이다. 그러므로 크기는 `(n_inputs, n_neurons)`\n",
    "    * 이 행렬은 표준편차가 $\\frac{2}{\\sqrt{n_{inputs}+n_{neurons}}}$인 절단 정규(가우시안) 분포(truncated normal distribution)를 사용해 무작위로 초기화된다. 이 표준편차를 사용하면 알고리즘이 훨씬 빠르게 수렴한다(11장 참조, 신경망을 엄청나게 효율적으로 만들어준 작은 변화 중 하나다).\n",
    "    > 표준 정규분포 대신 절단 정규분포를 사용하면 값이 큰 가중치가 생기지 않아 훈련이 느려지지 않는다.  \n",
    "    가중치가 크면 계산된 출력값이 커져 로지스틱 함수의 양극단에 가까워진다. 이 부분의 기울기는 0에 가까워 오차 그래디언트가 매우 희미해지고 가중치 업데이트가 느려지게 된다.  \n",
    "    `truncated_normal()` 함수는 2 표준편차 이상의 값을 제외한 정규분포 난수를 발생시킨다.\n",
    "    * 경사 하강법 알고리즘이 중단되지 않도록 대칭성을 피하기 위해 모든 은닉층의 가중치는 무작위로 초기화하는 것이 중요하다.\n",
    "    > 예를 들어 모든 가중치를 0으로 setting하면 모든 뉴런의 출력이 0이 되고, 은닉층의 모든 뉴런의 오차 그래디언트가 같게 된다.  \n",
    "    경사 하강법 스텝에서 각 층의 모든 가중치가 정확히 같은 식으로 업데이트된다. 그래서 같은 가중치 값이 계속 유지된다.  \n",
    "    다시 말해 한 층에 수백 개의 뉴런이 있어도 뉴런이 하나뿐인 것처럼 작동하다. 이 신경망은 제대로 작동하지 않을 것이다.\n",
    "4. 뉴런마다 하나의 편향을 갖도록 변수 `b`를 만들고 0으로 초기화한다(여기서는 대칭 문제가 없다).\n",
    "5. $\\mathbf Z = \\mathbf X \\cdot \\mathbf W + \\mathbf b$를 계산하기 위한 그래프를 만든다.\n",
    "    * 이 벡터화된 구현은 층에 있는 모든 뉴런과 배치에 있는 모든 샘플에 대해 입력에 대한 가중치 합에 편향을 더하는 계산을 효율적으로 한방에 수행한다.\n",
    "    * 행렬곱 2D 행렬에 열의 개수와 같은 1D 배열을 더하면 모든 행에 1D 배열이 더해지게 된다(**브로드캐스팅**)\n",
    "6. `tf.nn.relu`와 같은 `activation` 매개변수가 지정되어 있으면 `activation(Z)`(즉, `max(0, Z)`)를 반환, 그렇지 않으면 그냥 `Z` 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_layer(X, n_neurons, name, activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        stddev = 2 / np.sqrt(n_inputs)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "        W = tf.Variable(init, name='kernel')\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name='bias')\n",
    "        Z = tf.matmul(X, W) + b\n",
    "        if activation is not None:\n",
    "            return activation(Z)\n",
    "        else:\n",
    "            return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 만들어진 하나의 뉴런 층을 만드는 함수로 심층 신경망 만들기\n",
    "* 첫 번째 은닉층의 입력 : `X`\n",
    "* 두 번째 은닉층의 입력 : 첫 번째 은닉층의 출력\n",
    "* 출력층의 입력 : 두 번째 은닉층의 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('dnn'):\n",
    "    hidden1 = neuron_layer(X, n_hidden1, name='hidden1', activation=tf.nn.relu)\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, name='hidden', \n",
    "                           activation=tf.nn.relu)\n",
    "    logits = neuron_layer(hidden2, n_outputs, name='outputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `logits`는 softmax 활성화 함수로 들어가기 **직전의** 신경망 출력이다.  \n",
    "최적화 작업 때문에 softmax 계산은 나중에 처리한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2. 신경망 층 만들기 방법 2 : 텐서플로 함수 이용\n",
    "#### 텐서플로의 표준 신경망 층을 만드는 `tf.layers.dense()` 함수로 만들기\n",
    "* 모든 입력이 은닉층에 있는 모든 뉴런과 연결된 완전 연결 층(fully connected layer)를 만든다.\n",
    "* 이 함수는 적절한 초기화 방식을 사용해 `kernel`과 `bias`라는 이름으로 가중치와 편향 변수를 만든다.\n",
    "> * `kernel_initializer` 매개변수 : 가중치를 초기화한다.\n",
    "    * default : `tf.glorot_uniform_initializer()` 함수(11장 참조)를 사용하여 초기화한다.  \n",
    " *  `bias_initializer` 매개변수 : 편향을 초기화한다.\n",
    "    * default : `tf.zeros_initializer()` 함수로 0으로 초기화 된다.\n",
    "* `activation` 매개변수 : 활성화 함수를 지정한다.\n",
    "* 규제와 정규화 매개변수도 지원한다(11장 참조)\n",
    "* 이전에는 `tf.conrib.layers.fully_connected()` 였다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('dnn'):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, name='hidden1', activation=tf.nn.relu)\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, name='hidden2',\n",
    "                             activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name='outputs')\n",
    "    y_proba = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 훈련에 사용할 비용 함수 정의\n",
    "* 크로스 엔트로피 사용\n",
    "    * 크로스 엔트로피는 모델이 타깃 클래스에 대해 낮은 확률을 추정하지 않도록 제약을 가한다.\n",
    "* 텐서플로는 크로스 엔트로피를 계산하기 위함 함수를 여러 개 제공한다. 그 중 `sparse_softmax_cross_entropy_with_logits()` 함수를 사용한다.\n",
    "    * 이 함수는 '로짓(logit)'(즉, 소프트맥스 활성화 함수로 들어가기 전의 네트워크 출력)을 기반으로 크로스 엔트로피를 계산한다.\n",
    "    * 0 ~ 클래스 수 - 1(여기서는 0~ 9)의 정수로 된 레이블을 기대한다.\n",
    "    * 각 샘플에 대한 크로스 엔트로피를 담은 1D 텐서를 반환한다.\n",
    "* 그런 다음 모든 샘플에 대한 크로스 엔트로피 평균을 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, \n",
    "                                                              logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name='loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 경사 하강법 옵티마이저로 비용 함수 최소화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **NOTE**  \n",
    "* `sparse_softmax_cross_entropy_with_logits()` \n",
    "    * 소프트맥스 활성화 함수를 적용한 다음 크로스 엔트로피를 계산하는 것과 같다. 하지만 더 효율적이고 특별한 경우를 적절히 다룬다.  \n",
    "    * 로짓이 커지면 부동소수점 반올림 오차로 소프트맥스 출력이 0 또는 1이 될 수 있다. 이런 경우 크로스 엔트로피 함수 공식에 음의 무한대가 되는 $log(0)$이 포함된다.  \n",
    "`sparse_softmax_cross_entropy_with_logits()` 함수는 대신 작은 양수 $\\epsilon$에 대한 $log(\\epsilon)$을 계산함으로써 이 문제를 해결한다.  \n",
    "    * 안정적인 계산을 위해 소프트맥스 함수의 분모와 분자에서 가장 큰 로짓 값을 빼고 크로스 엔트로피 공식을 연결하여 처리한다.  \n",
    "    즉, 하나의 샘플에 대한 계산은\n",
    "    $$ LOSS = \\sum_{k=1}^K y_klog\\left(\\frac{exp(s_k)}{\\sum_{k=1}^K exp(s_k)}\\right) \n",
    "    = \\sum_{k=1}^K y_klog\\left(\\frac{exp(s_k)exp(-s_{max})}{\\sum_{k=1}^K exp(s_k)exp(-s_{max})}\\right)\n",
    "    = \\sum_{k=1}^K y_klog\\left(\\frac{exp(s_k - s_{max})}{\\sum_{k=1}^K exp(s_k - s_{max})}\\right)\n",
    "    = \\sum_{k=1}^K y_k\\left((s_k - s_{max}) - log(\\sum_{k=1}^K exp(s_k - s_{max})\\right)$$\n",
    "        * 두 번째 항이 $log(\\epsilon)$이다. \n",
    "        * scikit-learn에서는 소프트맥스의 출력이 `1e-10` ~ `1-1e-10` 사이가 되도록 `np.clip()` 함수를 사용하여 최솟값과 최댓값을 제한한다.\n",
    "* `softmax_cross_entropy_with_logits()`\n",
    "    * (0 ~ 클래스 수 -1) 원-핫 벡터(one-hot vector)형태로 레이블을 받는다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 평가\n",
    "* 간단히 정확도를 사용해 성능 측정\n",
    "* 먼저 샘플마다 가장 큰 로짓이 타깃 클래스에 해당하는지 여부를 확인해 신경망의 예측이 맞는지 결정한다.\n",
    "* 이를 위해 `in_top_k()` 함수를 사용한다.\n",
    "> `in_top_k(predictions, targets, k)` : 예측값과 타깃 레이블을 입력받아 타깃 레이블의 예측값이 크기 순으로 k번째 안에 들면 True, 그렇지 않으면 False\n",
    "* 이 함수는 boolean 값으로 채워진 1D 텐서를 반환하므로 실수형으로 변환하고 평균을 낸다.\n",
    "* 이 값의 신경망의 전체 정확도이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모든 변수를 초기화하는 노드 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 훈련된 모델 파라미터 저장\n",
    "훈련된 모델 파라미터를 디스크에 저장하기 위한 `Saver` 객체를 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. 실행 단계\n",
    "\n",
    "#### MNIST 데이터셋 로드\n",
    "scikit-learn 사용하지 않고 텐서플로 자체적으로 테이터를 추출하고 스케일을 조정하며 (0 ~ 1 사이로) 뒤섞은 후 한 번에 미니배치 하나씩 적재하는 함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# 스케일 조정\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 에포크 횟수와 미니배치 크기 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 세션을 열고, `init` 노드를 실행해서 모든 변수를 초기화한다.\n",
    "2. 바깥쪽 훈련 루프를 실행한다. 매 에포크에서 훈련 데이터의 크기를 미니배치 크기로 나눈 횟수만큼 반복한다.\n",
    "3. 각 미니배치는 `next_batch()` 메서드로부터 추출되며, 현재 미니배치의 입력 데이터와 타깃을 주입하면서 훈련 연산을 실행한다.\n",
    "4. 에포크의 끝에서 마지막 미니배치와 검증 데이터를 사용해 모델을 평가하여 결과를 출력한다.\n",
    "5. 모델 파라미터를 디스크에 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 배치 데이터 정확도: 0.9 검증 세트 정확도: 0.9024\n",
      "1 배치 데이터 정확도: 0.92 검증 세트 정확도: 0.9254\n",
      "2 배치 데이터 정확도: 0.94 검증 세트 정확도: 0.9374\n",
      "3 배치 데이터 정확도: 0.9 검증 세트 정확도: 0.9418\n",
      "4 배치 데이터 정확도: 0.94 검증 세트 정확도: 0.9472\n",
      "5 배치 데이터 정확도: 0.94 검증 세트 정확도: 0.9514\n",
      "6 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9546\n",
      "7 배치 데이터 정확도: 0.94 검증 세트 정확도: 0.961\n",
      "8 배치 데이터 정확도: 0.96 검증 세트 정확도: 0.9622\n",
      "9 배치 데이터 정확도: 0.94 검증 세트 정확도: 0.9648\n",
      "10 배치 데이터 정확도: 0.92 검증 세트 정확도: 0.9652\n",
      "11 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9668\n",
      "12 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9684\n",
      "13 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9704\n",
      "14 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9696\n",
      "15 배치 데이터 정확도: 0.94 검증 세트 정확도: 0.9718\n",
      "16 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9728\n",
      "17 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9728\n",
      "18 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9748\n",
      "19 배치 데이터 정확도: 0.96 검증 세트 정확도: 0.9758\n",
      "20 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9752\n",
      "21 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9734\n",
      "22 배치 데이터 정확도: 0.96 검증 세트 정확도: 0.9752\n",
      "23 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9762\n",
      "24 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9758\n",
      "25 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.976\n",
      "26 배치 데이터 정확도: 0.92 검증 세트 정확도: 0.9768\n",
      "27 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9776\n",
      "28 배치 데이터 정확도: 0.94 검증 세트 정확도: 0.978\n",
      "29 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9778\n",
      "30 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9776\n",
      "31 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9778\n",
      "32 배치 데이터 정확도: 0.96 검증 세트 정확도: 0.9778\n",
      "33 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9786\n",
      "34 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9784\n",
      "35 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.978\n",
      "36 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.979\n",
      "37 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9782\n",
      "38 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9792\n",
      "39 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9782\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, '배치 데이터 정확도:', acc_batch, '검증 세트 정확도:', \n",
    "              acc_valid)\n",
    "    save_path = saver.save(sess, './my_model_final.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. 신경망 사용하기\n",
    "신경망을 훈련시키고 나면 이를 사용해 예측을 만들 수 있다.  \n",
    "이 때 구성 단계를 그대로 재사용할 수 있지만, 실행 단계는 아래와 같이 바꿔야 한다.\n",
    "1. 디스크로부터 모델 파라미터를 읽어 들인다.\n",
    "2. 분류하려는 새 이미지를 읽는다.\n",
    "    * 훈련 데이터와 같은 특성 스케일로 조정!! (여기서는 0 ~ 1)\n",
    "    > MNIST 데이터셋에 대한 스케일 조정은 단순히 각 픽셀을 255로 나눠주는 것이다. 그래서 새로운 데이터에 대해서도 동일하게 255로 나눠준다.  \n",
    "    만약 훈련 데이터의 통계 속성을 사용하여 스케일을 조정했다면 새로운 데이터에도 반드시 훈련 데이터에서 얻은 통계 값을 사용해 스케일을 조정해야 한다. 그렇지 않으면 훈련 데이터에서 학습된 모델 파라미터로는 새로운 데이터를 올바르게 예측하지 못한다.\n",
    "3. `logits` 노드를 평가한다. \n",
    "4. 어떤 클래스 하나를 예측하는 것이라면 간단하게 가장 큰 클래스를 선택한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './my_model_final.ckpt') # 또는 save_path를 사용한다.\n",
    "    X_new_scaled = X_test[:20]\n",
    "    Z = logits.eval(feed_dict={X: X_new_scaled})\n",
    "    y_pred = np.argmax(Z, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 클래스:  [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4]\n",
      "진짜 클래스:  [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4]\n"
     ]
    }
   ],
   "source": [
    "print('예측 클래스: ', y_pred)\n",
    "print('진짜 클래스: ', y_test[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow_graph_in_jupyter import show_graph\n",
    "\n",
    "# show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 신경망 하이퍼파라미터 튜닝하기\n",
    "* 신경망의 유연성으로 인해 조절해야 할 하이퍼파라미터가 많아진다.\n",
    "* 상상할 수 있는 어떤 **네트워크 토폴로지**(network topology)(뉴런이 연결된 방식)도 사용할 수 있을 뿐만 아니라 간단한 다층 퍼셉트론조차도 층 수나 층마다의 뉴런 수, 각 층에서 사용하는 활성화 함수, 가중치 초기화 방식 등을 바꿀 수 있다.\n",
    "\n",
    "#### 최적의 하이퍼파라미터를 찾는 방법 \n",
    "* 랜덤 탐색\n",
    "    * 교차 검증을 활용한 그리드 탐색은 조정할 하이퍼파라미터가 많고 대규모 데이터셋에 신경망을 훈련할 때 오랜 시간이 걸리기 때문에 주어진 시간 안에 전체 하이퍼파라미터 공간 중 작은 부분만 탐색할 수 있다. 이런 경우엔 랜덤 탐색이 낫다.\n",
    "* 오스카(Oscar)같은 도구\n",
    "    * 좋은 하이퍼파라미터 조합을 빠르게 찾아주는 복잡한 알고리즘을 구현한 도구\n",
    "    * 이러한 도구는 어떤 하이퍼파라미터 값이 적절한지 감을 잡게 도와주고 탐색 공간을 줄여줄 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. 은닉층의 수\n",
    "* 많은 문제가 은닉층 하나로 시작해도 쓸 만한 결과를 얻을 수 있다.\n",
    "    * 사실 은닉층이 하나인 다층 퍼셉트론이더라도 뉴런 수가 충분하면 아주 복잡한 함수도 모델링할 수 있다는 것이 밝혀졌다.\n",
    "    > 시벤코 정리/일반 근사 이론 : 뉴런 수만 무한하다면 은닉층 하나로 어떤 함수도 근사할 수 있다는 정리/이론\n",
    "* 하지만 심층 신경망이 얕은 신경망보다 **파라미터 효율성**이 훨씬 좋다.\n",
    "    * 심층 신경망은 복잡한 함수를 모델링하는데 얕은 신경망보다 훨씬 적은 수의 뉴런을 사용하기 때문에 더 빠르게 훈련된다.\n",
    "    \n",
    "#### 심층 신경망이 더 좋은 이유 이해하기\n",
    "* 복사/붙여넣기 기능이 없는 드로잉 SW로 숲을 그린다고 한다면 나무, 가지, 잎 하나하나 모두 개별적으로 그려야 한다.\n",
    "* 잎 하나를 그리고 나뭇가지에 복사/붙여넣기 하고, 이 가지를 복사/붙여넣기 하여 나무를 만들고, 이 나무를 복사/붙여넣기하여 숲을 만들면 금세 일을 마칠 있다.\n",
    "* 실제 데이터는 이런 계층적 구조를 가진 경우가 많아 심층 신경망은 자동적으로 이런 점에서 유리하다.\n",
    "\n",
    "#### 심층 신경망 모델링\n",
    "아래쪽 은닉층은 저수준 구조를 모델링(예. 여러가지 방향이나 형태의 선분), 중간 은닉층은 저수준 구조를 연결하여 중간 수준의 구조를 모델링(예. 사각형, 원), 가장 위쪽 은닉층과 출력층은 이런 중간 수준의 구조를 연결하여 고수준의 구조를 모델링한다.(예. 얼굴)\n",
    "\n",
    "#### 계층 구조의 심층 신경망\n",
    "* 이런 계층 구조는 심층 신경망이 좋은 솔루션으로 빨리 수렴하게끔 도와줄 뿐만 아니라 새로운 데이터에 일반화되는 능력도 향상시켜준다.\n",
    "* ex)  \n",
    "    * 사진에서 얼굴을 인식하는 모델을 훈련시킨 후 헤어스타일을 인식하는 신경망을 새로 훈련시키려 한다면 첫 번째 네트워크의 하위층을 재사용하여 훈련을 시작할 수 있다.\n",
    "    * 새로운 신경망의 처음 몇 개 층의 가중치와 편향을 난수로 초기화하는 대신 첫 번째 신경망의 층에 있는 가중치와 편향 값으로 초기화할 수 있다.\n",
    "    * 이런 방식을 사용하면 대부분의 사진에 나타나는 저수준 구조를 학습할 필요가 없게 된다. 즉, (헤어스타일 같은) 고수준 구조만 학습하면 된다.\n",
    "\n",
    "#### 요약\n",
    "* 많은 문제가 하나 또는 두 개의 은닉층만 가지고도 꽤 잘 작동한다.  \n",
    "ex)\n",
    "    * MNIST 데이터셋에서는 은닉층 하나에 뉴런 몇 백개를 두어 97% 이상의 정확도를 쉽게 얻을 수 있다.\n",
    "    * 전체 뉴런 수는 동일하게 하고 은닉층을 두 개로 하면 거의 비슷한 시간에 98% 이상의 정확도를 얻을 수 있다.\n",
    "* 더 복잡한 문제라면 \n",
    "    * 훈련 세트에 과대적합이 생길 때까지 점진적으로 은닉층 수를 늘릴 수 있다. 대규모 이미지 분류나 음성 인식 같이 매우 복잡한 작업일 경우에는 수십 개(또는 수백 개, 또는 완전 연결되어 있지 않다(13장 참조)) 층으로 이뤄진 네트워크가 필요하다.\n",
    "    * 훈련 데이터가 아주 많이 필요하다.\n",
    "        * 하지만 이런 네트워크를 처음부터 훈련시키는 경우는 드물다. \n",
    "        * 비슷한 작업에서 가장 뛰어난 성능을 내는 미리 훈련된 네트워크 일부를 재사용하는 것이 일반적이다.\n",
    "            * 훈련이 훨씬 빨라지고 데이터가 훨씬 적게 필요하다(11장 참조)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. 은닉층의 뉴런 수\n",
    "* 입력층과 출력층의 뉴런 수 : 해당 작업에 필요한 입력과 출력의 형태에 따라 결정된다.  \n",
    "ex)\n",
    "    * MNIST는 28 × 28 = 784개 입력 뉴런과 10개의 출력 뉴런이 필요하다.\n",
    "    > 층의 뉴런 수를 정할 때 편향 뉴런은 특별히 언급하지 않는 것이 보통이다.\n",
    "\n",
    "#### 은닉층 구성 방식\n",
    "* 일반적으로 각 층의 뉴런을 점점 줄여서 깔때기처럼 구성한다. 저수준의 많은 특성이 고수준의 적은 특성으로 합쳐질 수 있기 때문  \n",
    "ex)\n",
    "    * 전형적이 MNIST 신경망은 첫 번째는 300개, 두 번째는 100개의 뉴런으로 구성된 두 개의 은닉층을 가진다.\n",
    "* 요즘엔 모든 은닉층에 같은 크기(동일 뉴런 수)를 많이 사용한다.\n",
    "    * 이러면 하이퍼파라미터가 층마다 다로 있지 않아서 전체를 통틀어 하나만 조정하면 된다.\n",
    "* 층의 개수와 마찬가지로 네트워크가 과대적합이 시작되기 전까지 점진적으로 뉴런 수를 늘린다.\n",
    "    * 일반적으로 층의 뉴런 수보다 층 수를 늘리는 쪽이 이득이 많다.완벽한 뉴런 수를 찾는 것이 어렵기 때문에\n",
    "    \n",
    "#### 과대적합\n",
    "* 단순 접근 방식\n",
    "    1. 실제 필요한 것보다 더 많은 층과 뉴런을 가진 모델을 선택한다.\n",
    "    2. 과대적합되지 않도록 조기 종료 기법을 사용한다(**드롭 아웃**(dropout) 사용, 11장 참조). \n",
    "        * 이를 '스트레치 팬츠(stretch pants)' 방식이라고 부른다. 즉, 맞는 사이즈의 바지를 찾느라 시간 낭비하는 대신에 그냥 큰 스트레치 팬츠를 사고 나중에 알맞게 줄이는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. 활성화 함수\n",
    "#### 은닉층\n",
    "* 대부분의 경우 ReLU 활성화 함수를 사용한다(또는 ReLU 변종을 사용할 수 있다. 11장 참조)\n",
    "    * 다른 활성화 함수보다 계산이 조금 더 빠르고, 입력밧이 클 때 특정 값에 수렴하지 않는 덕분에 경사 하강법이 평편한 지역에서 심하게 지체되지 않는다(로지스틱 함수, 하이퍼볼릭 탄젠트 함수는 1에 수렴한다).\n",
    "\n",
    "#### 출력층\n",
    "* 소프트맥스 활성화 함수가 일반적으로 분류 작업의 좋은 선택이다(클래스가 상호 배타적일 경우)\n",
    "* 회귀 작업일 경우에는 활성화 함수를 사용하지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연습문제\n",
    "## 1.\n",
    "([그림 10-3]에 있는 것과 같은) 초창기 인공 뉴런을 사용해 $\\mathbf A \\oplus \\mathbf B$($\\oplus$는 XOR 연산입니다)를 계산하는 인공신경망을 그려보세요.  \n",
    "힌트 : $\\mathbf A \\oplus \\mathbf B = (\\mathbf A \\land \\lnot B) \\lor (\\lnot A \\land B)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "부록 A 참조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.\n",
    "고전적인 퍼셉트론(즉, 퍼셉트론 훈련 알고리즘으로 훈련된 단일 TLU)보다 로지스틱 회귀 분류기가 일반적으로 선호되는 이유는 무엇인가요? 퍼셉트론을 어떻게 수정하면 로지스틱 회귀 분류기와 동등하게 만들 수 있나요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 고전적인 퍼셉트론\n",
    "데이터셋이 선형적으로 구분될 때만 수렴하고 클래스 확률을 추정할 수 없다.  \n",
    "\n",
    "#### 로지스틱 회귀 분류기\n",
    "데이터셋이 선형적으로 구분되지 못해도 좋은 솔루션으로 수렴하고 클래스 확률을 출력한다.\n",
    "\n",
    "#### 로지스틱 회귀 분류기와 동등하게 만들기\n",
    "퍼셉트론의 활성화 함수를 로지스틱 활성화 함수로(또는 여러 개 뉴런일 경우 소프트맥스 활성화 함수로) 바꾸고, 경사 하강법을 사용하여(또는 크로스 엔트로피 같은 비용함수를 최소화하는 다른 최적화 알고리즘을 사용하여) 훈련시키면 동일하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. \n",
    "왜 초창기의 다층 퍼셉트론을 훈련시킬 때 로지스틱 활성화 함수가 핵심 요소였나요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로지스틱 활성화 함수의 도함수는 어디에서나 0이 아니어서 경사 하강법이 항상 경사를 따라 이동할 수 있으므로 MLP의 핵심 요소였다.  \n",
    "활성화 함수가 계단 함수일 때는 경사가 없기 때문에 경사 하강법이 이동할 수 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. \n",
    "유명한 활성화 함수 네 가지는 무엇인가요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 계단 함수\n",
    "* 로지스틱 함수\n",
    "* 하이퍼볼릭 탄젠트\n",
    "* ReLU\n",
    "* ELU와 다른 ReLU 변종도 있다(11장 참조)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.\n",
    "10개의 통과 뉴런으로 된 입력층, 50개의 뉴런으로 된 은닉층, 그리고 3개의 뉴런으로 된 출력층으로 구성된 다층 퍼셉트론이 있다고 가정합시다. 모든 뉴런은 ReLU 활성화 함수를 사용합니다.\n",
    "* 입력 행렬 $\\mathbf X$의 크기는 얼마인가요?\n",
    "* 은닉층의 가중치 벡터 $\\mathbf W_h$와 편향 벡터 $\\mathbf b_h$의 크기는 얼마인가요?\n",
    "* 출력층의 가중치 벡터 $\\mathbf W_o$와 편향 벡터 $\\mathbf b_o$의 크기는 얼마인가요?\n",
    "* 네트워크의 출력 행렬 $\\mathbf Y$의 크기는 얼마인가요?\n",
    "* $\\mathbf X$, $\\mathbf W_h$, $\\mathbf b_h$, $\\mathbf W_o$, $\\mathbf b_o$의 함수로 네트워크의 출력 행렬 $\\mathbf Y$를 계산하는 식을 써보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $\\mathbf X$의 크기 : $m \\times 10$\n",
    "* $\\mathbf W_h$의 크기 : $10 \\times 50$, $\\mathbf b_h$의 길이 : $50$\n",
    "* $\\mathbf W_o$의 크기 : $50 \\times 3$, $\\mathbf b_o$의 길이 : $3$\n",
    "* $\\mathbf Y$의 크기 : $m \\times 3$\n",
    "* $\\mathbf Y = \\mbox{ReLU}(\\mbox{ReLU}(\\mathbf X \\cdot \\mathbf W_h + \\mathbf b_h) \\cdot \\mathbf W_o + \\mathbf b_o$\n",
    "    * ReLU 함수는 행렬에 있는 음수를 무조건 0으로 만든다.\n",
    "    * 편향 벡터를 행렬에 더하면 행렬의 모든 행에 덧셈이 각기 적용되는 **브로드캐스팅**이 일어난다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.\n",
    "스팸 메일을 분류하기 위해서는 출력층에 몇 개의 뉴런이 필요할까요? 출력층에 어떤 활성화 함수를 사용해야 할까요? MNIST 문제라면 출력층에 어떤 활성화 함수를 사용하고 뉴런은 몇 개가 필요할까요? 2장에서 본 주택 가격 예측용 네트워크에 대해 같은 질문의 답을 찾아보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 스팸 메일 분류\n",
    "신경망의 출력층에 하나의 뉴런만 필요하다. 예를들어 이메일이 스팸일 확률을 출력한다. 확률을 추정할 때 일반적으로 출력층에 로지스틱 활성화 함수를 사용한다.\n",
    "\n",
    "#### MNIST 문제\n",
    "출력층에 10개의 뉴런이 필요하고, 다중 클래스 환경에서 클래스마다 하나의 확률을 출력하기 위해 로지스틱 함수를 소프트맥스 활성화 함수로 바꾸어야 한다.\n",
    "\n",
    "#### 2장 주택 가격 예측\n",
    "출력층에 활성화 함수가 없는 출력 뉴런 하나가 필요하다.\n",
    "> 예측하려는 값의 범위가 아주 큰 경우라면 로그를 취한 타깃값을 예측하는게 좋을지 모른다.  \n",
    "이런 경우 신경망의 출력에 지수 함수를 적용하면 손쉽게 추정값을 얻을 수 있다($\\mbox{exp}(\\mbox{log } v) = v$ 이므로)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.\n",
    "역전파란 무엇이고, 어떻게 작동하나요? 역전파와 후진 모드 자동 미분의 차이점은 무엇인가요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 역전파\n",
    "인공 신경망을 훈련시키는 하나의 기법  \n",
    "먼저 모델의 모든 파라미터(모든 가중치와 편향)에 대한 비용함수의 그래디언트를 계산하고, 이 그래디언트를 사용해 경사 하강법 스텝을 수행한다.  \n",
    "역전파 단계는 모델 파라미터가 비용함수를 (희망하건대) 최소화하는 값으로 수렴할 때까지 훈련 배치에서 일반적으로 수천 혹은 수백만 번 수행된다.  \n",
    "그래디언트를 계산하기 위해 역전파는 후진 모드 자동 미분을 사용한다.\n",
    "\n",
    "#### 후진 모드 자동 미분\n",
    "계산 그래프의 정방향 계산에서 현재 훈련 배치에 대한 모든 노드의 값을 구한다.  \n",
    "그 다음에 역방향 계산에서 한번에 모든 그래디언트를 구한다.\n",
    "\n",
    "#### 차이점\n",
    "* 역전파는 그래디언트 계산과 경사 하강법 스텝을 여러 번 수행하여 인공 신경망을 훈련시키는 전체 프로세스를 의미한다.  \n",
    "* 후진 모드 자동 미분은 그래디언트를 효과적으로 계산하는 하나의 기법, 역전파에 사용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.\n",
    "다층 퍼셉트론에서 조정할 수 있는 하이퍼파라미터를 모두 나열해보세요. 훈련 데이터에 다층 퍼셉트론이 과대적합되었다면 이를 해결하기 위해 하이퍼파라미터를 어떻게 조정해야 할까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기본 MLP에서 바꿀 수 있는 하이퍼파라미터\n",
    "* 은닉층 수\n",
    "* 각 은닉층의 뉴런 수\n",
    "* 각 은닉층과 출력층에서 사용하는 활성화 함수\n",
    "* 추가 하이퍼파라미터(11장 참조)\n",
    "    * 가중치 초기화 방법\n",
    "    * 활성화 함수의 하이퍼파라미터(예. LeakyReLU의 $\\alpha$ 값)\n",
    "    * 그래디언트 클리핑 임곗값\n",
    "    * 옵티마이저의 종류와 하이퍼파라미터(예. `MomentumOptimizer`를 사용할 때 모멘텀 하이퍼파라미터)\n",
    "    * 각 층의 규제 종류와 규제 하이퍼파라미터(예. 드롭아웃과 드롭아웃 사용 시 드롭아웃될 비율)\n",
    "    \n",
    "일반적으로 ReLU(또는 이 함수의 변종, 11장 참조)가 은닉층의 활성화 함수 기본값으로 좋다.  \n",
    "출력층에서는 일반적으로 이진 분류에서는 로지스틱 활성화 함수, 다중 분류에서는 소프트맥스 활성화 함수를 사용하고, 회귀에서는 활성화 함수를 적용하지 않는다.\n",
    "\n",
    "#### 과대적합 시\n",
    "은닉층 수와 각 은닉층의 뉴런 수를 줄여볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.\n",
    "깊은(deep) 다층 퍼셉트론을 MNIST 데이터셋에 훈련시키고 98% 정확도를 얻을 수 있는지 확인해보세요. 9장의 마지막 연습문제에서와 같이 모든 부가 기능을 추가해보세요(즉, 체크포인트를 저장하고, 중지되었을 때 마지막 체크포인트를 복원하고, 서머리를 추가하고, 텐서보드를 사용해 학습 곡선을 그려보세요.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 심층 신경망 만들기\n",
    "먼저 심층 신경망을 만든다.  \n",
    "한 가지 추가된 것 외에는 앞서 했던 것과 동일하다.  \n",
    "텐서보드에서 학습 곡선을 볼 수 있도록 훈련하는 동안 손실과 정확도를 기록하는 `tf.summary.scalar()`를 추가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28 * 28 # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name='X')\n",
    "y = tf.placeholder(tf.int32, shape=(None), name='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('dnn'):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, name='hidden1', activation=tf.nn.relu)\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, name='hidden2',\n",
    "                             activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name='outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, \n",
    "                                                              logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name='loss')\n",
    "    loss_summary = tf.summary.scalar('log_loss', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    accuracy_summary = tf.summary.scalar('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서보드 로그를 기록할 디렉토리를 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def log_dir(prefix=''):\n",
    "    now = datetime.utcnow().strftime('%Y%m%d%H%M%S')\n",
    "    root_logdir = 'tf_logs'\n",
    "    if prefix:\n",
    "        prefix += '-'\n",
    "    name = prefix + 'run-' + now\n",
    "    return '{}/{}/'.format(root_logdir, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = log_dir('mnist_dnn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서보드 로그 작성에 필요한 `FileWriter` 객체를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 조기 종료 구현\n",
    "조기 종료를 구현하려면 검증 세트가 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_valid = mnist.validation.images\n",
    "# y_valid = mnist.validation.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크: 0 \t검증 세트 정확도: 90.240% \t손실: 0.35380\n",
      "에포크: 5 \t검증 세트 정확도: 95.140% \t손실: 0.17919\n",
      "에포크: 10 \t검증 세트 정확도: 96.520% \t손실: 0.12783\n",
      "에포크: 15 \t검증 세트 정확도: 97.180% \t손실: 0.10326\n",
      "에포크: 20 \t검증 세트 정확도: 97.520% \t손실: 0.09165\n",
      "에포크: 25 \t검증 세트 정확도: 97.600% \t손실: 0.08207\n",
      "에포크: 30 \t검증 세트 정확도: 97.760% \t손실: 0.07884\n",
      "에포크: 35 \t검증 세트 정확도: 97.800% \t손실: 0.07420\n",
      "에포크: 40 \t검증 세트 정확도: 97.820% \t손실: 0.07164\n",
      "에포크: 45 \t검증 세트 정확도: 98.060% \t손실: 0.06742\n",
      "에포크: 50 \t검증 세트 정확도: 98.020% \t손실: 0.06727\n",
      "에포크: 55 \t검증 세트 정확도: 98.040% \t손실: 0.06678\n",
      "에포크: 60 \t검증 세트 정확도: 98.040% \t손실: 0.06720\n",
      "에포크: 65 \t검증 세트 정확도: 98.200% \t손실: 0.06653\n",
      "에포크: 70 \t검증 세트 정확도: 98.180% \t손실: 0.06589\n",
      "에포크: 75 \t검증 세트 정확도: 98.140% \t손실: 0.06623\n",
      "에포크: 80 \t검증 세트 정확도: 98.160% \t손실: 0.06645\n",
      "에포크: 85 \t검증 세트 정확도: 98.220% \t손실: 0.06589\n",
      "에포크: 90 \t검증 세트 정확도: 98.200% \t손실: 0.06717\n",
      "에포크: 95 \t검증 세트 정확도: 98.200% \t손실: 0.06866\n",
      "에포크: 100 \t검증 세트 정확도: 98.240% \t손실: 0.06853\n",
      "에포크: 105 \t검증 세트 정확도: 98.200% \t손실: 0.07048\n",
      "에포크: 110 \t검증 세트 정확도: 98.240% \t손실: 0.07031\n",
      "에포크: 115 \t검증 세트 정확도: 98.300% \t손실: 0.07032\n",
      "에포크: 120 \t검증 세트 정확도: 98.260% \t손실: 0.07284\n",
      "조기 종료\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "n_epochs = 10001\n",
    "batch_size = 50\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "checkpoint_path = \"/tmp/my_deep_mnist_model.ckpt\"\n",
    "checkpoint_epoch_path = checkpoint_path + \".epoch\"\n",
    "final_model_path = \"./my_deep_mnist_model\"\n",
    "\n",
    "best_loss = np.infty\n",
    "epochs_without_progress = 0\n",
    "max_epochs_without_progress = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if os.path.isfile(checkpoint_epoch_path):\n",
    "        # 체크포인트 파일이 있으면 모델을 복원하고 에포크 숫자를 로드합니다\n",
    "        with open(checkpoint_epoch_path, \"rb\") as f:\n",
    "            start_epoch = int(f.read())\n",
    "        print(\"이전 훈련이 중지되었습니다. 에포크 {}에서 시작합니다\".format(start_epoch))\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        sess.run(init)\n",
    "\n",
    "    for epoch in range(start_epoch, n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val, loss_val, accuracy_summary_str, loss_summary_str = sess.run([accuracy, loss, accuracy_summary, loss_summary], feed_dict={X: X_valid, y: y_valid})\n",
    "        file_writer.add_summary(accuracy_summary_str, epoch)\n",
    "        file_writer.add_summary(loss_summary_str, epoch)\n",
    "        if epoch % 5 == 0:\n",
    "            print(\"에포크:\", epoch,\n",
    "                  \"\\t검증 세트 정확도: {:.3f}%\".format(accuracy_val * 100),\n",
    "                  \"\\t손실: {:.5f}\".format(loss_val))\n",
    "            saver.save(sess, checkpoint_path)\n",
    "            with open(checkpoint_epoch_path, \"wb\") as f:\n",
    "                f.write(b\"%d\" % (epoch + 1))\n",
    "            if loss_val < best_loss:\n",
    "                saver.save(sess, final_model_path)\n",
    "                best_loss = loss_val\n",
    "            else:\n",
    "                epochs_without_progress += 5\n",
    "                if epochs_without_progress > max_epochs_without_progress:\n",
    "                    print(\"조기 종료\")\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(checkpoint_epoch_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_deep_mnist_model\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, final_model_path)\n",
    "    accuracy_val = accuracy.eval(feed_dict={X: X_test, y: y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9791"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

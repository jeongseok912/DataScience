{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 확률분포의 분산\n",
    "* 확률밀도함수 $p(x)$의 수식을 안다면 다음처럼 이론적인 분산을 구할 수 있다.\n",
    "* 분산을 구하는 연산자는 $Var[·]$로 표기\n",
    "* 이 연산자로 계산된 분산값은 $σ^2$로 표기\n",
    "$$ σ^2 = Var[X] = E[(X - μ)^2] $$\n",
    "\n",
    "#### 이산확률변수의 분산\n",
    "평균으로부터 표본까지 거리의 제곱을 확률질량함수 $P(x)$로 가중평균한 값\n",
    "$$ σ^2 = Var[X] = E[(X - μ)^2] = \\sum_{x_i∈Ω}(x_i - μ)^2P(x_i) $$\n",
    "\n",
    "#### 연속확률변수의 분산\n",
    "평균으로부터 표본까지 거리의 제곱을 확률밀도함수 $p(x)$로 가중하여 적분한 값\n",
    "$$ σ^2 = Var[X] = E[(X - μ)^2] = \\int_{-∞}^∞(x - μ)^2p(x)dx $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 분산의 성질\n",
    "* 분산은 다음의 성질을 만족한다.\n",
    "    * 항상 0 또는 양수\n",
    "    $$ Var[X] ≥ 0 $$\n",
    "    * 확률변수가 아닌 상수 값 $c$에 대해\n",
    "    $$ Var[c] = 0 $$\n",
    "    $$ Var[cX] = c^2Var[X] $$\n",
    "* 기댓값의 성질을 이용하여 다음 성질을 증명할 수 있다.\n",
    "$$ Var[X] = E[X^2] - (E[X])^2 = E[X^2] - μ^2 $$ \n",
    "또는\n",
    "$$ E[X^2] = μ^2 + Var[X] $$\n",
    "> **증명**\n",
    "$$ Var[X] = E[(X - μ)^2] $$\n",
    "$$ = E[X^2 - 2μX + μ^2] $$\n",
    "$$ = E[X^2] - 2μE[X] + μ^2 $$\n",
    "$$ = E[X^2] - 2μ^2 + μ^2 $$\n",
    "$$ = E[X^2] - μ^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 두 확률변수의 합의 분산\n",
    "* 두 확률변수 $X, Y$의 합의 분산은 각 확률변수의 분산의 합과 다음과 같은 관계를 가짐\n",
    "$$ Var[X + Y] = Var[X] + Var[Y] + 2E[(X - \\mu_X)(Y - \\mu_Y)] $$\n",
    "    * 마지막항은 양수(+) 혹은 음수(-)\n",
    "> **증명**  \n",
    "우선 확률변수 $X + Y$의 기댓값은 (기댓값의 성질로부터)각 확률변수의 기댓값의 합과 같다.\n",
    "$$ E[X + Y] = \\mu_X + \\mu_Y $$\n",
    "분산의 정의와 기댓값의 성질로부터 다음이 성립\n",
    "$$ Var[X + Y] = E[(X + Y - (\\mu_X + \\mu_Y))^2] $$\n",
    "$$ = E[\\{(X - \\mu_X) + (Y - \\mu_Y)\\}^2] $$\n",
    "$$ = E[(X - \\mu_X)^2 + (Y - \\mu_Y)^2 + 2(X - \\mu_X)(Y - \\mu_Y)] $$\n",
    "$$ = E[(X - \\mu_X)^2] + E[(Y - \\mu_Y)^2] + 2E[(X - \\mu_X)(Y - \\mu_Y] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 확률변수의 독립\n",
    "## 4.1. 두 확률변수가 서로 독립(independent)\n",
    "두 확률변수가 가질 수 있는 모든 사건의 조합에 대해 결합사건의 확률이 각 사건의 확률의 곱과 같다는 뜻\n",
    "* 쉽게 생각하면 두 확률변수가 서로에게 영향을 미치지 않는다는 의미  \n",
    "\n",
    "ex)  \n",
    "주사위를 두 번 던져 각각 나오는 값을 나타내는 확률변수 $X_1$과 $X_2$는 서로 독립이다.\n",
    "\n",
    "## 4.2. 종속(dependent)\n",
    "두 확률변수에서 하나의 확률변수의 값이 특정한 값이면 다른 확률변수의 확률분포가 영향을 받아 변하게 되는 것\n",
    "* 쉽게 생각하면 두 확률변수가 서로에게 영향을 미치는 경우  \n",
    "\n",
    "ex)  \n",
    "주사위를 두 번 던져 나오는 값의 합은 각각의 주사위에서 나온 값에 종속적이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연습 문제\n",
    "1. 서로 독립이라고 생각되는 두 확률변수의 예를 들어라.\n",
    "2. 서로 종속이라고 생각되는 두 확률변수의 예를 들어라."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. 서로 독립일 때의 식\n",
    "두 확률변수 $X, Y$가 서로 독립이면 다음 식이 성립\n",
    "$$ E[(X - \\mu_X)(Y - \\mu_Y)] = 0 $$\n",
    "    * 이유는 나중에 설명\n",
    "#### 서로 독립인 두 확률변수의 합의 분산\n",
    "각 확률변수의 분산의 합과 같다.\n",
    "$$ Var[X + Y] = Var[X] + Var[Y] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연습 문제\n",
    "1. NumPy를 사용하여 100개의 숫자를 무작위로 생성하여 표본집합을 구한다. 이 표본집합을 확률변수 $X_1$의 표본이라고 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.17022005e-01, 7.20324493e-01, 1.14374817e-04, 3.02332573e-01,\n",
       "       1.46755891e-01, 9.23385948e-02, 1.86260211e-01, 3.45560727e-01,\n",
       "       3.96767474e-01, 5.38816734e-01, 4.19194514e-01, 6.85219500e-01,\n",
       "       2.04452250e-01, 8.78117436e-01, 2.73875932e-02, 6.70467510e-01,\n",
       "       4.17304802e-01, 5.58689828e-01, 1.40386939e-01, 1.98101489e-01,\n",
       "       8.00744569e-01, 9.68261576e-01, 3.13424178e-01, 6.92322616e-01,\n",
       "       8.76389152e-01, 8.94606664e-01, 8.50442114e-02, 3.90547832e-02,\n",
       "       1.69830420e-01, 8.78142503e-01, 9.83468338e-02, 4.21107625e-01,\n",
       "       9.57889530e-01, 5.33165285e-01, 6.91877114e-01, 3.15515631e-01,\n",
       "       6.86500928e-01, 8.34625672e-01, 1.82882773e-02, 7.50144315e-01,\n",
       "       9.88861089e-01, 7.48165654e-01, 2.80443992e-01, 7.89279328e-01,\n",
       "       1.03226007e-01, 4.47893526e-01, 9.08595503e-01, 2.93614148e-01,\n",
       "       2.87775339e-01, 1.30028572e-01, 1.93669579e-02, 6.78835533e-01,\n",
       "       2.11628116e-01, 2.65546659e-01, 4.91573159e-01, 5.33625451e-02,\n",
       "       5.74117605e-01, 1.46728575e-01, 5.89305537e-01, 6.99758360e-01,\n",
       "       1.02334429e-01, 4.14055988e-01, 6.94400158e-01, 4.14179270e-01,\n",
       "       4.99534589e-02, 5.35896406e-01, 6.63794645e-01, 5.14889112e-01,\n",
       "       9.44594756e-01, 5.86555041e-01, 9.03401915e-01, 1.37474704e-01,\n",
       "       1.39276347e-01, 8.07391289e-01, 3.97676837e-01, 1.65354197e-01,\n",
       "       9.27508580e-01, 3.47765860e-01, 7.50812103e-01, 7.25997985e-01,\n",
       "       8.83306091e-01, 6.23672207e-01, 7.50942434e-01, 3.48898342e-01,\n",
       "       2.69927892e-01, 8.95886218e-01, 4.28091190e-01, 9.64840047e-01,\n",
       "       6.63441498e-01, 6.21695720e-01, 1.14745973e-01, 9.49489259e-01,\n",
       "       4.49912133e-01, 5.78389614e-01, 4.08136803e-01, 2.37026980e-01,\n",
       "       9.03379521e-01, 5.73679487e-01, 2.87032703e-03, 6.17144914e-01])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(1)\n",
    "X1 = np.random.rand(100)\n",
    "X1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 같은 방식으로 100개의 숫자를 생성하며 확률변수 $X_2$의 표본집합을 구한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3266449 , 0.5270581 , 0.8859421 , 0.35726976, 0.90853515,\n",
       "       0.62336012, 0.01582124, 0.92943723, 0.69089692, 0.99732285,\n",
       "       0.17234051, 0.13713575, 0.93259546, 0.69681816, 0.06600017,\n",
       "       0.75546305, 0.75387619, 0.92302454, 0.71152476, 0.12427096,\n",
       "       0.01988013, 0.02621099, 0.02830649, 0.24621107, 0.86002795,\n",
       "       0.53883106, 0.55282198, 0.84203089, 0.12417332, 0.27918368,\n",
       "       0.58575927, 0.96959575, 0.56103022, 0.01864729, 0.80063267,\n",
       "       0.23297427, 0.8071052 , 0.38786064, 0.86354185, 0.74712164,\n",
       "       0.55624023, 0.13645523, 0.05991769, 0.12134346, 0.04455188,\n",
       "       0.10749413, 0.22570934, 0.71298898, 0.55971698, 0.01255598,\n",
       "       0.07197428, 0.96727633, 0.56810046, 0.20329323, 0.25232574,\n",
       "       0.74382585, 0.19542948, 0.58135893, 0.97001999, 0.8468288 ,\n",
       "       0.23984776, 0.49376971, 0.61995572, 0.8289809 , 0.15679139,\n",
       "       0.0185762 , 0.07002214, 0.48634511, 0.60632946, 0.56885144,\n",
       "       0.31736241, 0.98861615, 0.57974522, 0.38014117, 0.55094822,\n",
       "       0.74533443, 0.66923289, 0.26491956, 0.06633483, 0.3700842 ,\n",
       "       0.62971751, 0.21017401, 0.75275555, 0.06653648, 0.2603151 ,\n",
       "       0.80475456, 0.19343428, 0.63946088, 0.52467031, 0.92480797,\n",
       "       0.26329677, 0.06596109, 0.73506596, 0.77217803, 0.90781585,\n",
       "       0.93197207, 0.01395157, 0.23436209, 0.61677836, 0.94901632])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = np.random.rand(100)\n",
    "X2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 두 확률변수의 표본 쌍의 값을 더하여 확률변수 $X_1 + X_2$의 표본집합을 구한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74366691, 1.2473826 , 0.88605647, 0.65960233, 1.05529104,\n",
       "       0.71569871, 0.20208145, 1.27499796, 1.08766439, 1.53613958,\n",
       "       0.59153502, 0.82235525, 1.13704771, 1.5749356 , 0.09338777,\n",
       "       1.42593056, 1.17118099, 1.48171436, 0.8519117 , 0.32237245,\n",
       "       0.8206247 , 0.99447256, 0.34173067, 0.93853368, 1.7364171 ,\n",
       "       1.43343773, 0.63786619, 0.88108568, 0.29400373, 1.15732618,\n",
       "       0.68410611, 1.39070337, 1.51891975, 0.55181257, 1.49250979,\n",
       "       0.5484899 , 1.49360612, 1.22248632, 0.88183013, 1.49726596,\n",
       "       1.54510132, 0.88462088, 0.34036168, 0.91062278, 0.14777789,\n",
       "       0.55538766, 1.13430484, 1.00660313, 0.84749232, 0.14258455,\n",
       "       0.09134124, 1.64611186, 0.77972858, 0.46883989, 0.7438989 ,\n",
       "       0.7971884 , 0.76954709, 0.7280875 , 1.55932553, 1.54658716,\n",
       "       0.34218219, 0.9078257 , 1.31435588, 1.24316017, 0.20674485,\n",
       "       0.55447261, 0.73381679, 1.00123422, 1.55092422, 1.15540648,\n",
       "       1.22076432, 1.12609086, 0.71902157, 1.18753246, 0.94862506,\n",
       "       0.91068863, 1.59674147, 0.61268542, 0.81714694, 1.09608218,\n",
       "       1.5130236 , 0.83384622, 1.50369799, 0.41543482, 0.53024299,\n",
       "       1.70064078, 0.62152547, 1.60430093, 1.18811181, 1.54650369,\n",
       "       0.37804274, 1.01545035, 1.1849781 , 1.35056764, 1.31595266,\n",
       "       1.16899905, 0.91733109, 0.80804157, 0.61964868, 1.56616123])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3 = X1 + X2\n",
    "X3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. $X_1 + X_2$의 표본분산과 $X_1, X_2$의 표본분산의 값의 합을 각각 계산하여 두 값이 비슷함을 보여라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18204705753569503"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(X3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18667713583328754"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(X1) + np.var(X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 표본평균의 분산\n",
    "* 표본평균 $\\bar X$의 분산 $Var[\\bar X]$은 원래 확률변수 $X$의 분산 $Var[X]$와의 관계\n",
    "$$ Var[\\bar X] = \\frac{1}{N}Var[X] $$\n",
    "* 따라서 표본평균을 계산한 표본의 갯수가 커지면 표본평균의 값의 변동은 작아진다.\n",
    "* 표본의 수가 $\\infty$가 되면 표본평균의 값은 항상 일정한 값이 나온다.  \n",
    "즉, 확률적인 값이 아니라 결정론적인 값이 된다.\n",
    "> **증명**\n",
    "$$ Var[\\bar X] = E[(\\bar X - E[\\bar X])^2] $$\n",
    "$$ = E[(\\bar X - \\mu)^2] $$\n",
    "$$ = E[(\\frac{1}{N}\\sum_{i=1}^NX_i - \\mu)^2] $$\n",
    "$$ = E[(\\frac{1}{N}\\sum_{i=1}^NX_i - \\frac{1}{N}N\\mu)^2] $$\n",
    "$$ = E[\\{\\frac{1}{N}(\\sum_{i=1}^NX_i - N\\mu))\\}^2] $$\n",
    "$$ = E[\\{\\frac{1}{N}\\sum_{i=1}^N(X_i - \\mu)\\}^2] $$\n",
    "$$ = E[\\frac{1}{N^2}\\sum_{i=1}^N\\sum_{j=1}^N(X_i - \\mu)(X_j - \\mu)] $$\n",
    "$$ = \\frac{1}{N^2}\\sum_{i=1}^N\\sum_{j=1}^NE[(X_i - \\mu)(X_j - \\mu)] $$\n",
    "$i$번째 표본의 값은 $j$번째$(i ≠ j)$ 표본의 값에 영향을 미치지 않으므로 $X_i$와 $X_j(i ≠ j)$는 독립이다.  \n",
    "따라서\n",
    "$$ E[(X_i - \\mu)(X_j - \\mu)] = 0 \\text{ (i ≠ j)}$$\n",
    "라는 사실을 이용하면 $i = j$인 항, 즉 제곱항만 남는다.\n",
    "$$ Var[\\bar X] = \\frac{1}{N^2}\\sum_{i=1}^NE[(X_i - \\mu)^2] $$\n",
    "$$ = \\frac{1}{N^2}\\sum_{i=1}^NE[(X - \\mu)^2] $$\n",
    "$$ = \\frac{1}{N^2}NE[(X - \\mu)^2] $$\n",
    "$$ = \\frac{1}{N}E[(X - \\mu)^2] $$\n",
    "$$ = \\frac{1}{N}Var[X] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연습 문제\n",
    "1. NumPy를 사용하여 100개의 숫자를 무작위로 생성하여 표본집합을 구한다. 이 표본집합을 확률변수 $X_1$의 표본이라고 하자. $X_1$의 표본분산을 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0756121263848803"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "X_1 = np.random.rand(100)\n",
    "X_1_var = np.var(X_1)\n",
    "X_1_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 같은 작업을 50번 반복하여 확률변수 $X_2, X_3, ..., X_5ο$의 표본집합을 구한다.\n",
    "3. 확률변수 $X_i$의 표본집합의 표본평균 $\\bar x_i$를 각각 계산한다. 이 값들은 확률변수 $\\bar X$의 표본집합이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4587600378570775,\n",
       " 0.515418776128885,\n",
       " 0.47107415945425707,\n",
       " 0.5312484673595094,\n",
       " 0.43521089661866946,\n",
       " 0.49617604768023155]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = []\n",
    "\n",
    "for i in range(50):\n",
    "    mean = np.mean(np.random.rand(100))\n",
    "    arr.append(mean)\n",
    "arr[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 확률변수 $\\bar X$의 표본분산의 값을 계산하고 $X_1$의 표본분산과의 비율을 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006465807755363179"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbar_var = np.var(arr)\n",
    "xbar_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001512242527697606"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1_var / 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 위 식이 의미하는 바\n",
    "* 데이터를 생성하는 확률변수 $X$의 기댓값을 구하려면 확률밀도함수 $p(x)$의 수식을 알아야 한다. 그런데 우리는 그 수식을 정확히 알지 못한다.\n",
    "* 하지만 표본평균이라는 새로운 확률변수 $\\bar X$의 기댓값 $E[\\bar X]$은 원래 확률변수 $X$의 기댓값 $E[X]$과 같으므로 표본평균 $\\bar x$는 원래 확률변수 $X$의 기댓값 $E[X]$과 비슷한 값이 나올 것이다. 하지만 정확한 값은 아니다.\n",
    "* 만약 표본의 갯수 $N$이 크면 표본평균 $\\bar x$의 분산이 아주 작아지므로 표본평균의 값 $\\bar x$은 항상 표본평균의 기댓값 $E[\\bar X] = E[X]$ 근처의 거의 일정한 값이 나올 것이다.\n",
    "* 따라서 **표본의 갯수 $N$가 크면 표본평균 $\\bar x$은 원래 확률변수 $X$의 기댓값 $E[X]$의 근삿값**이라고 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 표본분산의 기댓값\n",
    "* 앞에서 표본평균의 기댓값을 구하면 이론적인 평균. 즉, 기댓값과 같아진다는 것 증명\n",
    "* 표본분산 $S^2$의 기대값은 이론적인 분산 $σ^2$과 같아지는 것이 아니라 이론적인 분산값의 $\\frac{N-1}{N}$배가 된다.  \n",
    "즉 표본분산의 값이 이론적인 분산의 값보다 더 작아진다.\n",
    "$$ E[S^2] = \\frac{N - 1}{N}σ^2 $$\n",
    "> **증명**\n",
    "$$ E[S^2] = E[\\frac{1}{N}\\sum_{i=1}^N(X_i - \\bar X)^2] $$\n",
    "$$ = E[\\frac{1}{N}\\sum_{i=1}^N\\{(X_i - \\mu) - (\\bar X - \\mu)\\}^2] $$\n",
    "$$ = E[\\frac{1}{N}\\sum_{i=1}^N\\{(X_i - \\mu)^2 - 2(X_i - \\mu)(\\bar X - \\mu) + (\\bar X - \\mu)^2\\}] $$\n",
    "$$ = E[\\frac{1}{N}\\sum_{i=1}^N(X_i - \\mu)^2] - 2E[\\frac{1}{N}\\sum_{i=1}^N(X_i - \\mu)(\\bar X - \\mu)] + E[\\frac{1}{N}\\sum_{i=1}^N(\\bar X - \\mu)^2] $$\n",
    "> * 이 때, 첫 번째 항은\n",
    "$$ E[\\frac{1}{N}\\sum_{i=1}^N(X_i - \\mu)^2] = E[\\frac{1}{N}\\sum_{i=1}^N(X - \\mu)^2] $$\n",
    "$$ = E[\\frac{1}{N}N(X - \\mu)^2] $$\n",
    "$$ = E[(X - \\mu)^2] $$\n",
    "$$ = Var[X] $$\n",
    "$$ = σ^2 $$\n",
    "> * 두 번째 항은\n",
    "$$ E[\\frac{1}{N}\\sum_{i=1}^N(X_i - \\mu)(\\bar X - \\mu)] = E[\\frac{1}{N}\\sum_{i=1}^N(X_i - \\mu)(\\frac{1}{N}\\sum_{j=1}^NX_j - \\mu)] $$\n",
    "$$ = E[\\frac{1}{N}\\sum_{i=1}^N(X_i - \\mu)(\\frac{1}{N}\\sum_{j=1}^N(X_j - \\mu)] $$\n",
    "$$ = E[\\frac{1}{N^2}\\sum_{i=1}^N\\sum_{j=1}^N(X_i - \\mu)(X_j - \\mu)] $$\n",
    "$X_i$와 $X_j (i ≠ j)$는 독립일 때,\n",
    "$$ E[(X_i - \\mu)(X_j - \\mu)] = 0 \\text{  (i ≠ j)} $$\n",
    "라는 성질을 이용하면\n",
    "$$ = E[\\frac{1}{N^2}\\sum_{i=1}^N(X_i - \\mu)^2] $$\n",
    "$$ = \\frac{1}{N}E[\\frac{1}{N}\\sum_{i=1}^N(X_i - \\mu)^2] $$\n",
    "$$ = \\frac{1}{N}E[\\frac{1}{N}\\sum_{i=1}^N(X - \\mu)^2] $$\n",
    "$$ = \\frac{1}{N}E[\\frac{1}{N}N(X - \\mu)^2] $$\n",
    "$$ = \\frac{1}{N}E[(X - \\mu)^2] $$\n",
    "$$ = \\frac{1}{N}Var[X] $$\n",
    "$$ = \\frac{σ^2}{N} $$\n",
    "> * 세 번째 항은\n",
    "$$ E[\\frac{1}{N}\\sum_{i=1}^N(\\bar X - \\mu)^2] = E[\\frac{1}{N}\\sum_{i=1}^N(\\frac{1}{N}\\sum_{j=1}^NX_j - \\mu)^2] $$\n",
    "$$ = E[\\frac{1}{N}\\sum_{i=1}^N(\\frac{1}{N}\\sum_{j=1}^N(X_j - \\mu)^2] $$\n",
    "$$ = E[\\frac{1}{N^3}\\sum_{i=1}^N\\sum_{j=1}^N\\sum_{k=1}^N(X_j - \\mu)(X_k - \\mu)] $$\n",
    "$X_j$와 $X_k (j ≠ k)$는 독립일 때,\n",
    "$$ E[(X_j - \\mu)(X_k - \\mu)] = 0 \\text{ (j ≠ k)} $$\n",
    "라는 성질을 이용하면\n",
    "$$ = E[\\frac{1}{N^3}\\sum_{i=1}^N\\sum_{j=1}^N(X_j - \\mu)^2] $$\n",
    "$$ = E[\\frac{1}{N^3}N\\sum_{j=1}^N(X_j - \\mu)^2] $$\n",
    "$$ = E[\\frac{1}{N^2}\\sum_{j=1}^N(X_j - \\mu)^2] $$\n",
    "$$ = \\frac{1}{N}E[\\frac{1}{N}\\sum_{j=1}^N(X_j - \\mu)^2] $$\n",
    "$$ = \\frac{1}{N}Var[X] $$\n",
    "$$ = \\frac{σ^2}{N} $$\n",
    "> * 따라서 세 항의 합은\n",
    "$$ E[S^2] = σ^2 - \\frac{2σ^2}{N} + \\frac{σ^2}{N} = \\frac{N - 1}{N}σ^2 $$\n",
    "\n",
    "#### 표본분산의 기대값이 정확하게 $σ^2$이 되려면\n",
    "평균과의 거리의 제곱의 평균을 구할 때, 분모가 $N$이 아니라 $N - 1$로 써야 한다.\n",
    "$$ σ^2 = \\frac{N}{N - 1}E[S^2] = \\frac{N}{N - 1}E[\\frac{1}{N}\\sum(X_i - \\bar X)^2] $$\n",
    "\n",
    "$$ = E[\\frac{1}{N - 1}\\sum(X_i - \\bar X)^2] $$\n",
    "\n",
    "$$ = E[S^2_{unbiased}] $$\n",
    "\n",
    "#### 표본분산이 실제 분산보다 작아지는 이유\n",
    "1. 표본분산을 계산할 때 사용하는 표본평균의 값이 데이터가 많이 몰려있는 쪽으로 편향되게 나온다.\n",
    "2. 이렇게 데이터가 몰려있는 위치에 있는 표본평균을 기준으로 각 데이터까지의 거리를 계산하면 원래의 기댓값으로부터의 거리보다 작게 나올 수 있다.\n",
    "\n",
    "#### 실제 데이터로 예 살펴보기\n",
    "기댓값 $\\mu = 0$, 분산 $\\sigma^2 = 1$인 정규분포로부터 5개 표본 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.33928471,  0.23556889, -0.15590853, -0.31232848, -0.50178967,\n",
       "       -1.09586204, -1.76360526])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(15)\n",
    "N = 7\n",
    "data = np.sort(np.random.normal(size=N))[::-1]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 표본의 표본평균은 약 0.036이다.(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.46494862738581794"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = np.mean(data)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터와 표본평균의 위치를 그림으로 그리기\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 2))\n",
    "sns.rugplot(data, height=0.5, linewidth=4)\n",
    "x = np.linspace(-3, 3, 100)\n",
    "plt.axvline(x=0, ls=\":\", c=\"r\", linewidth=2, label=\"실제 기댓값\")\n",
    "plt.axvline(x=mean, ls=\"--\", c=\"b\", linewidth=2, label=\"표본평균\")\n",
    "plt.legend()\n",
    "plt.xlim(-2, 2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "표본표준편차는 표본평균으로부터 각 데이터가 떨어진 거리의 평균(정확하게는 거리의 제곱의 평균의 제곱근)이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.80423333,  0.70051752,  0.30904009,  0.15262015, -0.03684105,\n",
       "       -0.63091342, -1.29865663])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 표본표준편차\n",
    "distance_from_sample_mean = data - mean\n",
    "distance_from_sample_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4774618257836171"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 표본분산\n",
    "sample_variance = (distance_from_sample_mean ** 2).mean()\n",
    "sample_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 값은 정확한 분산 값 1보다 작은 값이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5570387967475533"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# N - 1로 나누어 편향 보정한 값\n",
    "sample_variance * N / (N - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 거리값을 살펴보면 표본평균이 데이터가 많은 쪽으로 치우쳐 있기 때문에 다수의 데이터에 대해 정확한 기댓값($μ = 0$)으로부터의 거리보다 작아진다.\n",
    "* 주의할 점  \n",
    "표본분산의 기댓값이 원래의 분산값보다 작게 나온다.  \n",
    "즉 작게 나오는 경향이 있다는 것이지 표본분산값이 원래의 분산값보다 항상 작게 나온다는 뜻이 아니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 모멘트\n",
    "* 앞서 구한 기댓값이나 분산은 확률분포의 모멘트(moment)의 하나이다.\n",
    "$$ \\mu_n = E[(X - \\mu)^n] = \\int(x - \\mu)^np(x)dx $$\n",
    "* 모멘트는 확률분포에서 계산한 특징값이다.\n",
    "* 만약 두 개의 확률분포 $X, Y$가 있고 1차부터 $\\infty$ 차수에 이르기까지 두 확률분포의 모든 모멘트 값이 서로 같다면 두 확률분포는 같은 확률분포이다.\n",
    "$$ E[X] = E[Y] $$\n",
    "$$ E[(X - \\mu_X)^2] = E[(Y - \\mu_Y)^2] $$\n",
    "$$ E[(X - \\mu_X)^3] = E[(Y - \\mu_Y)^3] $$\n",
    "$$ E[(X - \\mu_X)^4] = E[(Y - \\mu_Y)^4] $$\n",
    "$$ E[(X - \\mu_X)^5] = E[(Y - \\mu_Y)^5] $$\n",
    "$$ ... $$\n",
    "이면\n",
    "$$ X =^d Y $$\n",
    "이다.  \n",
    "    * $=^d$: 두 확률변수가 같은 분포에서 나왔다는 것을 표시하는 기호"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. 비대칭도와 첨도\n",
    "#### 비대칭도(skew)\n",
    "* 3차 모멘트 값에서 계산하고 확률밀도함수의 비대칭 정도를 가리킨다.\n",
    "* 비대칭도가 0이면 확률분포가 대칭이다.\n",
    "$$ E[(\\frac{X - \\mu}{\\sigma})^3] = \\frac{\\mu_3}{\\sigma^3} $$\n",
    "\n",
    "#### 첨도(kurtosis)\n",
    "* 4차 모멘트 값에서 계산하며 확률이 정규분포와 대비하여 중심에 모여있는지 바깥으로 퍼져있는지를 나타낸다.\n",
    "$$ E[(\\frac{X - \\mu}{\\sigma})^4] = \\frac{\\mu_4}{\\sigma^4} $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
